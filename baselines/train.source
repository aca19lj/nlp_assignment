 <R> <C> Training data <WITH> BERT-large-FT <HAS> B-COPA <C> Overall <WITH> BERT-large-FT <HAS> 74.5 (± 0.7) <C> Easy <WITH> BERT-large-FT <HAS> 74.7 (± 0.4) <C> Hard <WITH> BERT-large-FT <HAS> [BOLD] 74.4 (± 0.9) <C> <R> <C> Training data <WITH> BERT-large-FT <HAS> B-COPA (50%) <C> Overall <WITH> BERT-large-FT <HAS> 74.3 (± 2.2) <C> Easy <WITH> BERT-large-FT <HAS> 76.8 (± 1.9) <C> Hard <WITH> BERT-large-FT <HAS> 72.8 (± 3.1) <C> <R> <C> Training data <WITH> BERT-large-FT <HAS> COPA <C> Overall <WITH> BERT-large-FT <HAS> [BOLD] 76.5 (± 2.7) <C> Easy <WITH> BERT-large-FT <HAS> [BOLD] 83.9 (± 4.4) <C> Hard <WITH> BERT-large-FT <HAS> 71.9 (± 2.5) <C> <R> <C> Training data <WITH> RoBERTa-large-FT <HAS> B-COPA <C> Overall <WITH> RoBERTa-large-FT <HAS> [BOLD] 89.0 (± 0.3) <C> Easy <WITH> RoBERTa-large-FT <HAS> 88.9 (± 2.1) <C> Hard <WITH> RoBERTa-large-FT <HAS> [BOLD] 89.0 (± 0.8) <C> <R> <C> Training data <WITH> RoBERTa-large-FT <HAS> B-COPA (50%) <C> Overall <WITH> RoBERTa-large-FT <HAS> 86.1 (± 2.2) <C> Easy <WITH> RoBERTa-large-FT <HAS> 87.4 (± 1.1) <C> Hard <WITH> RoBERTa-large-FT <HAS> 85.4 (± 2.9) <C> <R> <C> Training data <WITH> RoBERTa-large-FT <HAS> COPA <C> Overall <WITH> RoBERTa-large-FT <HAS> 87.7 (± 0.9) <C> Easy <WITH> RoBERTa-large-FT <HAS> [BOLD] 91.6 (± 1.1) <C> Hard <WITH> RoBERTa-large-FT <HAS> 85.3 (± 2.0) <C> <CAP> Table 5: Results of fine-tuned models on Balanced COPA. Easy: instances with superficial cues, Hard: instances without superficial cues.
 <R> <C> Accuracy <WITH> BigramPMI Goodwin et al. ( 2012 ) <HAS> 63.4 <C> <R> <C> Accuracy <WITH> PMI Gordon et al. ( 2011 ) <HAS> 65.4 <C> <R> <C> Accuracy <WITH> PMI+Connectives Luo et al. ( 2016 ) <HAS> 70.2 <C> <R> <C> Accuracy <WITH> PMI+Con.+Phrase Sasaki et al. ( 2017 ) <HAS> 71.4 <C> <R> <C> Accuracy <WITH> BERT-large Wang et al. ( 2019 ) <HAS> 70.5 <C> <R> <C> Accuracy <WITH> BERT-large Sap et al. ( 2019 ) <HAS> 75.0 <C> <R> <C> Accuracy <WITH> BERT-large Li et al. ( 2019 ) <HAS> 75.4 <C> <R> <C> Accuracy <WITH> RoBERTa-large (finetuned) <HAS> 90.6 <C> <R> <C> Accuracy <WITH> BERT-large (finetuned)* <HAS> 76.5 ± 2.7 <C> <R> <C> Accuracy <WITH> RoBERTa-large (finetuned)* <HAS> 87.7 ± 0.9 <C> <CAP> Table 1: Reported results on COPA. With the exception of Wang et al. (2019), BERT-large and RoBERTa-large yields substantial improvements over prior approaches. See §2 for model details. * indicates our replication experiments.
 <R> <C> App. <WITH> in <HAS> 47 <C> Prod. <WITH> in <HAS> 55.3 <C> Cov. <WITH> in <HAS> 9.40 <C> <R> <C> App. <WITH> was <HAS> 55 <C> Prod. <WITH> was <HAS> 61.8 <C> Cov. <WITH> was <HAS> 11.0 <C> <R> <C> App. <WITH> to <HAS> 82 <C> Prod. <WITH> to <HAS> 40.2 <C> Cov. <WITH> to <HAS> 16.4 <C> <R> <C> App. <WITH> the <HAS> 85 <C> Prod. <WITH> the <HAS> 38.8 <C> Cov. <WITH> the <HAS> 17.0 <C> <R> <C> App. <WITH> a <HAS> 106 <C> Prod. <WITH> a <HAS> 57.5 <C> Cov. <WITH> a <HAS> 21.2 <C> <CAP> Table 2: Applicability (App.), Productivity (Prod.) and Coverage (Cov.) of the various words in the alternatives of the COPA dev set.
 <R> <C> Accuracy <WITH> Original COPA <HAS> 100.0 <C> Fleiss’ kappa  [ITALIC] k <WITH> Original COPA <HAS> 0.973 <C> <R> <C> Accuracy <WITH> Balanced COPA <HAS> 97.0 <C> Fleiss’ kappa  [ITALIC] k <WITH> Balanced COPA <HAS> 0.798 <C> <CAP> Table 3: Results of human performance evaluation of the original COPA and Balanced COPA.
 <R> <C> Method <WITH> goodwin-etal-2012-utdhlt <HAS> PMI <C> Training Data <WITH> goodwin-etal-2012-utdhlt <HAS> unsupervised <C> Overall <WITH> goodwin-etal-2012-utdhlt <HAS> 61.8 <C> Easy <WITH> goodwin-etal-2012-utdhlt <HAS> 64.7 <C> Hard <WITH> goodwin-etal-2012-utdhlt <HAS> 60.0 <C> p-value (%) <WITH> goodwin-etal-2012-utdhlt <HAS> 19.8 <C> <R> <C> Method <WITH> gordon_commonsense_2011-1 <HAS> PMI <C> Training Data <WITH> gordon_commonsense_2011-1 <HAS> unsupervised <C> Overall <WITH> gordon_commonsense_2011-1 <HAS> 65.4 <C> Easy <WITH> gordon_commonsense_2011-1 <HAS> 65.8 <C> Hard <WITH> gordon_commonsense_2011-1 <HAS> 65.2 <C> p-value (%) <WITH> gordon_commonsense_2011-1 <HAS> 83.5 <C> <R> <C> Method <WITH> sasaki-etal-2017-handling <HAS> PMI <C> Training Data <WITH> sasaki-etal-2017-handling <HAS> unsupervised <C> Overall <WITH> sasaki-etal-2017-handling <HAS> 71.4 <C> Easy <WITH> sasaki-etal-2017-handling <HAS> 75.3 <C> Hard <WITH> sasaki-etal-2017-handling <HAS> 69.0 <C> p-value (%) <WITH> sasaki-etal-2017-handling <HAS> 4.8∗ <C> <R> <C> Method <WITH> Word frequency <HAS> wordfreq <C> Training Data <WITH> Word frequency <HAS> COPA <C> Overall <WITH> Word frequency <HAS> 53.5 <C> Easy <WITH> Word frequency <HAS> 57.4 <C> Hard <WITH> Word frequency <HAS> 51.3 <C> p-value (%) <WITH> Word frequency <HAS> 9.8 <C> <R> <C> Method <WITH> BERT-large-FT <HAS> LM, NSP <C> Training Data <WITH> BERT-large-FT <HAS> COPA <C> Overall <WITH> BERT-large-FT <HAS> 76.5 (± 2.7) <C> Easy <WITH> BERT-large-FT <HAS> 83.9 (± 4.4) <C> Hard <WITH> BERT-large-FT <HAS> 71.9 (± 2.5) <C> p-value (%) <WITH> BERT-large-FT <HAS> 0.0∗ <C> <R> <C> Method <WITH> RoBERTa-large-FT <HAS> LM <C> Training Data <WITH> RoBERTa-large-FT <HAS> COPA <C> Overall <WITH> RoBERTa-large-FT <HAS> 87.7 (± 0.9) <C> Easy <WITH> RoBERTa-large-FT <HAS> 91.6 (± 1.1) <C> Hard <WITH> RoBERTa-large-FT <HAS> 85.3 (± 2.0) <C> p-value (%) <WITH> RoBERTa-large-FT <HAS> 0.0∗ <C> <CAP> Table 4: Model performance on the COPA test set (Overall), on Easy instances with superficial cues, and on Hard instances without superficial cues. p-values according to Approximate Randomization Tests Noreen (1989), with ∗ indicating a significant difference between performance on Easy and Hard p<5%. Methods are pointwise mutual information (PMI), word frequency provided by the wordfreq package Speer et al. (2018), pretrained language model (LM), and next-sentence prediction (NSP).
 <R> <C> Training data <WITH> BERT-large <HAS> B-COPA <C> Overall <WITH> BERT-large <HAS> 70.5 (± 2.5) <C> Easy <WITH> BERT-large <HAS> 72.6 (± 2.3) <C> Hard <WITH> BERT-large <HAS> [BOLD] 69.1 (± 2.7) <C> <R> <C> Training data <WITH> BERT-large <HAS> B-COPA (50%) <C> Overall <WITH> BERT-large <HAS> 69.9 (± 1.9) <C> Easy <WITH> BERT-large <HAS> 71.2 (± 1.3) <C> Hard <WITH> BERT-large <HAS> 69.0 (± 3.5) <C> <R> <C> Training data <WITH> BERT-large <HAS> COPA <C> Overall <WITH> BERT-large <HAS> [BOLD] 71.7 (± 0.5) <C> Easy <WITH> BERT-large <HAS> [BOLD] 80.5 (± 0.4) <C> Hard <WITH> BERT-large <HAS> 66.3 (± 0.8) <C> <R> <C> Training data <WITH> RoBERTa-large <HAS> B-COPA <C> Overall <WITH> RoBERTa-large <HAS> [BOLD] 76.7 (± 0.8) <C> Easy <WITH> RoBERTa-large <HAS> 73.3 (± 1.5) <C> Hard <WITH> RoBERTa-large <HAS> [BOLD] 78.8 (± 2.0) <C> <R> <C> Training data <WITH> RoBERTa-large <HAS> B-COPA (50%) <C> Overall <WITH> RoBERTa-large <HAS> 72.4 (± 2.0) <C> Easy <WITH> RoBERTa-large <HAS> 72.1 (± 1.7) <C> Hard <WITH> RoBERTa-large <HAS> 72.6 (± 2.1) <C> <R> <C> Training data <WITH> RoBERTa-large <HAS> COPA <C> Overall <WITH> RoBERTa-large <HAS> 76.4 (± 0.7) <C> Easy <WITH> RoBERTa-large <HAS> [BOLD] 79.6 (± 1.0) <C> Hard <WITH> RoBERTa-large <HAS> 74.4 (± 1.1) <C> <R> <C> Training data <WITH> BERT-base-NSP <HAS> None <C> Overall <WITH> BERT-base-NSP <HAS> [BOLD] 66.4 <C> Easy <WITH> BERT-base-NSP <HAS> 66.2 <C> Hard <WITH> BERT-base-NSP <HAS> [BOLD] 66.7 <C> <R> <C> Training data <WITH> BERT-large-NSP <HAS> None <C> Overall <WITH> BERT-large-NSP <HAS> 65.0 <C> Easy <WITH> BERT-large-NSP <HAS> [BOLD] 66.9 <C> Hard <WITH> BERT-large-NSP <HAS> 62.1 <C> <CAP> Table 6: Results of non-fine-tuned models on Balanced COPA. Easy: instances with superficial cues, Hard: instances without superficial cues.
 <R> <C> [ITALIC] SCOPA <WITH> woman <HAS> 7.98 <C> [ITALIC] SB_COPA <WITH> woman <HAS> 4.84 <C> Diff. <WITH> woman <HAS> -3.14 <C> Prod. <WITH> woman <HAS> 0.25 <C> <R> <C> [ITALIC] SCOPA <WITH> mother <HAS> 5.16 <C> [ITALIC] SB_COPA <WITH> mother <HAS> 3.95 <C> Diff. <WITH> mother <HAS> -1.21 <C> Prod. <WITH> mother <HAS> 0.75 <C> <R> <C> [ITALIC] SCOPA <WITH> went <HAS> 6.00 <C> [ITALIC] SB_COPA <WITH> went <HAS> 5.15 <C> Diff. <WITH> went <HAS> -0.85 <C> Prod. <WITH> went <HAS> 0.73 <C> <R> <C> [ITALIC] SCOPA <WITH> down <HAS> 5.52 <C> [ITALIC] SB_COPA <WITH> down <HAS> 4.93 <C> Diff. <WITH> down <HAS> -0.58 <C> Prod. <WITH> down <HAS> 0.71 <C> <R> <C> [ITALIC] SCOPA <WITH> into <HAS> 4.07 <C> [ITALIC] SB_COPA <WITH> into <HAS> 3.51 <C> Diff. <WITH> into <HAS> -0.56 <C> Prod. <WITH> into <HAS> 0.40 <C> <CAP> Table 7: Sensitivity of BERT-large to superficial cues identified in §2 (unit: 10−2). Cues with top-5 reduction are shown. SCOPA,SB_COPA indicate the mean contributions of BERT-large trained on COPA, and BERT-large trained on B-COPA, respectively.
 <R> <C> Positive Sentiment Precision <WITH> SVM-w/o neg. <HAS> 0.57 <C> Positive Sentiment Recall <WITH> SVM-w/o neg. <HAS> 0.72 <C> Positive Sentiment Fscore <WITH> SVM-w/o neg. <HAS> 0.64 <C> <R> <C> Positive Sentiment Precision <WITH> SVM-Punct. neg. <HAS> 0.58 <C> Positive Sentiment Recall <WITH> SVM-Punct. neg. <HAS> 0.70 <C> Positive Sentiment Fscore <WITH> SVM-Punct. neg. <HAS> 0.63 <C> <R> <C> Positive Sentiment Precision <WITH> SVM-our-neg. <HAS> 0.58 <C> Positive Sentiment Recall <WITH> SVM-our-neg. <HAS> 0.73 <C> Positive Sentiment Fscore <WITH> SVM-our-neg. <HAS> 0.65 <C> <R> <C> Positive Sentiment Precision <WITH> CNN <HAS> 0.63 <C> Positive Sentiment Recall <WITH> CNN <HAS> 0.83 <C> Positive Sentiment Fscore <WITH> CNN <HAS> 0.72 <C> <R> <C> Positive Sentiment Precision <WITH> CNN-LSTM <HAS> 0.71 <C> Positive Sentiment Recall <WITH> CNN-LSTM <HAS> 0.72 <C> Positive Sentiment Fscore <WITH> CNN-LSTM <HAS> 0.72 <C> <R> <C> Positive Sentiment Precision <WITH> CNN-LSTM-Our-neg-Ant <HAS> [BOLD] 0.78 <C> Positive Sentiment Recall <WITH> CNN-LSTM-Our-neg-Ant <HAS> [BOLD] 0.77 <C> Positive Sentiment Fscore <WITH> CNN-LSTM-Our-neg-Ant <HAS> [BOLD] 0.78 <C> <R> <C> Positive Sentiment Precision <WITH> [EMPTY] <HAS> Negative Sentiment <C> Positive Sentiment Recall <WITH> [EMPTY] <HAS> Negative Sentiment <C> Positive Sentiment Fscore <WITH> [EMPTY] <HAS> Negative Sentiment <C> <R> <C> Positive Sentiment Precision <WITH> [EMPTY] <HAS> Precision <C> Positive Sentiment Recall <WITH> [EMPTY] <HAS> Recall <C> Positive Sentiment Fscore <WITH> [EMPTY] <HAS> Fscore <C> <R> <C> Positive Sentiment Precision <WITH> SVM-w/o neg. <HAS> 0.78 <C> Positive Sentiment Recall <WITH> SVM-w/o neg. <HAS> 0.86 <C> Positive Sentiment Fscore <WITH> SVM-w/o neg. <HAS> 0.82 <C> <R> <C> Positive Sentiment Precision <WITH> SVM-Punct. neg. <HAS> 0.78 <C> Positive Sentiment Recall <WITH> SVM-Punct. neg. <HAS> 0.87 <C> Positive Sentiment Fscore <WITH> SVM-Punct. neg. <HAS> 0.83 <C> <R> <C> Positive Sentiment Precision <WITH> SVM-Our neg. <HAS> 0.80 <C> Positive Sentiment Recall <WITH> SVM-Our neg. <HAS> 0.87 <C> Positive Sentiment Fscore <WITH> SVM-Our neg. <HAS> 0.83 <C> <R> <C> Positive Sentiment Precision <WITH> CNN <HAS> 0.88 <C> Positive Sentiment Recall <WITH> CNN <HAS> 0.72 <C> Positive Sentiment Fscore <WITH> CNN <HAS> 0.79 <C> <R> <C> Positive Sentiment Precision <WITH> CNN-LSTM. <HAS> 0.83 <C> Positive Sentiment Recall <WITH> CNN-LSTM. <HAS> 0.83 <C> Positive Sentiment Fscore <WITH> CNN-LSTM. <HAS> 0.83 <C> <R> <C> Positive Sentiment Precision <WITH> CNN-LSTM-our-neg-Ant <HAS> [BOLD] 0.87 <C> Positive Sentiment Recall <WITH> CNN-LSTM-our-neg-Ant <HAS> [BOLD] 0.87 <C> Positive Sentiment Fscore <WITH> CNN-LSTM-our-neg-Ant <HAS> [BOLD] 0.87 <C> <R> <C> Positive Sentiment Precision <WITH> [EMPTY] <HAS> Train <C> Positive Sentiment Recall <WITH> [EMPTY] <HAS> [EMPTY] <C> Positive Sentiment Fscore <WITH> [EMPTY] <HAS> Test <C> <R> <C> Positive Sentiment Precision <WITH> Positive tweets <HAS> 5121 <C> Positive Sentiment Recall <WITH> Positive tweets <HAS> [EMPTY] <C> Positive Sentiment Fscore <WITH> Positive tweets <HAS> 1320 <C> <R> <C> Positive Sentiment Precision <WITH> Negative tweets <HAS> 9094 <C> Positive Sentiment Recall <WITH> Negative tweets <HAS> [EMPTY] <C> Positive Sentiment Fscore <WITH> Negative tweets <HAS> 2244 <C> <CAP> Table 8: Sentiment classification evaluation, using different classifiers on the test set.
 <R> <C> [BOLD] Punctuation <WITH> In-scope (F) <HAS> 0.66 <C> [BOLD] BiLSTM <WITH> In-scope (F) <HAS> 0.88 <C> [BOLD] Proposed <WITH> In-scope (F) <HAS> 0.85 <C> <R> <C> [BOLD] Punctuation <WITH> Out-scope (F) <HAS> 0.87 <C> [BOLD] BiLSTM <WITH> Out-scope (F) <HAS> 0.97 <C> [BOLD] Proposed <WITH> Out-scope (F) <HAS> 0.97 <C> <R> <C> [BOLD] Punctuation <WITH> PCS <HAS> 0.52 <C> [BOLD] BiLSTM <WITH> PCS <HAS> 0.72 <C> [BOLD] Proposed <WITH> PCS <HAS> 0.72 <C> <CAP> Table 7: Negation classifier performance for scope detection with gold cues and scope.
 <R> <C> 2921 <WITH> True negation cues <HAS> 2674 <C> <R> <C> 2921 <WITH> False negation cues <HAS> 247 <C> <R> <C> 2921 <WITH> Average scope length <HAS> 2.9 <C> <R> <C> 2921 <WITH> Average sentence length <HAS> 13.6 <C> <R> <C> 2921 <WITH> Average tweet length <HAS> 22.3 <C> <CAP> Table 3: Cue and token distribution in the conversational negation corpus.
 <R> <C> [BOLD] F-Score  [BOLD] Baseline <WITH> False cues <HAS> 0.61 <C> [BOLD] F-Score  [BOLD] Proposed <WITH> False cues <HAS> 0.68 <C> [BOLD] Support <WITH> False cues <HAS> 47 <C> <R> <C> [BOLD] F-Score  [BOLD] Baseline <WITH> Actual cues <HAS> 0.97 <C> [BOLD] F-Score  [BOLD] Proposed <WITH> Actual cues <HAS> 0.98 <C> [BOLD] Support <WITH> Actual cues <HAS> 557 <C> <CAP> Table 4: Cue classification on the test set.
 <R> <C> Diversity <WITH> DAMD <HAS> 3.12 <C> App <WITH> DAMD <HAS> 2.50 <C> Good% <WITH> DAMD <HAS> 56.5% <C> OK% <WITH> DAMD <HAS> [BOLD] 37.4% <C> Invalid% <WITH> DAMD <HAS> 6.1% <C> <R> <C> Diversity <WITH> DAMD (+) <HAS> [BOLD] 3.65 <C> App <WITH> DAMD (+) <HAS> [BOLD] 2.53 <C> Good% <WITH> DAMD (+) <HAS> [BOLD] 63.0% <C> OK% <WITH> DAMD (+) <HAS> 27.1% <C> Invalid% <WITH> DAMD (+) <HAS> 9.9% <C> <R> <C> Diversity <WITH> HDSA (+) <HAS> 2.14 <C> App <WITH> HDSA (+) <HAS> 2.47 <C> Good% <WITH> HDSA (+) <HAS> 57.5% <C> OK% <WITH> HDSA (+) <HAS> 32.5% <C> Invalid% <WITH> HDSA (+) <HAS> [BOLD] 10.0% <C> <CAP> Table 5: Human evaluation results. Models with data augmentation are noted as (+). App denotes the average appropriateness score.
 <R> <C> Act # w/o <WITH> Single-Action Baselines <HAS> Single-Action Baselines <C> Act # w/ <WITH> Single-Action Baselines <HAS> Single-Action Baselines <C> Slot # w/o <WITH> Single-Action Baselines <HAS> Single-Action Baselines <C> Slot # w/ <WITH> Single-Action Baselines <HAS> Single-Action Baselines <C> <R> <C> Act # w/o <WITH> DAMD + greedy <HAS> [BOLD] 1.00 <C> Act # w/ <WITH> DAMD + greedy <HAS> [BOLD] 1.00 <C> Slot # w/o <WITH> DAMD + greedy <HAS> 1.95 <C> Slot # w/ <WITH> DAMD + greedy <HAS> [BOLD] 2.51 <C> <R> <C> Act # w/o <WITH> HDSA + fixed threshold <HAS> [BOLD] 1.00 <C> Act # w/ <WITH> HDSA + fixed threshold <HAS> [BOLD] 1.00 <C> Slot # w/o <WITH> HDSA + fixed threshold <HAS> 2.07 <C> Slot # w/ <WITH> HDSA + fixed threshold <HAS> [BOLD] 2.40 <C> <R> <C> Act # w/o <WITH> 5-Action Generation <HAS> 5-Action Generation <C> Act # w/ <WITH> 5-Action Generation <HAS> 5-Action Generation <C> Slot # w/o <WITH> 5-Action Generation <HAS> 5-Action Generation <C> Slot # w/ <WITH> 5-Action Generation <HAS> 5-Action Generation <C> <R> <C> Act # w/o <WITH> DAMD + beam search <HAS> 2.67 <C> Act # w/ <WITH> DAMD + beam search <HAS> [BOLD] 2.87 <C> Slot # w/o <WITH> DAMD + beam search <HAS> 3.36 <C> Slot # w/ <WITH> DAMD + beam search <HAS> [BOLD] 4.39 <C> <R> <C> Act # w/o <WITH> DAMD + diverse beam search <HAS> 2.68 <C> Act # w/ <WITH> DAMD + diverse beam search <HAS> [BOLD] 2.88 <C> Slot # w/o <WITH> DAMD + diverse beam search <HAS> 3.41 <C> Slot # w/ <WITH> DAMD + diverse beam search <HAS> [BOLD] 4.50 <C> <R> <C> Act # w/o <WITH> DAMD + top-k sampling <HAS> 3.08 <C> Act # w/ <WITH> DAMD + top-k sampling <HAS> [BOLD] 3.43 <C> Slot # w/o <WITH> DAMD + top-k sampling <HAS> 3.61 <C> Slot # w/ <WITH> DAMD + top-k sampling <HAS> [BOLD] 4.91 <C> <R> <C> Act # w/o <WITH> DAMD + top-p sampling <HAS> 3.08 <C> Act # w/ <WITH> DAMD + top-p sampling <HAS> [BOLD] 3.40 <C> Slot # w/o <WITH> DAMD + top-p sampling <HAS> 3.79 <C> Slot # w/ <WITH> DAMD + top-p sampling <HAS> [BOLD] 5.20 <C> <R> <C> Act # w/o <WITH> HDSA + sampled threshold <HAS> 1.32 <C> Act # w/ <WITH> HDSA + sampled threshold <HAS> [BOLD] 1.50 <C> Slot # w/o <WITH> HDSA + sampled threshold <HAS> 3.08 <C> Slot # w/ <WITH> HDSA + sampled threshold <HAS> [BOLD] 3.31 <C> <R> <C> Act # w/o <WITH> 10-Action Generation <HAS> 10-Action Generation <C> Act # w/ <WITH> 10-Action Generation <HAS> 10-Action Generation <C> Slot # w/o <WITH> 10-Action Generation <HAS> 10-Action Generation <C> Slot # w/ <WITH> 10-Action Generation <HAS> 10-Action Generation <C> <R> <C> Act # w/o <WITH> DAMD + beam search <HAS> 3.06 <C> Act # w/ <WITH> DAMD + beam search <HAS> [BOLD] 3.39 <C> Slot # w/o <WITH> DAMD + beam search <HAS> 4.06 <C> Slot # w/ <WITH> DAMD + beam search <HAS> [BOLD] 5.29 <C> <R> <C> Act # w/o <WITH> DAMD + diverse beam search <HAS> 3.05 <C> Act # w/ <WITH> DAMD + diverse beam search <HAS> [BOLD] 3.39 <C> Slot # w/o <WITH> DAMD + diverse beam search <HAS> 4.05 <C> Slot # w/ <WITH> DAMD + diverse beam search <HAS> [BOLD] 5.31 <C> <R> <C> Act # w/o <WITH> DAMD + top-k sampling <HAS> 3.59 <C> Act # w/ <WITH> DAMD + top-k sampling <HAS> [BOLD] 4.12 <C> Slot # w/o <WITH> DAMD + top-k sampling <HAS> 4.21 <C> Slot # w/ <WITH> DAMD + top-k sampling <HAS> [BOLD] 5.77 <C> <R> <C> Act # w/o <WITH> DAMD + top-p sampling <HAS> 3.53 <C> Act # w/ <WITH> DAMD + top-p sampling <HAS> [BOLD] 4.02 <C> Slot # w/o <WITH> DAMD + top-p sampling <HAS> 4.41 <C> Slot # w/ <WITH> DAMD + top-p sampling <HAS> [BOLD] 6.17 <C> <R> <C> Act # w/o <WITH> HDSA + sampled threshold <HAS> 1.54 <C> Act # w/ <WITH> HDSA + sampled threshold <HAS> [BOLD] 1.83 <C> Slot # w/o <WITH> HDSA + sampled threshold <HAS> 3.42 <C> Slot # w/ <WITH> HDSA + sampled threshold <HAS> [BOLD] 3.92 <C> <CAP> Table 1: Multi-action evaluation results. The “w” and “w/o” column denote with and without data augmentation respectively, and the better score between them is in bold. We report the average performance over 5 runs.
 <R> <C> Belief State Type <WITH> 1. Seq2Seq + Attention  <HAS> oracle <C> System Action Type <WITH> 1. Seq2Seq + Attention  <HAS> - <C> System Action Form <WITH> 1. Seq2Seq + Attention  <HAS> - <C> Inform (%) <WITH> 1. Seq2Seq + Attention  <HAS> 71.3 <C> Success (%) <WITH> 1. Seq2Seq + Attention  <HAS> 61.0 <C> BLEU <WITH> 1. Seq2Seq + Attention  <HAS> [BOLD] 18.9 <C> Combined Score <WITH> 1. Seq2Seq + Attention  <HAS> 85.1 <C> <R> <C> Belief State Type <WITH> 2. Seq2Seq + Copy <HAS> oracle <C> System Action Type <WITH> 2. Seq2Seq + Copy <HAS> - <C> System Action Form <WITH> 2. Seq2Seq + Copy <HAS> - <C> Inform (%) <WITH> 2. Seq2Seq + Copy <HAS> 86.2 <C> Success (%) <WITH> 2. Seq2Seq + Copy <HAS> [BOLD] 72.0 <C> BLEU <WITH> 2. Seq2Seq + Copy <HAS> 15.7 <C> Combined Score <WITH> 2. Seq2Seq + Copy <HAS> 94.8 <C> <R> <C> Belief State Type <WITH> 3. MD-Sequicity <HAS> oracle <C> System Action Type <WITH> 3. MD-Sequicity <HAS> - <C> System Action Form <WITH> 3. MD-Sequicity <HAS> - <C> Inform (%) <WITH> 3. MD-Sequicity <HAS> [BOLD] 86.6 <C> Success (%) <WITH> 3. MD-Sequicity <HAS> 71.6 <C> BLEU <WITH> 3. MD-Sequicity <HAS> 16.8 <C> Combined Score <WITH> 3. MD-Sequicity <HAS> [BOLD] 95.9 <C> <R> <C> Belief State Type <WITH> 4. SFN + RL (Mehri et al. mehri2019structured) <HAS> oracle <C> System Action Type <WITH> 4. SFN + RL (Mehri et al. mehri2019structured) <HAS> generated <C> System Action Form <WITH> 4. SFN + RL (Mehri et al. mehri2019structured) <HAS> one-hot <C> Inform (%) <WITH> 4. SFN + RL (Mehri et al. mehri2019structured) <HAS> 82.7 <C> Success (%) <WITH> 4. SFN + RL (Mehri et al. mehri2019structured) <HAS> 72.1 <C> BLEU <WITH> 4. SFN + RL (Mehri et al. mehri2019structured) <HAS> 16.3 <C> Combined Score <WITH> 4. SFN + RL (Mehri et al. mehri2019structured) <HAS> 93.7 <C> <R> <C> Belief State Type <WITH> 5. HDSA  <HAS> oracle <C> System Action Type <WITH> 5. HDSA  <HAS> generated <C> System Action Form <WITH> 5. HDSA  <HAS> graph <C> Inform (%) <WITH> 5. HDSA  <HAS> 82.9 <C> Success (%) <WITH> 5. HDSA  <HAS> 68.9 <C> BLEU <WITH> 5. HDSA  <HAS> [BOLD] 23.6 <C> Combined Score <WITH> 5. HDSA  <HAS> 99.5 <C> <R> <C> Belief State Type <WITH> 6. DAMD <HAS> oracle <C> System Action Type <WITH> 6. DAMD <HAS> generated <C> System Action Form <WITH> 6. DAMD <HAS> span <C> Inform (%) <WITH> 6. DAMD <HAS> [BOLD] 89.5 <C> Success (%) <WITH> 6. DAMD <HAS> 75.8 <C> BLEU <WITH> 6. DAMD <HAS> 18.3 <C> Combined Score <WITH> 6. DAMD <HAS> 100.9 <C> <R> <C> Belief State Type <WITH> 7. DAMD + multi-action data augmentation <HAS> oracle <C> System Action Type <WITH> 7. DAMD + multi-action data augmentation <HAS> generated <C> System Action Form <WITH> 7. DAMD + multi-action data augmentation <HAS> span <C> Inform (%) <WITH> 7. DAMD + multi-action data augmentation <HAS> 89.2 <C> Success (%) <WITH> 7. DAMD + multi-action data augmentation <HAS> [BOLD] 77.9 <C> BLEU <WITH> 7. DAMD + multi-action data augmentation <HAS> 18.6 <C> Combined Score <WITH> 7. DAMD + multi-action data augmentation <HAS> [BOLD] 102.2 <C> <R> <C> Belief State Type <WITH> 8. SFN + RL (Mehri et al. mehri2019structured) <HAS> oracle <C> System Action Type <WITH> 8. SFN + RL (Mehri et al. mehri2019structured) <HAS> oracle <C> System Action Form <WITH> 8. SFN + RL (Mehri et al. mehri2019structured) <HAS> one-hot <C> Inform (%) <WITH> 8. SFN + RL (Mehri et al. mehri2019structured) <HAS> - <C> Success (%) <WITH> 8. SFN + RL (Mehri et al. mehri2019structured) <HAS> - <C> BLEU <WITH> 8. SFN + RL (Mehri et al. mehri2019structured) <HAS> 29.0 <C> Combined Score <WITH> 8. SFN + RL (Mehri et al. mehri2019structured) <HAS> 106.0 <C> <R> <C> Belief State Type <WITH> 9. HDSA  <HAS> oracle <C> System Action Type <WITH> 9. HDSA  <HAS> oracle <C> System Action Form <WITH> 9. HDSA  <HAS> graph <C> Inform (%) <WITH> 9. HDSA  <HAS> 87.9 <C> Success (%) <WITH> 9. HDSA  <HAS> 78.0 <C> BLEU <WITH> 9. HDSA  <HAS> [BOLD] 30.4 <C> Combined Score <WITH> 9. HDSA  <HAS> 113.4 <C> <R> <C> Belief State Type <WITH> 10. DAMD + multi-action data augmentation <HAS> oracle <C> System Action Type <WITH> 10. DAMD + multi-action data augmentation <HAS> oracle <C> System Action Form <WITH> 10. DAMD + multi-action data augmentation <HAS> span <C> Inform (%) <WITH> 10. DAMD + multi-action data augmentation <HAS> [BOLD] 95.4 <C> Success (%) <WITH> 10. DAMD + multi-action data augmentation <HAS> [BOLD] 87.2 <C> BLEU <WITH> 10. DAMD + multi-action data augmentation <HAS> 27.3 <C> Combined Score <WITH> 10. DAMD + multi-action data augmentation <HAS> [BOLD] 118.5 <C> <R> <C> Belief State Type <WITH> 11. SFN + RL (Mehri et al. mehri2019structured) <HAS> generated <C> System Action Type <WITH> 11. SFN + RL (Mehri et al. mehri2019structured) <HAS> generated <C> System Action Form <WITH> 11. SFN + RL (Mehri et al. mehri2019structured) <HAS> one-hot <C> Inform (%) <WITH> 11. SFN + RL (Mehri et al. mehri2019structured) <HAS> 73.8 <C> Success (%) <WITH> 11. SFN + RL (Mehri et al. mehri2019structured) <HAS> 58.6 <C> BLEU <WITH> 11. SFN + RL (Mehri et al. mehri2019structured) <HAS> [BOLD] 16.9 <C> Combined Score <WITH> 11. SFN + RL (Mehri et al. mehri2019structured) <HAS> 83.0 <C> <R> <C> Belief State Type <WITH> 12. DAMD + multi-action data augmentation <HAS> generated <C> System Action Type <WITH> 12. DAMD + multi-action data augmentation <HAS> generated <C> System Action Form <WITH> 12. DAMD + multi-action data augmentation <HAS> span <C> Inform (%) <WITH> 12. DAMD + multi-action data augmentation <HAS> [BOLD] 76.3 <C> Success (%) <WITH> 12. DAMD + multi-action data augmentation <HAS> [BOLD] 60.4 <C> BLEU <WITH> 12. DAMD + multi-action data augmentation <HAS> 16.6 <C> Combined Score <WITH> 12. DAMD + multi-action data augmentation <HAS> [BOLD] 85.0 <C> <CAP> Table 2: Comparison of response generation results on MultiWOZ. The oracle/generated denotes either using ground truth or generated results. The results are grouped according to whether and how system action is modeled.
 <R> <C> in-domain SQuAD <WITH> [EMPTY] <HAS> EM <C> in-domain SQuAD <WITH> [EMPTY] <HAS> F1 <C> out-of-domain QA-SRL <WITH> [EMPTY] <HAS> EM <C> out-of-domain QA-SRL <WITH> [EMPTY] <HAS> F1 <C> <R> <C> in-domain SQuAD <WITH> MQAN <HAS> 31.76 <C> in-domain SQuAD <WITH> MQAN <HAS> 75.37 <C> out-of-domain QA-SRL <WITH> MQAN <HAS> <bold>10.99</bold> <C> out-of-domain QA-SRL <WITH> MQAN <HAS> 50.10 <C> <R> <C> in-domain SQuAD <WITH> +coverage <HAS> <bold>32.67</bold> <C> in-domain SQuAD <WITH> +coverage <HAS> <bold>76.83</bold> <C> out-of-domain QA-SRL <WITH> +coverage <HAS> 10.63 <C> out-of-domain QA-SRL <WITH> +coverage <HAS> <bold>50.89</bold> <C> <R> <C> in-domain SQuAD <WITH> BIDAF (ELMO) <HAS> 70.43 <C> in-domain SQuAD <WITH> BIDAF (ELMO) <HAS> 79.76 <C> out-of-domain QA-SRL <WITH> BIDAF (ELMO) <HAS> 28.35 <C> out-of-domain QA-SRL <WITH> BIDAF (ELMO) <HAS> 49.98 <C> <R> <C> in-domain SQuAD <WITH> +coverage <HAS> <bold>71.07</bold> <C> in-domain SQuAD <WITH> +coverage <HAS> <bold>80.15</bold> <C> out-of-domain QA-SRL <WITH> +coverage <HAS> <bold>30.58</bold> <C> out-of-domain QA-SRL <WITH> +coverage <HAS> <bold>52.43</bold> <C> <CAP> Table 3: Impact of using coverage for improving generalization across the datasets of similar tasks. Both models are trained on the SQuAD training data.
 <R> <C> in-domain MultiNLI <WITH> MQAN <HAS> 72.30 <C> out-of-domain SNLI <WITH> MQAN <HAS> 60.91 <C> out-of-domain Glockner <WITH> MQAN <HAS> 41.82 <C> out-of-domain SICK <WITH> MQAN <HAS> 53.95 <C> <R> <C> in-domain MultiNLI <WITH> + coverage <HAS> <bold>73.84</bold> <C> out-of-domain SNLI <WITH> + coverage <HAS> <bold>65.38</bold> <C> out-of-domain Glockner <WITH> + coverage <HAS> <bold>78.69</bold> <C> out-of-domain SICK <WITH> + coverage <HAS> <bold>54.55</bold> <C> <R> <C> in-domain MultiNLI <WITH> ESIM (ELMO) <HAS> 80.04 <C> out-of-domain SNLI <WITH> ESIM (ELMO) <HAS> 68.70 <C> out-of-domain Glockner <WITH> ESIM (ELMO) <HAS> 60.21 <C> out-of-domain SICK <WITH> ESIM (ELMO) <HAS> 51.37 <C> <R> <C> in-domain MultiNLI <WITH> + coverage <HAS> <bold>80.38</bold> <C> out-of-domain SNLI <WITH> + coverage <HAS> <bold>70.05</bold> <C> out-of-domain Glockner <WITH> + coverage <HAS> <bold>67.47</bold> <C> out-of-domain SICK <WITH> + coverage <HAS> <bold>52.65</bold> <C> <CAP> Table 2: Impact of using coverage for improving generalization across different datasets of the same task (NLI). All models are trained on MultiNLI.
 <R> <C> ACER <WITH> 1.666 <HAS> 0.775 <C> PPO <WITH> 1.666 <HAS> 0.639 <C> ALDM <WITH> 1.666 <HAS> 1.069 <C> GDPL <WITH> 1.666 <HAS> [BOLD] 0.238 <C> <CAP> Table 4: KL-divergence between different dialog policy and the human dialog KL(πturns||pturns), where πturns denotes the discrete distribution over the number of dialog turns of simulated sessions between the policy π and the agenda-based user simulator, and pturns for the real human-human dialog.
 <R> <C> Agenda Turns <WITH> GP-MBCM <HAS> 2.99 <C> Agenda Inform <WITH> GP-MBCM <HAS> 19.04 <C> Agenda Match <WITH> GP-MBCM <HAS> 44.29 <C> Agenda Success <WITH> GP-MBCM <HAS> 28.9 <C> <R> <C> Agenda Turns <WITH> ACER <HAS> 10.49 <C> Agenda Inform <WITH> ACER <HAS> 77.98 <C> Agenda Match <WITH> ACER <HAS> 62.83 <C> Agenda Success <WITH> ACER <HAS> 50.8 <C> <R> <C> Agenda Turns <WITH> PPO <HAS> 9.83 <C> Agenda Inform <WITH> PPO <HAS> 83.34 <C> Agenda Match <WITH> PPO <HAS> 69.09 <C> Agenda Success <WITH> PPO <HAS> 59.1 <C> <R> <C> Agenda Turns <WITH> ALDM <HAS> 12.47 <C> Agenda Inform <WITH> ALDM <HAS> 81.20 <C> Agenda Match <WITH> ALDM <HAS> 62.60 <C> Agenda Success <WITH> ALDM <HAS> 61.2 <C> <R> <C> Agenda Turns <WITH> GDPL-sess <HAS> [BOLD] 7.49 <C> Agenda Inform <WITH> GDPL-sess <HAS> 88.39 <C> Agenda Match <WITH> GDPL-sess <HAS> 77.56 <C> Agenda Success <WITH> GDPL-sess <HAS> 76.4 <C> <R> <C> Agenda Turns <WITH> GDPL-discr <HAS> 7.86 <C> Agenda Inform <WITH> GDPL-discr <HAS> 93.21 <C> Agenda Match <WITH> GDPL-discr <HAS> 80.43 <C> Agenda Success <WITH> GDPL-discr <HAS> 80.5 <C> <R> <C> Agenda Turns <WITH> GDPL <HAS> 7.64 <C> Agenda Inform <WITH> GDPL <HAS> [BOLD] 94.97 <C> Agenda Match <WITH> GDPL <HAS> [BOLD] 83.90 <C> Agenda Success <WITH> GDPL <HAS> [BOLD] 86.5 <C> <R> <C> Agenda Turns <WITH> [ITALIC] Human <HAS> [ITALIC] 7.37 <C> Agenda Inform <WITH> [ITALIC] Human <HAS> [ITALIC] 66.89 <C> Agenda Match <WITH> [ITALIC] Human <HAS> [ITALIC] 95.29 <C> Agenda Success <WITH> [ITALIC] Human <HAS> [ITALIC] 75.0 <C> <CAP> Table 3: Performance of different dialog agents on the multi-domain dialog corpus by interacting with the agenda-based user simulator. All the results except “dialog turns” are shown in percentage terms. Real human-human performance computed from the test set (i.e. the last row) serves as the upper bounds.
 <R> <C> VHUS Turns <WITH> ACER <HAS> 22.35 <C> VHUS Inform <WITH> ACER <HAS> 55.13 <C> VHUS Match <WITH> ACER <HAS> 33.08 <C> VHUS Success <WITH> ACER <HAS> 18.6 <C> <R> <C> VHUS Turns <WITH> PPO <HAS> [BOLD] 19.23 <C> VHUS Inform <WITH> PPO <HAS> [BOLD] 56.31 <C> VHUS Match <WITH> PPO <HAS> 33.08 <C> VHUS Success <WITH> PPO <HAS> 18.3 <C> <R> <C> VHUS Turns <WITH> ALDM <HAS> 26.90 <C> VHUS Inform <WITH> ALDM <HAS> 54.37 <C> VHUS Match <WITH> ALDM <HAS> 24.15 <C> VHUS Success <WITH> ALDM <HAS> 16.4 <C> <R> <C> VHUS Turns <WITH> GDPL <HAS> 22.43 <C> VHUS Inform <WITH> GDPL <HAS> 52.58 <C> VHUS Match <WITH> GDPL <HAS> [BOLD] 36.21 <C> VHUS Success <WITH> GDPL <HAS> [BOLD] 19.7 <C> <CAP> Table 5: Performance of different agents on the neural user simulator.
 <R> <C> Efficiency W <WITH> ACER <HAS> 55 <C> Efficiency D <WITH> ACER <HAS> 25 <C> Efficiency L <WITH> ACER <HAS> 20 <C> Quality W <WITH> ACER <HAS> 44 <C> Quality D <WITH> ACER <HAS> 32 <C> Quality L <WITH> ACER <HAS> 24 <C> Success W <WITH> ACER <HAS> 52 <C> Success D <WITH> ACER <HAS> 30 <C> Success L <WITH> ACER <HAS> 18 <C> <R> <C> Efficiency W <WITH> PPO <HAS> 74 <C> Efficiency D <WITH> PPO <HAS> 13 <C> Efficiency L <WITH> PPO <HAS> 13 <C> Quality W <WITH> PPO <HAS> 56 <C> Quality D <WITH> PPO <HAS> 26 <C> Quality L <WITH> PPO <HAS> 18 <C> Success W <WITH> PPO <HAS> 59 <C> Success D <WITH> PPO <HAS> 31 <C> Success L <WITH> PPO <HAS> 10 <C> <R> <C> Efficiency W <WITH> ALDM <HAS> 69 <C> Efficiency D <WITH> ALDM <HAS> 19 <C> Efficiency L <WITH> ALDM <HAS> 12 <C> Quality W <WITH> ALDM <HAS> 49 <C> Quality D <WITH> ALDM <HAS> 25 <C> Quality L <WITH> ALDM <HAS> 26 <C> Success W <WITH> ALDM <HAS> 61 <C> Success D <WITH> ALDM <HAS> 24 <C> Success L <WITH> ALDM <HAS> 15 <C> <CAP> Table 6: The count of human preference on dialog session pairs that GDPL wins (W), draws with (D) or loses to (L) other methods based on different criteria. One method wins the other if the majority prefer the former one.
 <R> <C> Inform Mean <WITH> Full <HAS> 8.413 <C> Inform Num <WITH> Full <HAS> 903 <C> Match Mean <WITH> Full <HAS> 10.59 <C> Match Num <WITH> Full <HAS> 450 <C> Success Mean <WITH> Full <HAS> 11.18 <C> Success Num <WITH> Full <HAS> 865 <C> <R> <C> Inform Mean <WITH> Other <HAS> -99.95 <C> Inform Num <WITH> Other <HAS> 76 <C> Match Mean <WITH> Other <HAS> -48.15 <C> Match Num <WITH> Other <HAS> 99 <C> Success Mean <WITH> Other <HAS> -71.62 <C> Success Num <WITH> Other <HAS> 135 <C> <CAP> Table 7: Return distribution of GDPL on each metric. The first row counts the dialog sessions that get the full score of the corresponding metric, and the results of the rest sessions are included in the second row.
 <R> <C> # dims <WITH> GloVe <HAS> 300 <C> Analg. (sem) <WITH> GloVe <HAS> 78.94 <C> Analg. (syn) <WITH> GloVe <HAS> 64.12 <C> Total <WITH> GloVe <HAS> 70.99 <C> <R> <C> # dims <WITH> Word2Vec <HAS> 300 <C> Analg. (sem) <WITH> Word2Vec <HAS> 81.03 <C> Analg. (syn) <WITH> Word2Vec <HAS> 66.11 <C> Total <WITH> Word2Vec <HAS> 73.03 <C> <R> <C> # dims <WITH> OIWE-IPG <HAS> 300 <C> Analg. (sem) <WITH> OIWE-IPG <HAS> 19.99 <C> Analg. (syn) <WITH> OIWE-IPG <HAS> 23.44 <C> Total <WITH> OIWE-IPG <HAS> 21.84 <C> <R> <C> # dims <WITH> SOV <HAS> 3000 <C> Analg. (sem) <WITH> SOV <HAS> 64.09 <C> Analg. (syn) <WITH> SOV <HAS> 46.26 <C> Total <WITH> SOV <HAS> 54.53 <C> <R> <C> # dims <WITH> SPINE <HAS> 1000 <C> Analg. (sem) <WITH> SPINE <HAS> 17.07 <C> Analg. (syn) <WITH> SPINE <HAS> 8.68 <C> Total <WITH> SPINE <HAS> 12.57 <C> <R> <C> # dims <WITH> Word2Sense <HAS> 2250 <C> Analg. (sem) <WITH> Word2Sense <HAS> 12.94 <C> Analg. (syn) <WITH> Word2Sense <HAS> 19.44 <C> Total <WITH> Word2Sense <HAS> 5.84 <C> <R> <C> # dims <WITH> Proposed <HAS> 300 <C> Analg. (sem) <WITH> Proposed <HAS> 79.96 <C> Analg. (syn) <WITH> Proposed <HAS> 63.52 <C> Total <WITH> Proposed <HAS> 71.15 <C> <CAP> TABLE VII: Precision scores for the Analogy Test
 <R> <C> GloVe <WITH> Participants 1 to 5 <HAS> 80/88/82/78/97 <C> Imparted <WITH> Participants 1 to 5 <HAS> 212/170/207/229/242 <C> <R> <C> GloVe <WITH> Mean/Std <HAS> 85/6.9 <C> Imparted <WITH> Mean/Std <HAS> 212/24.4 <C> <CAP> TABLE V: Word Intrusion Test Results: Correct Answers out of 300 Questions
 <R> <C> GloVe <WITH> WS-353-ALL <HAS> 0.612 <C> Word2Vec <WITH> WS-353-ALL <HAS> 0.7156 <C> OIWE-IPG <WITH> WS-353-ALL <HAS> 0.634 <C> SOV <WITH> WS-353-ALL <HAS> 0.622 <C> SPINE <WITH> WS-353-ALL <HAS> 0.173 <C> Word2Sense <WITH> WS-353-ALL <HAS> 0.690 <C> Proposed <WITH> WS-353-ALL <HAS> 0.657 <C> <R> <C> GloVe <WITH> SIMLEX-999 <HAS> 0.359 <C> Word2Vec <WITH> SIMLEX-999 <HAS> 0.3939 <C> OIWE-IPG <WITH> SIMLEX-999 <HAS> 0.295 <C> SOV <WITH> SIMLEX-999 <HAS> 0.355 <C> SPINE <WITH> SIMLEX-999 <HAS> 0.090 <C> Word2Sense <WITH> SIMLEX-999 <HAS> 0.380 <C> Proposed <WITH> SIMLEX-999 <HAS> 0.381 <C> <R> <C> GloVe <WITH> VERB-143 <HAS> 0.326 <C> Word2Vec <WITH> VERB-143 <HAS> 0.4430 <C> OIWE-IPG <WITH> VERB-143 <HAS> 0.255 <C> SOV <WITH> VERB-143 <HAS> 0.271 <C> SPINE <WITH> VERB-143 <HAS> 0.293 <C> Word2Sense <WITH> VERB-143 <HAS> 0.271 <C> Proposed <WITH> VERB-143 <HAS> 0.348 <C> <R> <C> GloVe <WITH> SimVerb-3500 <HAS> 0.193 <C> Word2Vec <WITH> SimVerb-3500 <HAS> 0.2856 <C> OIWE-IPG <WITH> SimVerb-3500 <HAS> 0.184 <C> SOV <WITH> SimVerb-3500 <HAS> 0.197 <C> SPINE <WITH> SimVerb-3500 <HAS> 0.035 <C> Word2Sense <WITH> SimVerb-3500 <HAS> 0.234 <C> Proposed <WITH> SimVerb-3500 <HAS> 0.245 <C> <R> <C> GloVe <WITH> WS-353-REL <HAS> 0.578 <C> Word2Vec <WITH> WS-353-REL <HAS> 0.6457 <C> OIWE-IPG <WITH> WS-353-REL <HAS> 0.595 <C> SOV <WITH> WS-353-REL <HAS> 0.578 <C> SPINE <WITH> WS-353-REL <HAS> 0.134 <C> Word2Sense <WITH> WS-353-REL <HAS> 0.695 <C> Proposed <WITH> WS-353-REL <HAS> 0.619 <C> <R> <C> GloVe <WITH> RW-STANF. <HAS> 0.378 <C> Word2Vec <WITH> RW-STANF. <HAS> 0.4858 <C> OIWE-IPG <WITH> RW-STANF. <HAS> 0.316 <C> SOV <WITH> RW-STANF. <HAS> 0.373 <C> SPINE <WITH> RW-STANF. <HAS> 0.122 <C> Word2Sense <WITH> RW-STANF. <HAS> 0.390 <C> Proposed <WITH> RW-STANF. <HAS> 0.382 <C> <R> <C> GloVe <WITH> YP-130 <HAS> 0.524 <C> Word2Vec <WITH> YP-130 <HAS> 0.5211 <C> OIWE-IPG <WITH> YP-130 <HAS> 0.353 <C> SOV <WITH> YP-130 <HAS> 0.482 <C> SPINE <WITH> YP-130 <HAS> 0.169 <C> Word2Sense <WITH> YP-130 <HAS> 0.420 <C> Proposed <WITH> YP-130 <HAS> 0.589 <C> <R> <C> GloVe <WITH> MEN-TR-3k <HAS> 0.710 <C> Word2Vec <WITH> MEN-TR-3k <HAS> 0.7528 <C> OIWE-IPG <WITH> MEN-TR-3k <HAS> 0.684 <C> SOV <WITH> MEN-TR-3k <HAS> 0.696 <C> SPINE <WITH> MEN-TR-3k <HAS> 0.298 <C> Word2Sense <WITH> MEN-TR-3k <HAS> 0.769 <C> Proposed <WITH> MEN-TR-3k <HAS> 0.725 <C> <R> <C> GloVe <WITH> RG-65 <HAS> 0.768 <C> Word2Vec <WITH> RG-65 <HAS> 0.8051 <C> OIWE-IPG <WITH> RG-65 <HAS> 0.736 <C> SOV <WITH> RG-65 <HAS> 0.732 <C> SPINE <WITH> RG-65 <HAS> 0.338 <C> Word2Sense <WITH> RG-65 <HAS> 0.761 <C> Proposed <WITH> RG-65 <HAS> 0.774 <C> <R> <C> GloVe <WITH> MTurk-771 <HAS> 0.650 <C> Word2Vec <WITH> MTurk-771 <HAS> 0.6712 <C> OIWE-IPG <WITH> MTurk-771 <HAS> 0.593 <C> SOV <WITH> MTurk-771 <HAS> 0.623 <C> SPINE <WITH> MTurk-771 <HAS> 0.199 <C> Word2Sense <WITH> MTurk-771 <HAS> 0.665 <C> Proposed <WITH> MTurk-771 <HAS> 0.671 <C> <R> <C> GloVe <WITH> WS-353-SIM <HAS> 0.682 <C> Word2Vec <WITH> WS-353-SIM <HAS> 0.7883 <C> OIWE-IPG <WITH> WS-353-SIM <HAS> 0.713 <C> SOV <WITH> WS-353-SIM <HAS> 0.702 <C> SPINE <WITH> WS-353-SIM <HAS> 0.220 <C> Word2Sense <WITH> WS-353-SIM <HAS> 0.720 <C> Proposed <WITH> WS-353-SIM <HAS> 0.720 <C> <R> <C> GloVe <WITH> MC-30 <HAS> 0.749 <C> Word2Vec <WITH> MC-30 <HAS> 0.8112 <C> OIWE-IPG <WITH> MC-30 <HAS> 0.799 <C> SOV <WITH> MC-30 <HAS> 0.726 <C> SPINE <WITH> MC-30 <HAS> 0.330 <C> Word2Sense <WITH> MC-30 <HAS> 0.735 <C> Proposed <WITH> MC-30 <HAS> 0.776 <C> <R> <C> GloVe <WITH> MTurk-287 <HAS> 0.649 <C> Word2Vec <WITH> MTurk-287 <HAS> 0.6645 <C> OIWE-IPG <WITH> MTurk-287 <HAS> 0.591 <C> SOV <WITH> MTurk-287 <HAS> 0.631 <C> SPINE <WITH> MTurk-287 <HAS> 0.295 <C> Word2Sense <WITH> MTurk-287 <HAS> 0.674 <C> Proposed <WITH> MTurk-287 <HAS> 0.634 <C> <R> <C> GloVe <WITH> Average <HAS> 0.552 <C> Word2Vec <WITH> Average <HAS> 0.6141 <C> OIWE-IPG <WITH> Average <HAS> 0.519 <C> SOV <WITH> Average <HAS> 0.538 <C> SPINE <WITH> Average <HAS> 0.207 <C> Word2Sense <WITH> Average <HAS> 0.570 <C> Proposed <WITH> Average <HAS> 0.579 <C> <CAP> TABLE VI: Correlations for Word Similarity Tests
 <R> <C> # of Questions Seen <WITH> All <HAS> 8783 <C> GloVe <WITH> All <HAS> 78.94 <C> Word2Vec <WITH> All <HAS> 81.03 <C> Proposed <WITH> All <HAS> 79.96 <C> <R> <C> # of Questions Seen <WITH> At least one <HAS> 1635 <C> GloVe <WITH> At least one <HAS> 67.58 <C> Word2Vec <WITH> At least one <HAS> 70.89 <C> Proposed <WITH> At least one <HAS> 67.89 <C> <R> <C> # of Questions Seen <WITH> concept word <HAS> 1635 <C> GloVe <WITH> concept word <HAS> 67.58 <C> Word2Vec <WITH> concept word <HAS> 70.89 <C> Proposed <WITH> concept word <HAS> 67.89 <C> <R> <C> # of Questions Seen <WITH> All concept words <HAS> 110 <C> GloVe <WITH> All concept words <HAS> 77.27 <C> Word2Vec <WITH> All concept words <HAS> 89.09 <C> Proposed <WITH> All concept words <HAS> 83.64 <C> <CAP> TABLE VIII: Precision scores for the Semantic Analogy Test
 <R> <C> Word2Vec <WITH> 77.34 <HAS> 77.91 <C> OIWE-IPG <WITH> 77.34 <HAS> 74.27 <C> SOV <WITH> 77.34 <HAS> 78.43 <C> SPINE <WITH> 77.34 <HAS> 74.13 <C> Word2Sense <WITH> 77.34 <HAS> 81.21 <C> Proposed <WITH> 77.34 <HAS> 78.26 <C> <CAP> TABLE IX: Accuracies (%) for Sentiment Classification Task
 <R> <C> R <WITH> Cluster+Lemma <HAS> 71.3 <C> MUC P <WITH> Cluster+Lemma <HAS> 83 <C> [ITALIC] F1 <WITH> Cluster+Lemma <HAS> 76.7 <C> R <WITH> Cluster+Lemma <HAS> 53.4 <C> B3 P <WITH> Cluster+Lemma <HAS> 84.9 <C> [ITALIC] F1 <WITH> Cluster+Lemma <HAS> 65.6 <C> R <WITH> Cluster+Lemma <HAS> 70.1 <C> CEAF- [ITALIC] e P <WITH> Cluster+Lemma <HAS> 52.5 <C> [ITALIC] F1 <WITH> Cluster+Lemma <HAS> 60 <C> CoNLL  [ITALIC] F1 <WITH> Cluster+Lemma <HAS> 67.4 <C> <R> <C> R <WITH> Disjoint <HAS> 76.7 <C> MUC P <WITH> Disjoint <HAS> 80.8 <C> [ITALIC] F1 <WITH> Disjoint <HAS> 78.7 <C> R <WITH> Disjoint <HAS> 63.2 <C> B3 P <WITH> Disjoint <HAS> 78.2 <C> [ITALIC] F1 <WITH> Disjoint <HAS> 69.9 <C> R <WITH> Disjoint <HAS> 65.3 <C> CEAF- [ITALIC] e P <WITH> Disjoint <HAS> 58.3 <C> [ITALIC] F1 <WITH> Disjoint <HAS> 61.6 <C> CoNLL  [ITALIC] F1 <WITH> Disjoint <HAS> 70 <C> <R> <C> R <WITH> Joint <HAS> 78.6 <C> MUC P <WITH> Joint <HAS> 80.9 <C> [ITALIC] F1 <WITH> Joint <HAS> 79.7 <C> R <WITH> Joint <HAS> 65.5 <C> B3 P <WITH> Joint <HAS> 76.4 <C> [ITALIC] F1 <WITH> Joint <HAS> 70.5 <C> R <WITH> Joint <HAS> 65.4 <C> CEAF- [ITALIC] e P <WITH> Joint <HAS> 61.3 <C> [ITALIC] F1 <WITH> Joint <HAS> 63.3 <C> CoNLL  [ITALIC] F1 <WITH> Joint <HAS> [BOLD] 71.2 <C> <CAP> Table 2: Combined within- and cross-document entity coreference results on the ECB+ test set.
 <R> <C> R <WITH> [BOLD] Baselines <HAS> [EMPTY] <C> MUC P <WITH> [BOLD] Baselines <HAS> [EMPTY] <C> [ITALIC] F1 <WITH> [BOLD] Baselines <HAS> [EMPTY] <C> R <WITH> [BOLD] Baselines <HAS> [EMPTY] <C> B3 P <WITH> [BOLD] Baselines <HAS> [EMPTY] <C> [ITALIC] F1 <WITH> [BOLD] Baselines <HAS> [EMPTY] <C> R <WITH> [BOLD] Baselines <HAS> [EMPTY] <C> CEAF- [ITALIC] e P <WITH> [BOLD] Baselines <HAS> [EMPTY] <C> [ITALIC] F1 <WITH> [BOLD] Baselines <HAS> [EMPTY] <C> CoNLL  [ITALIC] F1 <WITH> [BOLD] Baselines <HAS> [EMPTY] <C> <R> <C> R <WITH> Cluster+Lemma <HAS> 76.5 <C> MUC P <WITH> Cluster+Lemma <HAS> 79.9 <C> [ITALIC] F1 <WITH> Cluster+Lemma <HAS> 78.1 <C> R <WITH> Cluster+Lemma <HAS> 71.7 <C> B3 P <WITH> Cluster+Lemma <HAS> 85 <C> [ITALIC] F1 <WITH> Cluster+Lemma <HAS> 77.8 <C> R <WITH> Cluster+Lemma <HAS> 75.5 <C> CEAF- [ITALIC] e P <WITH> Cluster+Lemma <HAS> 71.7 <C> [ITALIC] F1 <WITH> Cluster+Lemma <HAS> 73.6 <C> CoNLL  [ITALIC] F1 <WITH> Cluster+Lemma <HAS> 76.5 <C> <R> <C> R <WITH> CV Cybulska and Vossen ( 2015a ) <HAS> 71 <C> MUC P <WITH> CV Cybulska and Vossen ( 2015a ) <HAS> 75 <C> [ITALIC] F1 <WITH> CV Cybulska and Vossen ( 2015a ) <HAS> 73 <C> R <WITH> CV Cybulska and Vossen ( 2015a ) <HAS> 71 <C> B3 P <WITH> CV Cybulska and Vossen ( 2015a ) <HAS> 78 <C> [ITALIC] F1 <WITH> CV Cybulska and Vossen ( 2015a ) <HAS> 74 <C> R <WITH> CV Cybulska and Vossen ( 2015a ) <HAS> - <C> CEAF- [ITALIC] e P <WITH> CV Cybulska and Vossen ( 2015a ) <HAS> - <C> [ITALIC] F1 <WITH> CV Cybulska and Vossen ( 2015a ) <HAS> 64 <C> CoNLL  [ITALIC] F1 <WITH> CV Cybulska and Vossen ( 2015a ) <HAS> 73 <C> <R> <C> R <WITH> KCP Kenyon-Dean et al. ( 2018 ) <HAS> 67 <C> MUC P <WITH> KCP Kenyon-Dean et al. ( 2018 ) <HAS> 71 <C> [ITALIC] F1 <WITH> KCP Kenyon-Dean et al. ( 2018 ) <HAS> 69 <C> R <WITH> KCP Kenyon-Dean et al. ( 2018 ) <HAS> 71 <C> B3 P <WITH> KCP Kenyon-Dean et al. ( 2018 ) <HAS> 67 <C> [ITALIC] F1 <WITH> KCP Kenyon-Dean et al. ( 2018 ) <HAS> 69 <C> R <WITH> KCP Kenyon-Dean et al. ( 2018 ) <HAS> 71 <C> CEAF- [ITALIC] e P <WITH> KCP Kenyon-Dean et al. ( 2018 ) <HAS> 67 <C> [ITALIC] F1 <WITH> KCP Kenyon-Dean et al. ( 2018 ) <HAS> 69 <C> CoNLL  [ITALIC] F1 <WITH> KCP Kenyon-Dean et al. ( 2018 ) <HAS> 69 <C> <R> <C> R <WITH> Cluster+KCP <HAS> 68.4 <C> MUC P <WITH> Cluster+KCP <HAS> 79.3 <C> [ITALIC] F1 <WITH> Cluster+KCP <HAS> 73.4 <C> R <WITH> Cluster+KCP <HAS> 67.2 <C> B3 P <WITH> Cluster+KCP <HAS> 87.2 <C> [ITALIC] F1 <WITH> Cluster+KCP <HAS> 75.9 <C> R <WITH> Cluster+KCP <HAS> 77.4 <C> CEAF- [ITALIC] e P <WITH> Cluster+KCP <HAS> 66.4 <C> [ITALIC] F1 <WITH> Cluster+KCP <HAS> 71.5 <C> CoNLL  [ITALIC] F1 <WITH> Cluster+KCP <HAS> 73.6 <C> <R> <C> R <WITH> [BOLD] Model Variants <HAS> [EMPTY] <C> MUC P <WITH> [BOLD] Model Variants <HAS> [EMPTY] <C> [ITALIC] F1 <WITH> [BOLD] Model Variants <HAS> [EMPTY] <C> R <WITH> [BOLD] Model Variants <HAS> [EMPTY] <C> B3 P <WITH> [BOLD] Model Variants <HAS> [EMPTY] <C> [ITALIC] F1 <WITH> [BOLD] Model Variants <HAS> [EMPTY] <C> R <WITH> [BOLD] Model Variants <HAS> [EMPTY] <C> CEAF- [ITALIC] e P <WITH> [BOLD] Model Variants <HAS> [EMPTY] <C> [ITALIC] F1 <WITH> [BOLD] Model Variants <HAS> [EMPTY] <C> CoNLL  [ITALIC] F1 <WITH> [BOLD] Model Variants <HAS> [EMPTY] <C> <R> <C> R <WITH> Disjoint <HAS> 75.5 <C> MUC P <WITH> Disjoint <HAS> 83.6 <C> [ITALIC] F1 <WITH> Disjoint <HAS> 79.4 <C> R <WITH> Disjoint <HAS> 75.4 <C> B3 P <WITH> Disjoint <HAS> 86 <C> [ITALIC] F1 <WITH> Disjoint <HAS> 80.4 <C> R <WITH> Disjoint <HAS> 80.3 <C> CEAF- [ITALIC] e P <WITH> Disjoint <HAS> 71.9 <C> [ITALIC] F1 <WITH> Disjoint <HAS> 75.9 <C> CoNLL  [ITALIC] F1 <WITH> Disjoint <HAS> 78.5 <C> <R> <C> R <WITH> Joint <HAS> 77.6 <C> MUC P <WITH> Joint <HAS> 84.5 <C> [ITALIC] F1 <WITH> Joint <HAS> 80.9 <C> R <WITH> Joint <HAS> 76.1 <C> B3 P <WITH> Joint <HAS> 85.1 <C> [ITALIC] F1 <WITH> Joint <HAS> 80.3 <C> R <WITH> Joint <HAS> 81 <C> CEAF- [ITALIC] e P <WITH> Joint <HAS> 73.8 <C> [ITALIC] F1 <WITH> Joint <HAS> 77.3 <C> CoNLL  [ITALIC] F1 <WITH> Joint <HAS> [BOLD] 79.5 <C> <CAP> Table 3: Combined within- and cross-document event coreference results on the ECB+ test set.
 <R> <C> R <WITH> Cluster+Lemma <HAS> 71.3 <C> MUC P <WITH> Cluster+Lemma <HAS> 83 <C> <italic>F</italic>1 <WITH> Cluster+Lemma <HAS> 76.7 <C> R <WITH> Cluster+Lemma <HAS> 53.4 <C> B3 P <WITH> Cluster+Lemma <HAS> 84.9 <C> <italic>F</italic>1 <WITH> Cluster+Lemma <HAS> 65.6 <C> R <WITH> Cluster+Lemma <HAS> 70.1 <C> CEAF-<italic>e</italic> P <WITH> Cluster+Lemma <HAS> 52.5 <C> <italic>F</italic>1 <WITH> Cluster+Lemma <HAS> 60 <C> CoNLL <italic>F</italic>1 <WITH> Cluster+Lemma <HAS> 67.4 <C> <R> <C> R <WITH> Disjoint <HAS> 76.7 <C> MUC P <WITH> Disjoint <HAS> 80.8 <C> <italic>F</italic>1 <WITH> Disjoint <HAS> 78.7 <C> R <WITH> Disjoint <HAS> 63.2 <C> B3 P <WITH> Disjoint <HAS> 78.2 <C> <italic>F</italic>1 <WITH> Disjoint <HAS> 69.9 <C> R <WITH> Disjoint <HAS> 65.3 <C> CEAF-<italic>e</italic> P <WITH> Disjoint <HAS> 58.3 <C> <italic>F</italic>1 <WITH> Disjoint <HAS> 61.6 <C> CoNLL <italic>F</italic>1 <WITH> Disjoint <HAS> 70 <C> <R> <C> R <WITH> Joint <HAS> 78.6 <C> MUC P <WITH> Joint <HAS> 80.9 <C> <italic>F</italic>1 <WITH> Joint <HAS> 79.7 <C> R <WITH> Joint <HAS> 65.5 <C> B3 P <WITH> Joint <HAS> 76.4 <C> <italic>F</italic>1 <WITH> Joint <HAS> 70.5 <C> R <WITH> Joint <HAS> 65.4 <C> CEAF-<italic>e</italic> P <WITH> Joint <HAS> 61.3 <C> <italic>F</italic>1 <WITH> Joint <HAS> 63.3 <C> CoNLL <italic>F</italic>1 <WITH> Joint <HAS> <bold>71.2</bold> <C> <CAP> Table 2: Combined within- and cross-document entity coreference results on the ECB+ test set.
 <R> <C> R <WITH> <bold>Baselines</bold> <HAS> [EMPTY] <C> MUC P <WITH> <bold>Baselines</bold> <HAS> [EMPTY] <C> <italic>F</italic>1 <WITH> <bold>Baselines</bold> <HAS> [EMPTY] <C> R <WITH> <bold>Baselines</bold> <HAS> [EMPTY] <C> B3 P <WITH> <bold>Baselines</bold> <HAS> [EMPTY] <C> <italic>F</italic>1 <WITH> <bold>Baselines</bold> <HAS> [EMPTY] <C> R <WITH> <bold>Baselines</bold> <HAS> [EMPTY] <C> CEAF-<italic>e</italic> P <WITH> <bold>Baselines</bold> <HAS> [EMPTY] <C> <italic>F</italic>1 <WITH> <bold>Baselines</bold> <HAS> [EMPTY] <C> CoNLL <italic>F</italic>1 <WITH> <bold>Baselines</bold> <HAS> [EMPTY] <C> <R> <C> R <WITH> Cluster+Lemma <HAS> 76.5 <C> MUC P <WITH> Cluster+Lemma <HAS> 79.9 <C> <italic>F</italic>1 <WITH> Cluster+Lemma <HAS> 78.1 <C> R <WITH> Cluster+Lemma <HAS> 71.7 <C> B3 P <WITH> Cluster+Lemma <HAS> 85 <C> <italic>F</italic>1 <WITH> Cluster+Lemma <HAS> 77.8 <C> R <WITH> Cluster+Lemma <HAS> 75.5 <C> CEAF-<italic>e</italic> P <WITH> Cluster+Lemma <HAS> 71.7 <C> <italic>F</italic>1 <WITH> Cluster+Lemma <HAS> 73.6 <C> CoNLL <italic>F</italic>1 <WITH> Cluster+Lemma <HAS> 76.5 <C> <R> <C> R <WITH> CV Cybulska and Vossen (<ref id='bib-bib8'>2015a</ref>) <HAS> 71 <C> MUC P <WITH> CV Cybulska and Vossen (<ref id='bib-bib8'>2015a</ref>) <HAS> 75 <C> <italic>F</italic>1 <WITH> CV Cybulska and Vossen (<ref id='bib-bib8'>2015a</ref>) <HAS> 73 <C> R <WITH> CV Cybulska and Vossen (<ref id='bib-bib8'>2015a</ref>) <HAS> 71 <C> B3 P <WITH> CV Cybulska and Vossen (<ref id='bib-bib8'>2015a</ref>) <HAS> 78 <C> <italic>F</italic>1 <WITH> CV Cybulska and Vossen (<ref id='bib-bib8'>2015a</ref>) <HAS> 74 <C> R <WITH> CV Cybulska and Vossen (<ref id='bib-bib8'>2015a</ref>) <HAS> - <C> CEAF-<italic>e</italic> P <WITH> CV Cybulska and Vossen (<ref id='bib-bib8'>2015a</ref>) <HAS> - <C> <italic>F</italic>1 <WITH> CV Cybulska and Vossen (<ref id='bib-bib8'>2015a</ref>) <HAS> 64 <C> CoNLL <italic>F</italic>1 <WITH> CV Cybulska and Vossen (<ref id='bib-bib8'>2015a</ref>) <HAS> 73 <C> <R> <C> R <WITH> KCP Kenyon-Dean et al. (<ref id='bib-bib14'>2018</ref>) <HAS> 67 <C> MUC P <WITH> KCP Kenyon-Dean et al. (<ref id='bib-bib14'>2018</ref>) <HAS> 71 <C> <italic>F</italic>1 <WITH> KCP Kenyon-Dean et al. (<ref id='bib-bib14'>2018</ref>) <HAS> 69 <C> R <WITH> KCP Kenyon-Dean et al. (<ref id='bib-bib14'>2018</ref>) <HAS> 71 <C> B3 P <WITH> KCP Kenyon-Dean et al. (<ref id='bib-bib14'>2018</ref>) <HAS> 67 <C> <italic>F</italic>1 <WITH> KCP Kenyon-Dean et al. (<ref id='bib-bib14'>2018</ref>) <HAS> 69 <C> R <WITH> KCP Kenyon-Dean et al. (<ref id='bib-bib14'>2018</ref>) <HAS> 71 <C> CEAF-<italic>e</italic> P <WITH> KCP Kenyon-Dean et al. (<ref id='bib-bib14'>2018</ref>) <HAS> 67 <C> <italic>F</italic>1 <WITH> KCP Kenyon-Dean et al. (<ref id='bib-bib14'>2018</ref>) <HAS> 69 <C> CoNLL <italic>F</italic>1 <WITH> KCP Kenyon-Dean et al. (<ref id='bib-bib14'>2018</ref>) <HAS> 69 <C> <R> <C> R <WITH> Cluster+KCP <HAS> 68.4 <C> MUC P <WITH> Cluster+KCP <HAS> 79.3 <C> <italic>F</italic>1 <WITH> Cluster+KCP <HAS> 73.4 <C> R <WITH> Cluster+KCP <HAS> 67.2 <C> B3 P <WITH> Cluster+KCP <HAS> 87.2 <C> <italic>F</italic>1 <WITH> Cluster+KCP <HAS> 75.9 <C> R <WITH> Cluster+KCP <HAS> 77.4 <C> CEAF-<italic>e</italic> P <WITH> Cluster+KCP <HAS> 66.4 <C> <italic>F</italic>1 <WITH> Cluster+KCP <HAS> 71.5 <C> CoNLL <italic>F</italic>1 <WITH> Cluster+KCP <HAS> 73.6 <C> <R> <C> R <WITH> <bold>Model Variants</bold> <HAS> [EMPTY] <C> MUC P <WITH> <bold>Model Variants</bold> <HAS> [EMPTY] <C> <italic>F</italic>1 <WITH> <bold>Model Variants</bold> <HAS> [EMPTY] <C> R <WITH> <bold>Model Variants</bold> <HAS> [EMPTY] <C> B3 P <WITH> <bold>Model Variants</bold> <HAS> [EMPTY] <C> <italic>F</italic>1 <WITH> <bold>Model Variants</bold> <HAS> [EMPTY] <C> R <WITH> <bold>Model Variants</bold> <HAS> [EMPTY] <C> CEAF-<italic>e</italic> P <WITH> <bold>Model Variants</bold> <HAS> [EMPTY] <C> <italic>F</italic>1 <WITH> <bold>Model Variants</bold> <HAS> [EMPTY] <C> CoNLL <italic>F</italic>1 <WITH> <bold>Model Variants</bold> <HAS> [EMPTY] <C> <R> <C> R <WITH> Disjoint <HAS> 75.5 <C> MUC P <WITH> Disjoint <HAS> 83.6 <C> <italic>F</italic>1 <WITH> Disjoint <HAS> 79.4 <C> R <WITH> Disjoint <HAS> 75.4 <C> B3 P <WITH> Disjoint <HAS> 86 <C> <italic>F</italic>1 <WITH> Disjoint <HAS> 80.4 <C> R <WITH> Disjoint <HAS> 80.3 <C> CEAF-<italic>e</italic> P <WITH> Disjoint <HAS> 71.9 <C> <italic>F</italic>1 <WITH> Disjoint <HAS> 75.9 <C> CoNLL <italic>F</italic>1 <WITH> Disjoint <HAS> 78.5 <C> <R> <C> R <WITH> Joint <HAS> 77.6 <C> MUC P <WITH> Joint <HAS> 84.5 <C> <italic>F</italic>1 <WITH> Joint <HAS> 80.9 <C> R <WITH> Joint <HAS> 76.1 <C> B3 P <WITH> Joint <HAS> 85.1 <C> <italic>F</italic>1 <WITH> Joint <HAS> 80.3 <C> R <WITH> Joint <HAS> 81 <C> CEAF-<italic>e</italic> P <WITH> Joint <HAS> 73.8 <C> <italic>F</italic>1 <WITH> Joint <HAS> 77.3 <C> CoNLL <italic>F</italic>1 <WITH> Joint <HAS> <bold>79.5</bold> <C> <CAP> Table 3: Combined within- and cross-document event coreference results on the ECB+ test set.
 <R> <C> 0.1 <WITH> PCNN+ATT <HAS> 0.698 <C> 0.2 <WITH> PCNN+ATT <HAS> 0.606 <C> 0.3 <WITH> PCNN+ATT <HAS> 0.518 <C> 0.4 <WITH> PCNN+ATT <HAS> 0.446 <C> AUC <WITH> PCNN+ATT <HAS> 0.323 <C> <R> <C> 0.1 <WITH> Rank+ExATT <HAS> 0.789 <C> 0.2 <WITH> Rank+ExATT <HAS> 0.726 <C> 0.3 <WITH> Rank+ExATT <HAS> 0.620 <C> 0.4 <WITH> Rank+ExATT <HAS> 0.514 <C> AUC <WITH> Rank+ExATT <HAS> 0.395 <C> <R> <C> 0.1 <WITH> Our Model <HAS> 0.788 <C> 0.2 <WITH> Our Model <HAS> [BOLD] 0.743 <C> 0.3 <WITH> Our Model <HAS> [BOLD] 0.654 <C> 0.4 <WITH> Our Model <HAS> [BOLD] 0.546 <C> AUC <WITH> Our Model <HAS> [BOLD] 0.397 <C> <CAP> Table 1: Precisions on the NYT dataset.
 <R> <C> 0.1 <WITH> Rank+ExATT <HAS> 0.584 <C> 0.2 <WITH> Rank+ExATT <HAS> 0.535 <C> 0.3 <WITH> Rank+ExATT <HAS> 0.487 <C> AUC <WITH> Rank+ExATT <HAS> 0.392 <C> <R> <C> 0.1 <WITH> PCNN+ATT (m) <HAS> 0.365 <C> 0.2 <WITH> PCNN+ATT (m) <HAS> 0.317 <C> 0.3 <WITH> PCNN+ATT (m) <HAS> 0.213 <C> AUC <WITH> PCNN+ATT (m) <HAS> 0.204 <C> <R> <C> 0.1 <WITH> PCNN+ATT (1) <HAS> 0.665 <C> 0.2 <WITH> PCNN+ATT (1) <HAS> 0.517 <C> 0.3 <WITH> PCNN+ATT (1) <HAS> 0.413 <C> AUC <WITH> PCNN+ATT (1) <HAS> 0.396 <C> <R> <C> 0.1 <WITH> Our Model <HAS> 0.650 <C> 0.2 <WITH> Our Model <HAS> 0.519 <C> 0.3 <WITH> Our Model <HAS> 0.422 <C> AUC <WITH> Our Model <HAS> [BOLD] 0.405 <C> <CAP> Table 2: Precisions on the Wikidata dataset.
 <R> <C> 0.1 <WITH> -Word-ATT <HAS> 0.648 <C> 0.2 <WITH> -Word-ATT <HAS> 0.515 <C> 0.3 <WITH> -Word-ATT <HAS> 0.395 <C> AUC <WITH> -Word-ATT <HAS> 0.389 <C> <R> <C> 0.1 <WITH> -Capsule <HAS> 0.635 <C> 0.2 <WITH> -Capsule <HAS> 0.507 <C> 0.3 <WITH> -Capsule <HAS> 0.413 <C> AUC <WITH> -Capsule <HAS> 0.386 <C> <R> <C> 0.1 <WITH> Our Model <HAS> 0.650 <C> 0.2 <WITH> Our Model <HAS> 0.519 <C> 0.3 <WITH> Our Model <HAS> 0.422 <C> AUC <WITH> Our Model <HAS> 0.405 <C> <CAP> Table 3: Ablation study of capsule net and word-level attention on Wikidata dataset.
 <R> <C> 0.1 <WITH> [ITALIC] d=1 <HAS> 0.602 <C> 0.2 <WITH> [ITALIC] d=1 <HAS> 0.487 <C> 0.3 <WITH> [ITALIC] d=1 <HAS> 0.403 <C> AUC <WITH> [ITALIC] d=1 <HAS> 0.367 <C> Time <WITH> [ITALIC] d=1 <HAS> 4h <C> <R> <C> 0.1 <WITH> [ITALIC] d=32 <HAS> 0.645 <C> 0.2 <WITH> [ITALIC] d=32 <HAS> 0.501 <C> 0.3 <WITH> [ITALIC] d=32 <HAS> 0.393 <C> AUC <WITH> [ITALIC] d=32 <HAS> 0.370 <C> Time <WITH> [ITALIC] d=32 <HAS> - <C> <R> <C> 0.1 <WITH> [ITALIC] d=16 <HAS> 0.655 <C> 0.2 <WITH> [ITALIC] d=16 <HAS> 0.518 <C> 0.3 <WITH> [ITALIC] d=16 <HAS> 0.413 <C> AUC <WITH> [ITALIC] d=16 <HAS> 0.413 <C> Time <WITH> [ITALIC] d=16 <HAS> 20h <C> <R> <C> 0.1 <WITH> [ITALIC] d=8 <HAS> 0.650 <C> 0.2 <WITH> [ITALIC] d=8 <HAS> 0.519 <C> 0.3 <WITH> [ITALIC] d=8 <HAS> 0.422 <C> AUC <WITH> [ITALIC] d=8 <HAS> 0.405 <C> Time <WITH> [ITALIC] d=8 <HAS> 8h <C> <CAP> Table 4: Precisions on the Wikidata dataset with different choice of d.
 <R> <C> 0.1 <WITH> Iteration=1 <HAS> 0.531 <C> 0.2 <WITH> Iteration=1 <HAS> 0.455 <C> 0.3 <WITH> Iteration=1 <HAS> 0.353 <C> AUC <WITH> Iteration=1 <HAS> 0.201 <C> <R> <C> 0.1 <WITH> Iteration=2 <HAS> 0.592 <C> 0.2 <WITH> Iteration=2 <HAS> 0.498 <C> 0.3 <WITH> Iteration=2 <HAS> 0.385 <C> AUC <WITH> Iteration=2 <HAS> 0.375 <C> <R> <C> 0.1 <WITH> Iteration=3 <HAS> 0.650 <C> 0.2 <WITH> Iteration=3 <HAS> 0.519 <C> 0.3 <WITH> Iteration=3 <HAS> 0.422 <C> AUC <WITH> Iteration=3 <HAS> 0.405 <C> <R> <C> 0.1 <WITH> Iteration=4 <HAS> 0.601 <C> 0.2 <WITH> Iteration=4 <HAS> 0.505 <C> 0.3 <WITH> Iteration=4 <HAS> 0.422 <C> AUC <WITH> Iteration=4 <HAS> 0.385 <C> <R> <C> 0.1 <WITH> Iteration=5 <HAS> 0.575 <C> 0.2 <WITH> Iteration=5 <HAS> 0.495 <C> 0.3 <WITH> Iteration=5 <HAS> 0.394 <C> AUC <WITH> Iteration=5 <HAS> 0.376 <C> <CAP> Table 5: Precisions on the Wikidata dataset with different number of dynamic routing iterations.
 <R> <C> Reward <WITH> Kryscinski et al. ( 2018 ) <HAS> R-L <C> R-1 <WITH> Kryscinski et al. ( 2018 ) <HAS> 40.2 <C> R-2 <WITH> Kryscinski et al. ( 2018 ) <HAS> 17.4 <C> R-L <WITH> Kryscinski et al. ( 2018 ) <HAS> 37.5 <C> <R> <C> Reward <WITH> Narayan et al. ( 2018b ) <HAS> R-1,2,L <C> R-1 <WITH> Narayan et al. ( 2018b ) <HAS> 40.0 <C> R-2 <WITH> Narayan et al. ( 2018b ) <HAS> 18.2 <C> R-L <WITH> Narayan et al. ( 2018b ) <HAS> 36.6 <C> <R> <C> Reward <WITH> Chen and Bansal ( 2018 ) <HAS> R-L <C> R-1 <WITH> Chen and Bansal ( 2018 ) <HAS> 41.5 <C> R-2 <WITH> Chen and Bansal ( 2018 ) <HAS> 18.7 <C> R-L <WITH> Chen and Bansal ( 2018 ) <HAS> 37.8 <C> <R> <C> Reward <WITH> Dong et al. ( 2018 ) <HAS> R-1,2,L <C> R-1 <WITH> Dong et al. ( 2018 ) <HAS> 41.5 <C> R-2 <WITH> Dong et al. ( 2018 ) <HAS> 18.7 <C> R-L <WITH> Dong et al. ( 2018 ) <HAS> 37.6 <C> <R> <C> Reward <WITH> Zhang et al. ( 2018 ) <HAS> [EMPTY] <C> R-1 <WITH> Zhang et al. ( 2018 ) <HAS> 41.1 <C> R-2 <WITH> Zhang et al. ( 2018 ) <HAS> 18.8 <C> R-L <WITH> Zhang et al. ( 2018 ) <HAS> 37.5 <C> <R> <C> Reward <WITH> Zhou et al. ( 2018 ) <HAS> [EMPTY] <C> R-1 <WITH> Zhou et al. ( 2018 ) <HAS> 41.6 <C> R-2 <WITH> Zhou et al. ( 2018 ) <HAS> 19.0 <C> R-L <WITH> Zhou et al. ( 2018 ) <HAS> 38.0 <C> <R> <C> Reward <WITH> Kedzie et al. ( 2018 ) <HAS> [EMPTY] <C> R-1 <WITH> Kedzie et al. ( 2018 ) <HAS> 39.1 <C> R-2 <WITH> Kedzie et al. ( 2018 ) <HAS> 17.9 <C> R-L <WITH> Kedzie et al. ( 2018 ) <HAS> 35.9 <C> <R> <C> Reward <WITH> (ours) NeuralTD <HAS> Learned <C> R-1 <WITH> (ours) NeuralTD <HAS> 39.6 <C> R-2 <WITH> (ours) NeuralTD <HAS> 18.1 <C> R-L <WITH> (ours) NeuralTD <HAS> 36.5 <C> <CAP> Table 3: Full-length ROUGE F-scores of some recent RL-based (upper) and supervised (middle) extractive summarisation systems, as well as our system with learned rewards (bottom). R-1/2/L stands for ROUGE-1/2/L. Our system maximises the learned reward instead of ROUGE, hence receives lower ROUGE scores.
 <R> <C> [ITALIC] ρ <WITH> ROUGE-1 <HAS> .290 <C> [ITALIC] r <WITH> ROUGE-1 <HAS> .304 <C> G-Pre <WITH> ROUGE-1 <HAS> .392 <C> G-Rec <WITH> ROUGE-1 <HAS> .428 <C> <R> <C> [ITALIC] ρ <WITH> ROUGE-2 <HAS> .259 <C> [ITALIC] r <WITH> ROUGE-2 <HAS> .278 <C> G-Pre <WITH> ROUGE-2 <HAS> .408 <C> G-Rec <WITH> ROUGE-2 <HAS> .444 <C> <R> <C> [ITALIC] ρ <WITH> ROUGE-L <HAS> .274 <C> [ITALIC] r <WITH> ROUGE-L <HAS> .297 <C> G-Pre <WITH> ROUGE-L <HAS> .390 <C> G-Rec <WITH> ROUGE-L <HAS> .426 <C> <R> <C> [ITALIC] ρ <WITH> ROUGE-SU4 <HAS> .282 <C> [ITALIC] r <WITH> ROUGE-SU4 <HAS> .279 <C> G-Pre <WITH> ROUGE-SU4 <HAS> .404 <C> G-Rec <WITH> ROUGE-SU4 <HAS> .440 <C> <R> <C> [ITALIC] ρ <WITH> BLEU-1 <HAS> .256 <C> [ITALIC] r <WITH> BLEU-1 <HAS> .281 <C> G-Pre <WITH> BLEU-1 <HAS> .409 <C> G-Rec <WITH> BLEU-1 <HAS> .448 <C> <R> <C> [ITALIC] ρ <WITH> BLEU-2 <HAS> .301 <C> [ITALIC] r <WITH> BLEU-2 <HAS> .312 <C> G-Pre <WITH> BLEU-2 <HAS> .411 <C> G-Rec <WITH> BLEU-2 <HAS> .446 <C> <R> <C> [ITALIC] ρ <WITH> BLEU-3 <HAS> .317 <C> [ITALIC] r <WITH> BLEU-3 <HAS> .312 <C> G-Pre <WITH> BLEU-3 <HAS> .409 <C> G-Rec <WITH> BLEU-3 <HAS> .444 <C> <R> <C> [ITALIC] ρ <WITH> BLEU-4 <HAS> .311 <C> [ITALIC] r <WITH> BLEU-4 <HAS> .307 <C> G-Pre <WITH> BLEU-4 <HAS> .409 <C> G-Rec <WITH> BLEU-4 <HAS> .446 <C> <R> <C> [ITALIC] ρ <WITH> BLEU-5 <HAS> .308 <C> [ITALIC] r <WITH> BLEU-5 <HAS> .303 <C> G-Pre <WITH> BLEU-5 <HAS> .420 <C> G-Rec <WITH> BLEU-5 <HAS> .459 <C> <R> <C> [ITALIC] ρ <WITH> METEOR <HAS> .305 <C> [ITALIC] r <WITH> METEOR <HAS> .285 <C> G-Pre <WITH> METEOR <HAS> .409 <C> G-Rec <WITH> METEOR <HAS> .444 <C> <R> <C> [ITALIC] ρ <WITH> InferSent-Cosine <HAS> [BOLD] .329 <C> [ITALIC] r <WITH> InferSent-Cosine <HAS> [BOLD] .339 <C> G-Pre <WITH> InferSent-Cosine <HAS> .417 <C> G-Rec <WITH> InferSent-Cosine <HAS> .460 <C> <R> <C> [ITALIC] ρ <WITH> BERT-Cosine <HAS> .312 <C> [ITALIC] r <WITH> BERT-Cosine <HAS> .335 <C> G-Pre <WITH> BERT-Cosine <HAS> [BOLD] .440 <C> G-Rec <WITH> BERT-Cosine <HAS> [BOLD] .484 <C> <CAP> Table 1: Quality of reward metrics. G-Pre and G-Rec are the precision and recall rate of the “good” summaries identified by the metrics, resp. All metrics here require reference summaries. We perform stemming and stop words removal as preprosessing, as they help increase the correlation. For InferSent, the embeddings of the reference/system summaries are obtained by averaging the embeddings of the sentences therein.
 <R> <C> Encoder <WITH> MLP <HAS> CNN-RNN <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] ρ <WITH> MLP <HAS> .311 <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] r <WITH> MLP <HAS> .340 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Pre <WITH> MLP <HAS> .486 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Rec <WITH> MLP <HAS> .532 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] ρ <WITH> MLP <HAS> .318 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] r <WITH> MLP <HAS> .335 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Pre <WITH> MLP <HAS> .481 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Rec <WITH> MLP <HAS> .524 <C> <R> <C> Encoder <WITH> MLP <HAS> PMeans-RNN <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] ρ <WITH> MLP <HAS> .313 <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] r <WITH> MLP <HAS> .331 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Pre <WITH> MLP <HAS> .489 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Rec <WITH> MLP <HAS> .536 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] ρ <WITH> MLP <HAS> .354 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] r <WITH> MLP <HAS> .375 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Pre <WITH> MLP <HAS> .502 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Rec <WITH> MLP <HAS> .556 <C> <R> <C> Encoder <WITH> MLP <HAS> BERT <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] ρ <WITH> MLP <HAS> [BOLD] .487 <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] r <WITH> MLP <HAS> [BOLD] .526 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Pre <WITH> MLP <HAS> [BOLD] .544 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Rec <WITH> MLP <HAS> [BOLD] .597 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] ρ <WITH> MLP <HAS> [BOLD] .505 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] r <WITH> MLP <HAS> [BOLD] .531 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Pre <WITH> MLP <HAS> [BOLD] .556 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Rec <WITH> MLP <HAS> [BOLD] .608 <C> <R> <C> Encoder <WITH> SimRed <HAS> CNN <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] ρ <WITH> SimRed <HAS> .340 <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] r <WITH> SimRed <HAS> .392 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Pre <WITH> SimRed <HAS> .470 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Rec <WITH> SimRed <HAS> .515 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] ρ <WITH> SimRed <HAS> .396 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] r <WITH> SimRed <HAS> .443 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Pre <WITH> SimRed <HAS> .499 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Rec <WITH> SimRed <HAS> .549 <C> <R> <C> Encoder <WITH> SimRed <HAS> PMeans <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] ρ <WITH> SimRed <HAS> .354 <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] r <WITH> SimRed <HAS> .393 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Pre <WITH> SimRed <HAS> .493 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Rec <WITH> SimRed <HAS> .541 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] ρ <WITH> SimRed <HAS> .370 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] r <WITH> SimRed <HAS> .374 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Pre <WITH> SimRed <HAS> .507 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Rec <WITH> SimRed <HAS> .551 <C> <R> <C> Encoder <WITH> SimRed <HAS> BERT <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] ρ <WITH> SimRed <HAS> .266 <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] r <WITH> SimRed <HAS> .296 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Pre <WITH> SimRed <HAS> .458 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Rec <WITH> SimRed <HAS> .495 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] ρ <WITH> SimRed <HAS> .325 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] r <WITH> SimRed <HAS> .338 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Pre <WITH> SimRed <HAS> .485 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Rec <WITH> SimRed <HAS> .533 <C> <R> <C> Encoder <WITH> Peyrard and Gurevych ( 2018 ) <HAS> Peyrard and Gurevych ( 2018 ) <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] ρ <WITH> Peyrard and Gurevych ( 2018 ) <HAS> .177 <C> [ITALIC] Reg. loss (Eq. ( 1 ))  [ITALIC] r <WITH> Peyrard and Gurevych ( 2018 ) <HAS> .189 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Pre <WITH> Peyrard and Gurevych ( 2018 ) <HAS> .271 <C> [ITALIC] Reg. loss (Eq. ( 1 )) G-Rec <WITH> Peyrard and Gurevych ( 2018 ) <HAS> .306 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] ρ <WITH> Peyrard and Gurevych ( 2018 ) <HAS> .175 <C> [ITALIC] Pref. loss (Eq. ( 3 ))  [ITALIC] r <WITH> Peyrard and Gurevych ( 2018 ) <HAS> .186 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Pre <WITH> Peyrard and Gurevych ( 2018 ) <HAS> .268 <C> [ITALIC] Pref. loss (Eq. ( 3 )) G-Rec <WITH> Peyrard and Gurevych ( 2018 ) <HAS> .174 <C> <CAP> Table 2: Summary-level correlation of learned reward functions. All results are averaged over 5-fold cross validations. Unlike the metrics in Table 1, all rewards in this table do not require reference summaries.
 <R> <C> Ours <WITH> Avg. Human Rating <HAS> [BOLD] 2.52 <C> Refresh <WITH> Avg. Human Rating <HAS> 2.27 <C> ExtAbsRL <WITH> Avg. Human Rating <HAS> 1.66 <C> <R> <C> Ours <WITH> Best% <HAS> [BOLD] 70.0 <C> Refresh <WITH> Best% <HAS> 33.3 <C> ExtAbsRL <WITH> Best% <HAS> 6.7 <C> <CAP> Table 4: Human evaluation on extractive summaries. Our system receives significantly higher human ratings on average. “Best%”: in how many percentage of documents a system receives the highest human rating.
 <R> <C> R-1 <WITH> R-L (original) <HAS> 40.9 <C> R-2 <WITH> R-L (original) <HAS> 17.8 <C> R-L <WITH> R-L (original) <HAS> 38.5 <C> Human <WITH> R-L (original) <HAS> 1.75 <C> Pref% <WITH> R-L (original) <HAS> 15 <C> <R> <C> R-1 <WITH> Learned (ours) <HAS> 39.2 <C> R-2 <WITH> Learned (ours) <HAS> 17.4 <C> R-L <WITH> Learned (ours) <HAS> 37.5 <C> Human <WITH> Learned (ours) <HAS> [BOLD] 2.20 <C> Pref% <WITH> Learned (ours) <HAS> [BOLD] 75 <C> <CAP> Table 5: Performance of ExtAbsRL with different reward functions, measured in terms of ROUGE (center) and human judgements (right). Using our learned reward yields significantly (p=0.0057) higher average human rating. “Pref%”: in how many percentage of documents a system receives the higher human rating.
 <R> <C> [BOLD] Parameters <WITH> Base <HAS> 8.0M <C> [BOLD] Validation AUC@0.05 <WITH> Base <HAS> [BOLD] 0.871 <C> [BOLD] Test AUC@0.05 <WITH> Base <HAS> 0.816 <C> <R> <C> [BOLD] Parameters <WITH> 4L SRU → 2L LSTM <HAS> 7.3M <C> [BOLD] Validation AUC@0.05 <WITH> 4L SRU → 2L LSTM <HAS> 0.864 <C> [BOLD] Test AUC@0.05 <WITH> 4L SRU → 2L LSTM <HAS> [BOLD] 0.829 <C> <R> <C> [BOLD] Parameters <WITH> 4L SRU → 2L SRU <HAS> 7.8M <C> [BOLD] Validation AUC@0.05 <WITH> 4L SRU → 2L SRU <HAS> 0.856 <C> [BOLD] Test AUC@0.05 <WITH> 4L SRU → 2L SRU <HAS> [BOLD] 0.829 <C> <R> <C> [BOLD] Parameters <WITH> Flat → hierarchical <HAS> 12.4M <C> [BOLD] Validation AUC@0.05 <WITH> Flat → hierarchical <HAS> 0.825 <C> [BOLD] Test AUC@0.05 <WITH> Flat → hierarchical <HAS> 0.559 <C> <R> <C> [BOLD] Parameters <WITH> Cross entropy → hinge loss <HAS> 8.0M <C> [BOLD] Validation AUC@0.05 <WITH> Cross entropy → hinge loss <HAS> 0.765 <C> [BOLD] Test AUC@0.05 <WITH> Cross entropy → hinge loss <HAS> 0.693 <C> <R> <C> [BOLD] Parameters <WITH> 6.6M → 1M examples <HAS> 8.0M <C> [BOLD] Validation AUC@0.05 <WITH> 6.6M → 1M examples <HAS> 0.835 <C> [BOLD] Test AUC@0.05 <WITH> 6.6M → 1M examples <HAS> 0.694 <C> <R> <C> [BOLD] Parameters <WITH> 6.6M → 100K examples <HAS> 8.0M <C> [BOLD] Validation AUC@0.05 <WITH> 6.6M → 100K examples <HAS> 0.565 <C> [BOLD] Test AUC@0.05 <WITH> 6.6M → 100K examples <HAS> 0.417 <C> <R> <C> [BOLD] Parameters <WITH> 200 → 100 negatives <HAS> 8.0M <C> [BOLD] Validation AUC@0.05 <WITH> 200 → 100 negatives <HAS> 0.864 <C> [BOLD] Test AUC@0.05 <WITH> 200 → 100 negatives <HAS> 0.647 <C> <R> <C> [BOLD] Parameters <WITH> 200 → 10 negatives <HAS> 8.0M <C> [BOLD] Validation AUC@0.05 <WITH> 200 → 10 negatives <HAS> 0.720 <C> [BOLD] Test AUC@0.05 <WITH> 200 → 10 negatives <HAS> 0.412 <C> <CAP> Table 9: An ablation study showing the effect of different model architectures and training regimes on performance on the proprietary help desk dataset.
 <R> <C> [BOLD] Layer <WITH> SRU <HAS> 2 <C> [BOLD] Params <WITH> SRU <HAS> 3.7M <C> [BOLD] Time <WITH> SRU <HAS> 14.7 <C> <R> <C> [BOLD] Layer <WITH> SRU <HAS> 4 <C> [BOLD] Params <WITH> SRU <HAS> 8.0M <C> [BOLD] Time <WITH> SRU <HAS> 21.9 <C> <R> <C> [BOLD] Layer <WITH> LSTM <HAS> 2 <C> [BOLD] Params <WITH> LSTM <HAS> 7.3M <C> [BOLD] Time <WITH> LSTM <HAS> 90.9 <C> <R> <C> [BOLD] Layer <WITH> LSTM <HAS> 4 <C> [BOLD] Params <WITH> LSTM <HAS> 15.9M <C> [BOLD] Time <WITH> LSTM <HAS> 174.8 <C> <R> <C> [BOLD] Layer <WITH> +rank response <HAS> - <C> [BOLD] Params <WITH> +rank response <HAS> - <C> [BOLD] Time <WITH> +rank response <HAS> 0.9 <C> <CAP> Table 8: Inference time (milliseconds) of our model to encode a context using an SRU or an LSTM encoder on a single CPU core. The last row shows the extra time needed to compare the response encoding to 10,000 cached candidate response encodings in order to find the best response.
 <R> <C> [BOLD] Validation <WITH> AUC <HAS> 0.991 <C> [BOLD] Test <WITH> AUC <HAS> 0.977 <C> <R> <C> [BOLD] Validation <WITH> AUC@0.1 <HAS> 0.925 <C> [BOLD] Test <WITH> AUC@0.1 <HAS> 0.885 <C> <R> <C> [BOLD] Validation <WITH> AUC@0.05 <HAS> 0.871 <C> [BOLD] Test <WITH> AUC@0.05 <HAS> 0.816 <C> <R> <C> [BOLD] Validation <WITH> AUC@0.01 <HAS> 0.677 <C> [BOLD] Test <WITH> AUC@0.01 <HAS> 0.630 <C> <CAP> Table 3: AUC and AUC@p of our model on the propriety help desk dataset.
 <R> <C> [BOLD] R@1 <WITH> 10 <HAS> 0.892 <C> [BOLD] R@3 <WITH> 10 <HAS> 0.979 <C> [BOLD] R@5 <WITH> 10 <HAS> 0.987 <C> [BOLD] R@10 <WITH> 10 <HAS> 1 <C> <R> <C> [BOLD] R@1 <WITH> 100 <HAS> 0.686 <C> [BOLD] R@3 <WITH> 100 <HAS> 0.842 <C> [BOLD] R@5 <WITH> 100 <HAS> 0.894 <C> [BOLD] R@10 <WITH> 100 <HAS> 0.948 <C> <R> <C> [BOLD] R@1 <WITH> 1,000 <HAS> 0.449 <C> [BOLD] R@3 <WITH> 1,000 <HAS> 0.611 <C> [BOLD] R@5 <WITH> 1,000 <HAS> 0.677 <C> [BOLD] R@10 <WITH> 1,000 <HAS> 0.760 <C> <R> <C> [BOLD] R@1 <WITH> 10,000 <HAS> 0.234 <C> [BOLD] R@3 <WITH> 10,000 <HAS> 0.360 <C> [BOLD] R@5 <WITH> 10,000 <HAS> 0.421 <C> [BOLD] R@10 <WITH> 10,000 <HAS> 0.505 <C> <CAP> Table 4: Recall@k from n response candidates for different values of n using random whitelists. Each random whitelist includes the correct response along with n−1 randomly selected responses.
 <R> <C> [BOLD] R@1 <WITH> Random 10K+ <HAS> 0.252 <C> [BOLD] R@3 <WITH> Random 10K+ <HAS> 0.400 <C> [BOLD] R@5 <WITH> Random 10K+ <HAS> 0.472 <C> [BOLD] R@10 <WITH> Random 10K+ <HAS> 0.560 <C> [BOLD] BLEU <WITH> Random 10K+ <HAS> 37.71 <C> <R> <C> [BOLD] R@1 <WITH> Frequency 10K+ <HAS> 0.257 <C> [BOLD] R@3 <WITH> Frequency 10K+ <HAS> 0.389 <C> [BOLD] R@5 <WITH> Frequency 10K+ <HAS> 0.455 <C> [BOLD] R@10 <WITH> Frequency 10K+ <HAS> 0.544 <C> [BOLD] BLEU <WITH> Frequency 10K+ <HAS> 41.34 <C> <R> <C> [BOLD] R@1 <WITH> Clustering 10K+ <HAS> 0.230 <C> [BOLD] R@3 <WITH> Clustering 10K+ <HAS> 0.376 <C> [BOLD] R@5 <WITH> Clustering 10K+ <HAS> 0.447 <C> [BOLD] R@10 <WITH> Clustering 10K+ <HAS> 0.541 <C> [BOLD] BLEU <WITH> Clustering 10K+ <HAS> 37.59 <C> <R> <C> [BOLD] R@1 <WITH> Random 1K+ <HAS> 0.496 <C> [BOLD] R@3 <WITH> Random 1K+ <HAS> 0.663 <C> [BOLD] R@5 <WITH> Random 1K+ <HAS> 0.728 <C> [BOLD] R@10 <WITH> Random 1K+ <HAS> 0.805 <C> [BOLD] BLEU <WITH> Random 1K+ <HAS> 59.28 <C> <R> <C> [BOLD] R@1 <WITH> Frequency 1K+ <HAS> 0.513 <C> [BOLD] R@3 <WITH> Frequency 1K+ <HAS> 0.666 <C> [BOLD] R@5 <WITH> Frequency 1K+ <HAS> 0.726 <C> [BOLD] R@10 <WITH> Frequency 1K+ <HAS> 0.794 <C> [BOLD] BLEU <WITH> Frequency 1K+ <HAS> 67.05 <C> <R> <C> [BOLD] R@1 <WITH> Clustering 1K+ <HAS> 0.481 <C> [BOLD] R@3 <WITH> Clustering 1K+ <HAS> 0.667 <C> [BOLD] R@5 <WITH> Clustering 1K+ <HAS> 0.745 <C> [BOLD] R@10 <WITH> Clustering 1K+ <HAS> 0.835 <C> [BOLD] BLEU <WITH> Clustering 1K+ <HAS> 61.88 <C> <R> <C> [BOLD] R@1 <WITH> Frequency 10K <HAS> 0.136 <C> [BOLD] R@3 <WITH> Frequency 10K <HAS> 0.261 <C> [BOLD] R@5 <WITH> Frequency 10K <HAS> 0.327 <C> [BOLD] R@10 <WITH> Frequency 10K <HAS> 0.420 <C> [BOLD] BLEU <WITH> Frequency 10K <HAS> 30.46 <C> <R> <C> [BOLD] R@1 <WITH> Clustering 10K <HAS> 0.164 <C> [BOLD] R@3 <WITH> Clustering 10K <HAS> 0.292 <C> [BOLD] R@5 <WITH> Clustering 10K <HAS> 0.360 <C> [BOLD] R@10 <WITH> Clustering 10K <HAS> 0.457 <C> [BOLD] BLEU <WITH> Clustering 10K <HAS> 31.47 <C> <R> <C> [BOLD] R@1 <WITH> Frequency 1K <HAS> 0.273 <C> [BOLD] R@3 <WITH> Frequency 1K <HAS> 0.465 <C> [BOLD] R@5 <WITH> Frequency 1K <HAS> 0.550 <C> [BOLD] R@10 <WITH> Frequency 1K <HAS> 0.658 <C> [BOLD] BLEU <WITH> Frequency 1K <HAS> 47.13 <C> <R> <C> [BOLD] R@1 <WITH> Clustering 1K <HAS> 0.331 <C> [BOLD] R@3 <WITH> Clustering 1K <HAS> 0.542 <C> [BOLD] R@5 <WITH> Clustering 1K <HAS> 0.650 <C> [BOLD] R@10 <WITH> Clustering 1K <HAS> 0.782 <C> [BOLD] BLEU <WITH> Clustering 1K <HAS> 49.26 <C> <CAP> Table 5: Recall@k for random, frequency, and clustering whitelists of different sizes. The “+” indicates that the true response is added to the whitelist.
 <R> <C> [BOLD] R@1 <WITH> Frequency 10K <HAS> 0.136 <C> [BOLD] Coverage <WITH> Frequency 10K <HAS> 45.04% <C> <R> <C> [BOLD] R@1 <WITH> Clustering 10K <HAS> 0.164 <C> [BOLD] Coverage <WITH> Clustering 10K <HAS> 38.38% <C> <R> <C> [BOLD] R@1 <WITH> Frequency 1K <HAS> 0.273 <C> [BOLD] Coverage <WITH> Frequency 1K <HAS> 33.38% <C> <R> <C> [BOLD] R@1 <WITH> Clustering 1K <HAS> 0.331 <C> [BOLD] Coverage <WITH> Clustering 1K <HAS> 23.28% <C> <CAP> Table 6: Recall@1 versus coverage for frequency and clustering whitelists.
 <R> <C> [BOLD] Great <WITH> Freq. 1K <HAS> 54% <C> [BOLD] Good <WITH> Freq. 1K <HAS> 26% <C> [BOLD] Bad <WITH> Freq. 1K <HAS> 20% <C> [BOLD] Accept <WITH> Freq. 1K <HAS> 80% <C> <R> <C> [BOLD] Great <WITH> Cluster. 1K <HAS> 55% <C> [BOLD] Good <WITH> Cluster. 1K <HAS> 21% <C> [BOLD] Bad <WITH> Cluster. 1K <HAS> 23% <C> [BOLD] Accept <WITH> Cluster. 1K <HAS> 77% <C> <R> <C> [BOLD] Great <WITH> Freq. 10K <HAS> 56% <C> [BOLD] Good <WITH> Freq. 10K <HAS> 24% <C> [BOLD] Bad <WITH> Freq. 10K <HAS> 21% <C> [BOLD] Accept <WITH> Freq. 10K <HAS> 80% <C> <R> <C> [BOLD] Great <WITH> Cluster. 10K <HAS> 57% <C> [BOLD] Good <WITH> Cluster. 10K <HAS> 23% <C> [BOLD] Bad <WITH> Cluster. 10K <HAS> 20% <C> [BOLD] Accept <WITH> Cluster. 10K <HAS> 80% <C> <R> <C> [BOLD] Great <WITH> Real response <HAS> 60% <C> [BOLD] Good <WITH> Real response <HAS> 24% <C> [BOLD] Bad <WITH> Real response <HAS> 16% <C> [BOLD] Accept <WITH> Real response <HAS> 84% <C> <CAP> Table 7: Results of the human evaluation of the responses produced by our model. A response is acceptable if it is either good or great. Note: Numbers may not add up to 100% due to rounding.
 <R> <C> M <WITH> Random <HAS> 43.6 <C> F <WITH> Random <HAS> 39.3 <C> B <WITH> Random <HAS> [ITALIC] 0.90 <C> O <WITH> Random <HAS> 41.5 <C> <R> <C> M <WITH> Token Distance <HAS> 50.1 <C> F <WITH> Token Distance <HAS> 42.4 <C> B <WITH> Token Distance <HAS> [ITALIC] 0.85 <C> O <WITH> Token Distance <HAS> 46.4 <C> <R> <C> M <WITH> Topical Entity <HAS> 51.5 <C> F <WITH> Topical Entity <HAS> 43.7 <C> B <WITH> Topical Entity <HAS> [ITALIC] 0.85 <C> O <WITH> Topical Entity <HAS> 47.7 <C> <R> <C> M <WITH> Syntactic Distance <HAS> 63.0 <C> F <WITH> Syntactic Distance <HAS> 56.2 <C> B <WITH> Syntactic Distance <HAS> [ITALIC] 0.89 <C> O <WITH> Syntactic Distance <HAS> 59.7 <C> <R> <C> M <WITH> Parallelism <HAS> [BOLD] 67.1 <C> F <WITH> Parallelism <HAS> [BOLD] 63.1 <C> B <WITH> Parallelism <HAS> [ITALIC]  [BOLD] 0.94 <C> O <WITH> Parallelism <HAS> [BOLD] 65.2 <C> <R> <C> M <WITH> Parallelism+URL <HAS> [BOLD] 71.1 <C> F <WITH> Parallelism+URL <HAS> [BOLD] 66.9 <C> B <WITH> Parallelism+URL <HAS> [ITALIC]  [BOLD] 0.94 <C> O <WITH> Parallelism+URL <HAS> [BOLD] 69.0 <C> <R> <C> M <WITH> Transformer-Single <HAS> 58.6 <C> F <WITH> Transformer-Single <HAS> 51.2 <C> B <WITH> Transformer-Single <HAS> [ITALIC] 0.87 <C> O <WITH> Transformer-Single <HAS> 55.0 <C> <R> <C> M <WITH> Transformer-Multi <HAS> 59.3 <C> F <WITH> Transformer-Multi <HAS> 52.9 <C> B <WITH> Transformer-Multi <HAS> [ITALIC] 0.89 <C> O <WITH> Transformer-Multi <HAS> 56.2 <C> <CAP> Table 6: Performance of our baselines on the development set. Parallelism+URL tests the page-context setting; all other test the snippet-context setting. Bold indicates best performance in each setting.
 <R> <C> M <WITH> Lee et al. ( 2013 ) <HAS> 55.4 <C> F <WITH> Lee et al. ( 2013 ) <HAS> 45.5 <C> B <WITH> Lee et al. ( 2013 ) <HAS> [ITALIC] 0.82 <C> O <WITH> Lee et al. ( 2013 ) <HAS> 50.5 <C> <R> <C> M <WITH> Clark and Manning <HAS> 58.5 <C> F <WITH> Clark and Manning <HAS> 51.3 <C> B <WITH> Clark and Manning <HAS> [ITALIC] 0.88 <C> O <WITH> Clark and Manning <HAS> 55.0 <C> <R> <C> M <WITH> Wiseman et al. <HAS> [BOLD] 68.4 <C> F <WITH> Wiseman et al. <HAS> 59.9 <C> B <WITH> Wiseman et al. <HAS> [ITALIC] 0.88 <C> O <WITH> Wiseman et al. <HAS> 64.2 <C> <R> <C> M <WITH> Lee et al. ( 2017 ) <HAS> 67.2 <C> F <WITH> Lee et al. ( 2017 ) <HAS> [BOLD] 62.2 <C> B <WITH> Lee et al. ( 2017 ) <HAS> [ITALIC]  [BOLD] 0.92 <C> O <WITH> Lee et al. ( 2017 ) <HAS> [BOLD] 64.7 <C> <CAP> Table 4: Performance of off-the-shelf resolvers on the GAP development set, split by Masculine and Feminine (Bias shows F/M), and Overall. Bold indicates best performance.
 <R> <C> M <WITH> Random <HAS> 47.5 <C> F <WITH> Random <HAS> 50.5 <C> B <WITH> Random <HAS> [ITALIC] 1.06 <C> O <WITH> Random <HAS> 49.0 <C> <R> <C> M <WITH> Token Distance <HAS> 50.6 <C> F <WITH> Token Distance <HAS> 47.5 <C> B <WITH> Token Distance <HAS> [ITALIC] 0.94 <C> O <WITH> Token Distance <HAS> 49.1 <C> <R> <C> M <WITH> Topical Entity <HAS> 50.2 <C> F <WITH> Topical Entity <HAS> 47.3 <C> B <WITH> Topical Entity <HAS> [ITALIC] 0.94 <C> O <WITH> Topical Entity <HAS> 48.8 <C> <R> <C> M <WITH> Syntactic Distance <HAS> 66.7 <C> F <WITH> Syntactic Distance <HAS> 66.7 <C> B <WITH> Syntactic Distance <HAS> [ITALIC]  [BOLD] 1.00 <C> O <WITH> Syntactic Distance <HAS> 66.7 <C> <R> <C> M <WITH> Parallelism <HAS> [BOLD] 69.3 <C> F <WITH> Parallelism <HAS> [BOLD] 69.2 <C> B <WITH> Parallelism <HAS> [ITALIC]  [BOLD] 1.00 <C> O <WITH> Parallelism <HAS> [BOLD] 69.2 <C> <R> <C> M <WITH> Parallelism+URL <HAS> [BOLD] 74.2 <C> F <WITH> Parallelism+URL <HAS> [BOLD] 71.6 <C> B <WITH> Parallelism+URL <HAS> [ITALIC]  [BOLD] 0.96 <C> O <WITH> Parallelism+URL <HAS> [BOLD] 72.9 <C> <R> <C> M <WITH> Transformer-Single <HAS> 59.6 <C> F <WITH> Transformer-Single <HAS> 56.6 <C> B <WITH> Transformer-Single <HAS> [ITALIC] 0.95 <C> O <WITH> Transformer-Single <HAS> 58.1 <C> <R> <C> M <WITH> Transformer-Multi <HAS> 62.9 <C> F <WITH> Transformer-Multi <HAS> 61.7 <C> B <WITH> Transformer-Multi <HAS> [ITALIC] 0.98 <C> O <WITH> Transformer-Multi <HAS> 62.3 <C> <CAP> Table 7: Performance of our baselines on the development set in the gold-two-mention task (access to the two candidate name spans). Parallelism+URL tests the page-context setting; all other test the snippet-context setting. Bold indicates best performance in each setting.
 <R> <C> L0 <WITH> H0 <HAS> 4 6.9 <C> L1 <WITH> H0 <HAS> 4 7.4 <C> L2 <WITH> H0 <HAS> 4 5.8 <C> L3 <WITH> H0 <HAS> 4 6.2 <C> L4 <WITH> H0 <HAS> 4 5.8 <C> L5 <WITH> H0 <HAS> 4 5.7 <C> <R> <C> L0 <WITH> H1 <HAS> 4 5.3 <C> L1 <WITH> H1 <HAS> 4 6.5 <C> L2 <WITH> H1 <HAS> 4 6.4 <C> L3 <WITH> H1 <HAS> 4 6.2 <C> L4 <WITH> H1 <HAS> 4 9.4 <C> L5 <WITH> H1 <HAS> 4 6.3 <C> <R> <C> L0 <WITH> H2 <HAS> 4 5.8 <C> L1 <WITH> H2 <HAS> 4 6.7 <C> L2 <WITH> H2 <HAS> 4 6.3 <C> L3 <WITH> H2 <HAS> 4 6.5 <C> L4 <WITH> H2 <HAS> 4 5.7 <C> L5 <WITH> H2 <HAS> 4 5.9 <C> <R> <C> L0 <WITH> H3 <HAS> 4 6.0 <C> L1 <WITH> H3 <HAS> 4 6.3 <C> L2 <WITH> H3 <HAS> 4 6.8 <C> L3 <WITH> H3 <HAS> 4 6.0 <C> L4 <WITH> H3 <HAS> 4 6.6 <C> L5 <WITH> H3 <HAS> 4 8.0 <C> <R> <C> L0 <WITH> H4 <HAS> 4 5.7 <C> L1 <WITH> H4 <HAS> 4 6.3 <C> L2 <WITH> H4 <HAS> 4 6.5 <C> L3 <WITH> H4 <HAS> 4 7.8 <C> L4 <WITH> H4 <HAS> 4 5.1 <C> L5 <WITH> H4 <HAS> 4 7.0 <C> <R> <C> L0 <WITH> H5 <HAS> 4 7.0 <C> L1 <WITH> H5 <HAS> 4 6.5 <C> L2 <WITH> H5 <HAS> 4 6.5 <C> L3 <WITH> H5 <HAS> 4 5.6 <C> L4 <WITH> H5 <HAS> 4 6.2 <C> L5 <WITH> H5 <HAS> 5 2.9 <C> <R> <C> L0 <WITH> H6 <HAS> 4 6.7 <C> L1 <WITH> H6 <HAS> 4 5.4 <C> L2 <WITH> H6 <HAS> 4 6.4 <C> L3 <WITH> H6 <HAS> 4 5.3 <C> L4 <WITH> H6 <HAS> 4 6.9 <C> L5 <WITH> H6 <HAS> 4 7.0 <C> <R> <C> L0 <WITH> H7 <HAS> 4 3.8 <C> L1 <WITH> H7 <HAS> 4 6.6 <C> L2 <WITH> H7 <HAS> 4 6.4 <C> L3 <WITH> H7 <HAS> 5 5.0 <C> L4 <WITH> H7 <HAS> 4 6.4 <C> L5 <WITH> H7 <HAS> 4 6.2 <C> <CAP> Table 8: Coreference signal of a Transformer model on the validation dataset, by encoder attention layer and head.
 <R> <C> [EMPTY] <WITH> Transf. <HAS> Correct <C> Parallelism Correct <WITH> Transf. <HAS> 48.7% <C> Parallelism Incorrect <WITH> Transf. <HAS> 13.4% <C> <R> <C> [EMPTY] <WITH> Transf. <HAS> Incorrect <C> Parallelism Correct <WITH> Transf. <HAS> 21.6% <C> Parallelism Incorrect <WITH> Transf. <HAS> 16.3% <C> <CAP> Table 9: Comparison of the predictions of the Parallelism and Transformer-Single heuristics over the GAP development dataset.
 <R> <C> NYT10 Prec. <WITH> 1 <HAS> 0.541 <C> NYT10 Rec. <WITH> 1 <HAS> 0.595 <C> NYT10 F1 <WITH> 1 <HAS> [BOLD] 0.566 <C> NYT11 Prec. <WITH> 1 <HAS> 0.495 <C> NYT11 Rec. <WITH> 1 <HAS> 0.621 <C> NYT11 F1 <WITH> 1 <HAS> 0.551 <C> <R> <C> NYT10 Prec. <WITH> 2 <HAS> 0.521 <C> NYT10 Rec. <WITH> 2 <HAS> 0.597 <C> NYT10 F1 <WITH> 2 <HAS> 0.556 <C> NYT11 Prec. <WITH> 2 <HAS> 0.482 <C> NYT11 Rec. <WITH> 2 <HAS> 0.656 <C> NYT11 F1 <WITH> 2 <HAS> 0.555 <C> <R> <C> NYT10 Prec. <WITH> 3 <HAS> 0.490 <C> NYT10 Rec. <WITH> 3 <HAS> 0.617 <C> NYT10 F1 <WITH> 3 <HAS> 0.547 <C> NYT11 Prec. <WITH> 3 <HAS> 0.509 <C> NYT11 Rec. <WITH> 3 <HAS> 0.633 <C> NYT11 F1 <WITH> 3 <HAS> 0.564 <C> <R> <C> NYT10 Prec. <WITH> 4 <HAS> 0.449 <C> NYT10 Rec. <WITH> 4 <HAS> 0.623 <C> NYT10 F1 <WITH> 4 <HAS> 0.522 <C> NYT11 Prec. <WITH> 4 <HAS> 0.507 <C> NYT11 Rec. <WITH> 4 <HAS> 0.652 <C> NYT11 F1 <WITH> 4 <HAS> [BOLD] 0.571 <C> <R> <C> NYT10 Prec. <WITH> 5 <HAS> 0.467 <C> NYT10 Rec. <WITH> 5 <HAS> 0.609 <C> NYT10 F1 <WITH> 5 <HAS> 0.529 <C> NYT11 Prec. <WITH> 5 <HAS> 0.488 <C> NYT11 Rec. <WITH> 5 <HAS> 0.677 <C> NYT11 F1 <WITH> 5 <HAS> 0.567 <C> <CAP> Table 3: Performance comparison of our model with different values of m on the two datasets.
 <R> <C> NYT10 Prec. <WITH> CNN zeng2014relation <HAS> 0.413 <C> NYT10 Rec. <WITH> CNN zeng2014relation <HAS> 0.591 <C> NYT10 F1 <WITH> CNN zeng2014relation <HAS> 0.486 <C> NYT11 Prec. <WITH> CNN zeng2014relation <HAS> 0.444 <C> NYT11 Rec. <WITH> CNN zeng2014relation <HAS> 0.625 <C> NYT11 F1 <WITH> CNN zeng2014relation <HAS> 0.519 <C> <R> <C> NYT10 Prec. <WITH> PCNN zeng2015distant <HAS> 0.380 <C> NYT10 Rec. <WITH> PCNN zeng2015distant <HAS> [BOLD] 0.642 <C> NYT10 F1 <WITH> PCNN zeng2015distant <HAS> 0.477 <C> NYT11 Prec. <WITH> PCNN zeng2015distant <HAS> 0.446 <C> NYT11 Rec. <WITH> PCNN zeng2015distant <HAS> 0.679 <C> NYT11 F1 <WITH> PCNN zeng2015distant <HAS> 0.538† <C> <R> <C> NYT10 Prec. <WITH> EA huang2016attention <HAS> 0.443 <C> NYT10 Rec. <WITH> EA huang2016attention <HAS> 0.638 <C> NYT10 F1 <WITH> EA huang2016attention <HAS> 0.523† <C> NYT11 Prec. <WITH> EA huang2016attention <HAS> 0.419 <C> NYT11 Rec. <WITH> EA huang2016attention <HAS> 0.677 <C> NYT11 F1 <WITH> EA huang2016attention <HAS> 0.517 <C> <R> <C> NYT10 Prec. <WITH> BGWA jat2018attention <HAS> 0.364 <C> NYT10 Rec. <WITH> BGWA jat2018attention <HAS> 0.632 <C> NYT10 F1 <WITH> BGWA jat2018attention <HAS> 0.462 <C> NYT11 Prec. <WITH> BGWA jat2018attention <HAS> 0.417 <C> NYT11 Rec. <WITH> BGWA jat2018attention <HAS> [BOLD] 0.692 <C> NYT11 F1 <WITH> BGWA jat2018attention <HAS> 0.521 <C> <R> <C> NYT10 Prec. <WITH> BiLSTM-CNN <HAS> 0.490 <C> NYT10 Rec. <WITH> BiLSTM-CNN <HAS> 0.507 <C> NYT10 F1 <WITH> BiLSTM-CNN <HAS> 0.498 <C> NYT11 Prec. <WITH> BiLSTM-CNN <HAS> 0.473 <C> NYT11 Rec. <WITH> BiLSTM-CNN <HAS> 0.606 <C> NYT11 F1 <WITH> BiLSTM-CNN <HAS> 0.531 <C> <R> <C> NYT10 Prec. <WITH> Our model <HAS> [BOLD] 0.541 <C> NYT10 Rec. <WITH> Our model <HAS> 0.595 <C> NYT10 F1 <WITH> Our model <HAS> [BOLD] 0.566* <C> NYT11 Prec. <WITH> Our model <HAS> [BOLD] 0.507 <C> NYT11 Rec. <WITH> Our model <HAS> 0.652 <C> NYT11 F1 <WITH> Our model <HAS> [BOLD] 0.571* <C> <CAP> Table 2: Performance comparison of different models on the two datasets. * denotes a statistically significant improvement over the previous best state-of-the-art model with p<0.01 under the bootstrap paired t-test. † denotes the previous best state-of-the-art model.
 <R> <C> Prec. <WITH> (A1) BiLSTM-CNN <HAS> 0.473 <C> Rec. <WITH> (A1) BiLSTM-CNN <HAS> 0.606 <C> F1 <WITH> (A1) BiLSTM-CNN <HAS> 0.531 <C> <R> <C> Prec. <WITH> (A2) Standard attention <HAS> 0.466 <C> Rec. <WITH> (A2) Standard attention <HAS> 0.638 <C> F1 <WITH> (A2) Standard attention <HAS> 0.539 <C> <R> <C> Prec. <WITH> (A3) Window size ( [ITALIC] ws)=5 <HAS> 0.507 <C> Rec. <WITH> (A3) Window size ( [ITALIC] ws)=5 <HAS> 0.652 <C> F1 <WITH> (A3) Window size ( [ITALIC] ws)=5 <HAS> [BOLD] 0.571 <C> <R> <C> Prec. <WITH> (A4) Window size ( [ITALIC] ws)=10 <HAS> 0.510 <C> Rec. <WITH> (A4) Window size ( [ITALIC] ws)=10 <HAS> 0.640 <C> F1 <WITH> (A4) Window size ( [ITALIC] ws)=10 <HAS> 0.568 <C> <R> <C> Prec. <WITH> (A5) Softmax <HAS> 0.490 <C> Rec. <WITH> (A5) Softmax <HAS> 0.658 <C> F1 <WITH> (A5) Softmax <HAS> 0.562 <C> <R> <C> Prec. <WITH> (A6) Max-pool <HAS> 0.492 <C> Rec. <WITH> (A6) Max-pool <HAS> 0.600 <C> F1 <WITH> (A6) Max-pool <HAS> 0.541 <C> <CAP> Table 4: Effectiveness of model components (m=4) on the NYT11 dataset.
 <R> <C> Overall <WITH> QRC - VGG(det) <HAS> 60.21 <C> people <WITH> QRC - VGG(det) <HAS> 75.08 <C> clothing <WITH> QRC - VGG(det) <HAS> 55.9 <C> bodyparts <WITH> QRC - VGG(det) <HAS> 20.27 <C> animals <WITH> QRC - VGG(det) <HAS> 73.36 <C> vehicles <WITH> QRC - VGG(det) <HAS> 68.95 <C> instruments <WITH> QRC - VGG(det) <HAS> 45.68 <C> scene <WITH> QRC - VGG(det) <HAS> 65.27 <C> other <WITH> QRC - VGG(det) <HAS> 38.8 <C> <R> <C> Overall <WITH> CITE - VGG(det) <HAS> 61.89 <C> people <WITH> CITE - VGG(det) <HAS> [BOLD] 75.95 <C> clothing <WITH> CITE - VGG(det) <HAS> 58.50 <C> bodyparts <WITH> CITE - VGG(det) <HAS> 30.78 <C> animals <WITH> CITE - VGG(det) <HAS> [BOLD] 77.03 <C> vehicles <WITH> CITE - VGG(det) <HAS> [BOLD] 79.25 <C> instruments <WITH> CITE - VGG(det) <HAS> 48.15 <C> scene <WITH> CITE - VGG(det) <HAS> 58.78 <C> other <WITH> CITE - VGG(det) <HAS> 43.24 <C> <R> <C> Overall <WITH> ZSGNet - VGG (cls) <HAS> 60.12 <C> people <WITH> ZSGNet - VGG (cls) <HAS> 72.52 <C> clothing <WITH> ZSGNet - VGG (cls) <HAS> 60.57 <C> bodyparts <WITH> ZSGNet - VGG (cls) <HAS> 38.51 <C> animals <WITH> ZSGNet - VGG (cls) <HAS> 63.61 <C> vehicles <WITH> ZSGNet - VGG (cls) <HAS> 64.47 <C> instruments <WITH> ZSGNet - VGG (cls) <HAS> 49.59 <C> scene <WITH> ZSGNet - VGG (cls) <HAS> 64.66 <C> other <WITH> ZSGNet - VGG (cls) <HAS> 41.09 <C> <R> <C> Overall <WITH> ZSGNet - Res50 (cls) <HAS> [BOLD] 63.39 <C> people <WITH> ZSGNet - Res50 (cls) <HAS> 73.87 <C> clothing <WITH> ZSGNet - Res50 (cls) <HAS> [BOLD] 66.18 <C> bodyparts <WITH> ZSGNet - Res50 (cls) <HAS> [BOLD] 45.27 <C> animals <WITH> ZSGNet - Res50 (cls) <HAS> 73.79 <C> vehicles <WITH> ZSGNet - Res50 (cls) <HAS> 71.38 <C> instruments <WITH> ZSGNet - Res50 (cls) <HAS> [BOLD] 58.54 <C> scene <WITH> ZSGNet - Res50 (cls) <HAS> [BOLD] 66.49 <C> other <WITH> ZSGNet - Res50 (cls) <HAS> [BOLD] 45.53 <C> <CAP> Table 3: Category-wise performance with the default split of Flickr30k Entities.
 <R> <C> Net <WITH> SCRC  <HAS> VGG <C> Flickr30k <WITH> SCRC  <HAS> 27.8 <C> ReferIt <WITH> SCRC  <HAS> 17.9 <C> <R> <C> Net <WITH> GroundeR (cls)  <HAS> VGG <C> Flickr30k <WITH> GroundeR (cls)  <HAS> 42.43 <C> ReferIt <WITH> GroundeR (cls)  <HAS> 24.18 <C> <R> <C> Net <WITH> GroundeR (det)  <HAS> VGG <C> Flickr30k <WITH> GroundeR (det)  <HAS> 48.38 <C> ReferIt <WITH> GroundeR (det)  <HAS> 28.5 <C> <R> <C> Net <WITH> MCB (det)  <HAS> VGG <C> Flickr30k <WITH> MCB (det)  <HAS> 48.7 <C> ReferIt <WITH> MCB (det)  <HAS> 28.9 <C> <R> <C> Net <WITH> Li (cls)  <HAS> VGG <C> Flickr30k <WITH> Li (cls)  <HAS> - <C> ReferIt <WITH> Li (cls)  <HAS> 40 <C> <R> <C> Net <WITH> QRC* (det)  <HAS> VGG <C> Flickr30k <WITH> QRC* (det)  <HAS> 60.21 <C> ReferIt <WITH> QRC* (det)  <HAS> 44.1 <C> <R> <C> Net <WITH> CITE* (cls)  <HAS> VGG <C> Flickr30k <WITH> CITE* (cls)  <HAS> 61.89 <C> ReferIt <WITH> CITE* (cls)  <HAS> 34.13 <C> <R> <C> Net <WITH> QRG* (det) <HAS> VGG <C> Flickr30k <WITH> QRG* (det) <HAS> 60.1 <C> ReferIt <WITH> QRG* (det) <HAS> - <C> <R> <C> Net <WITH> [BOLD] ZSGNet (cls) <HAS> [BOLD] VGG <C> Flickr30k <WITH> [BOLD] ZSGNet (cls) <HAS> [BOLD] 60.12 <C> ReferIt <WITH> [BOLD] ZSGNet (cls) <HAS> [BOLD] 53.31 <C> <R> <C> Net <WITH> [BOLD] ZSGNet (cls) <HAS> [BOLD] Res50 <C> Flickr30k <WITH> [BOLD] ZSGNet (cls) <HAS> [BOLD] 63.39 <C> ReferIt <WITH> [BOLD] ZSGNet (cls) <HAS> [BOLD] 58.63 <C> <CAP> Table 2: Comparison of our model with other state of the art methods. We denote those networks which use classification weights from ImageNet [41] using “cls” and those networks which use detection weights from Pascal VOC [12] using “det”. The reported numbers are all Accuracy@IoU=0.5 or equivalently Recall@1. Models marked with “*” fine-tune their detection network on the entities in the Flickr30k.
 <R> <C> Net <WITH> QRG <HAS> VGG <C> Flickr- Split-0 <WITH> QRG <HAS> 35.62 <C> Flickr- Split-1 <WITH> QRG <HAS> 24.42 <C> VG-2B 0.3 <WITH> QRG <HAS> 13.17 <C> VG-2B 0.5 <WITH> QRG <HAS> 7.64 <C> VG-2UB 0.3 <WITH> QRG <HAS> 12.39 <C> VG-2UB 0.5 <WITH> QRG <HAS> 7.15 <C> VG-3B 0.3 <WITH> QRG <HAS> 14.21 <C> VG-3B 0.5 <WITH> QRG <HAS> 8.35 <C> VG-3UB 0.3 <WITH> QRG <HAS> 13.03 <C> VG-3UB 0.5 <WITH> QRG <HAS> 7.52 <C> <R> <C> Net <WITH> ZSGNet <HAS> VGG <C> Flickr- Split-0 <WITH> ZSGNet <HAS> 39.32 <C> Flickr- Split-1 <WITH> ZSGNet <HAS> 29.35 <C> VG-2B 0.3 <WITH> ZSGNet <HAS> 17.09 <C> VG-2B 0.5 <WITH> ZSGNet <HAS> 11.02 <C> VG-2UB 0.3 <WITH> ZSGNet <HAS> 16.48 <C> VG-2UB 0.5 <WITH> ZSGNet <HAS> 10.55 <C> VG-3B 0.3 <WITH> ZSGNet <HAS> 17.63 <C> VG-3B 0.5 <WITH> ZSGNet <HAS> 11.42 <C> VG-3UB 0.3 <WITH> ZSGNet <HAS> 17.35 <C> VG-3UB 0.5 <WITH> ZSGNet <HAS> 10.97 <C> <R> <C> Net <WITH> ZSGNet <HAS> Res50 <C> Flickr- Split-0 <WITH> ZSGNet <HAS> [BOLD] 43.02 <C> Flickr- Split-1 <WITH> ZSGNet <HAS> [BOLD] 31.23 <C> VG-2B 0.3 <WITH> ZSGNet <HAS> [BOLD] 19.95 <C> VG-2B 0.5 <WITH> ZSGNet <HAS> [BOLD] 12.90 <C> VG-2UB 0.3 <WITH> ZSGNet <HAS> [BOLD] 19.12 <C> VG-2UB 0.5 <WITH> ZSGNet <HAS> [BOLD] 12.37 <C> VG-3B 0.3 <WITH> ZSGNet <HAS> [BOLD] 20.77 <C> VG-3B 0.5 <WITH> ZSGNet <HAS> [BOLD] 13.77 <C> VG-3UB 0.3 <WITH> ZSGNet <HAS> [BOLD] 19.72 <C> VG-3UB 0.5 <WITH> ZSGNet <HAS> [BOLD] 12.82 <C> <CAP> Table 4: Accuracy across various unseen splits. For Flickr-Split-0,1 we use Accuracy with IoU threshold of 0.5. Since Visual Genome annotations are noisy we additionally report Accuracy with IoU threshold of 0.3. The second row denotes the IoU threshold at which the Accuracy is calculated. “B” and “UB” denote the balanced and unbalanced sets.
 <R> <C> Accuracy on RefClef <WITH> BM + Softmax <HAS> 48.54 <C> <R> <C> Accuracy on RefClef <WITH> BM + BCE <HAS> 55.20 <C> <R> <C> Accuracy on RefClef <WITH> BM + FL <HAS> 57.13 <C> <R> <C> Accuracy on RefClef <WITH> BM + FL + Img-Resize <HAS> [BOLD] 61.75 <C> <CAP> Table 6: Ablation study: BM=Base Model, softmax means we classify only one candidate box as foreground, BCE = Binary Cross Entropy means we classify each candidate box as the foreground or background, FL = Focal Loss, Img-Resize: use images of dimension 600×600
 <R> <C> [BOLD] Training scheme <WITH> 1 <HAS> News <C> [BOLD] News <WITH> 1 <HAS> 37.8 <C> [BOLD] TED <WITH> 1 <HAS> 25.3 <C> [BOLD] IT <WITH> 1 <HAS> 35.3 <C> <R> <C> [BOLD] Training scheme <WITH> 2 <HAS> TED <C> [BOLD] News <WITH> 2 <HAS> 23.7 <C> [BOLD] TED <WITH> 2 <HAS> 24.1 <C> [BOLD] IT <WITH> 2 <HAS> 14.4 <C> <R> <C> [BOLD] Training scheme <WITH> 3 <HAS> IT <C> [BOLD] News <WITH> 3 <HAS> 1.6 <C> [BOLD] TED <WITH> 3 <HAS> 1.8 <C> [BOLD] IT <WITH> 3 <HAS> 39.6 <C> <R> <C> [BOLD] Training scheme <WITH> 4 <HAS> News and TED <C> [BOLD] News <WITH> 4 <HAS> 38.2 <C> [BOLD] TED <WITH> 4 <HAS> 25.5 <C> [BOLD] IT <WITH> 4 <HAS> 35.4 <C> <R> <C> [BOLD] Training scheme <WITH> 5 <HAS> 1 then TED, No-reg <C> [BOLD] News <WITH> 5 <HAS> 30.6 <C> [BOLD] TED <WITH> 5 <HAS> [BOLD] 27.0 <C> [BOLD] IT <WITH> 5 <HAS> 22.1 <C> <R> <C> [BOLD] Training scheme <WITH> 6 <HAS> 1 then TED, L2 <C> [BOLD] News <WITH> 6 <HAS> 37.9 <C> [BOLD] TED <WITH> 6 <HAS> 26.7 <C> [BOLD] IT <WITH> 6 <HAS> 31.8 <C> <R> <C> [BOLD] Training scheme <WITH> 7 <HAS> 1 then TED, EWC <C> [BOLD] News <WITH> 7 <HAS> [BOLD] 38.3 <C> [BOLD] TED <WITH> 7 <HAS> [BOLD] 27.0 <C> [BOLD] IT <WITH> 7 <HAS> 33.1 <C> <R> <C> [BOLD] Training scheme <WITH> 8 <HAS> 5 then IT, No-reg <C> [BOLD] News <WITH> 8 <HAS> 8.0 <C> [BOLD] TED <WITH> 8 <HAS> 6.9 <C> [BOLD] IT <WITH> 8 <HAS> 56.3 <C> <R> <C> [BOLD] Training scheme <WITH> 9 <HAS> 6 then IT, L2 <C> [BOLD] News <WITH> 9 <HAS> 32.3 <C> [BOLD] TED <WITH> 9 <HAS> 22.6 <C> [BOLD] IT <WITH> 9 <HAS> 56.9 <C> <R> <C> [BOLD] Training scheme <WITH> 10 <HAS> 7 then IT, EWC <C> [BOLD] News <WITH> 10 <HAS> 35.8 <C> [BOLD] TED <WITH> 10 <HAS> 24.6 <C> [BOLD] IT <WITH> 10 <HAS> [BOLD] 57.0 <C> <CAP> Table 4: Test BLEU for en-de adaptive training, with sequential adaptation to a third task. EWC-tuned models give the best performance on each domain.
 <R> <C> [BOLD] Training scheme <WITH> 1 <HAS> Health <C> [BOLD] Health <WITH> 1 <HAS> [BOLD] 35.9 <C> [BOLD] Bio <WITH> 1 <HAS> 33.1 <C> <R> <C> [BOLD] Training scheme <WITH> 2 <HAS> Bio <C> [BOLD] Health <WITH> 2 <HAS> 29.6 <C> [BOLD] Bio <WITH> 2 <HAS> 36.1 <C> <R> <C> [BOLD] Training scheme <WITH> 3 <HAS> Health and Bio <C> [BOLD] Health <WITH> 3 <HAS> 35.8 <C> [BOLD] Bio <WITH> 3 <HAS> 37.2 <C> <R> <C> [BOLD] Training scheme <WITH> 4 <HAS> 1 then Bio, No-reg <C> [BOLD] Health <WITH> 4 <HAS> 30.3 <C> [BOLD] Bio <WITH> 4 <HAS> 36.6 <C> <R> <C> [BOLD] Training scheme <WITH> 5 <HAS> 1 then Bio, L2 <C> [BOLD] Health <WITH> 5 <HAS> 35.1 <C> [BOLD] Bio <WITH> 5 <HAS> 37.3 <C> <R> <C> [BOLD] Training scheme <WITH> 6 <HAS> 1 then Bio, EWC <C> [BOLD] Health <WITH> 6 <HAS> 35.2 <C> [BOLD] Bio <WITH> 6 <HAS> [BOLD] 37.8 <C> <CAP> Table 3: Test BLEU for es-en adaptive training. EWC reduces forgetting compared to other fine-tuning methods, while offering the greatest improvement on the new domain.
 <R> <C> [BOLD] es-en  [BOLD] Health <WITH> Oracle model <HAS> 35.9 <C> [BOLD] es-en  [BOLD] Bio <WITH> Oracle model <HAS> 36.1 <C> [BOLD] en-de  [BOLD] News <WITH> Oracle model <HAS> 37.8 <C> [BOLD] en-de  [BOLD] TED <WITH> Oracle model <HAS> 24.1 <C> [BOLD] en-de  [BOLD] IT <WITH> Oracle model <HAS> 39.6 <C> <R> <C> [BOLD] es-en  [BOLD] Health <WITH> Uniform <HAS> 33.1 <C> [BOLD] es-en  [BOLD] Bio <WITH> Uniform <HAS> 36.4 <C> [BOLD] en-de  [BOLD] News <WITH> Uniform <HAS> 21.9 <C> [BOLD] en-de  [BOLD] TED <WITH> Uniform <HAS> 18.4 <C> [BOLD] en-de  [BOLD] IT <WITH> Uniform <HAS> 38.9 <C> <R> <C> [BOLD] es-en  [BOLD] Health <WITH> Identity-BI <HAS> 35.0 <C> [BOLD] es-en  [BOLD] Bio <WITH> Identity-BI <HAS> 36.6 <C> [BOLD] en-de  [BOLD] News <WITH> Identity-BI <HAS> 32.7 <C> [BOLD] en-de  [BOLD] TED <WITH> Identity-BI <HAS> 25.3 <C> [BOLD] en-de  [BOLD] IT <WITH> Identity-BI <HAS> 42.6 <C> <R> <C> [BOLD] es-en  [BOLD] Health <WITH> BI <HAS> 35.9 <C> [BOLD] es-en  [BOLD] Bio <WITH> BI <HAS> 36.5 <C> [BOLD] en-de  [BOLD] News <WITH> BI <HAS> 38.0 <C> [BOLD] en-de  [BOLD] TED <WITH> BI <HAS> 26.1 <C> [BOLD] en-de  [BOLD] IT <WITH> BI <HAS> [BOLD] 44.7 <C> <R> <C> [BOLD] es-en  [BOLD] Health <WITH> IS <HAS> [BOLD] 36.0 <C> [BOLD] es-en  [BOLD] Bio <WITH> IS <HAS> 36.8 <C> [BOLD] en-de  [BOLD] News <WITH> IS <HAS> 37.5 <C> [BOLD] en-de  [BOLD] TED <WITH> IS <HAS> 25.6 <C> [BOLD] en-de  [BOLD] IT <WITH> IS <HAS> 43.3 <C> <R> <C> [BOLD] es-en  [BOLD] Health <WITH> BI + IS <HAS> [BOLD] 36.0 <C> [BOLD] es-en  [BOLD] Bio <WITH> BI + IS <HAS> [BOLD] 36.9 <C> [BOLD] en-de  [BOLD] News <WITH> BI + IS <HAS> [BOLD] 38.4 <C> [BOLD] en-de  [BOLD] TED <WITH> BI + IS <HAS> [BOLD] 26.4 <C> [BOLD] en-de  [BOLD] IT <WITH> BI + IS <HAS> [BOLD] 44.7 <C> <CAP> Table 5: Test BLEU for 2-model es-en and 3-model en-de unadapted model ensembling, compared to oracle unadapted model chosen if test domain is known. Uniform ensembling generally underperforms the oracle, while BI+IS outperforms the oracle.
 <R> <C> [BOLD] es-en  [BOLD] Health <WITH> Oracle model <HAS> 35.9 <C> [BOLD] es-en  [BOLD] Bio <WITH> Oracle model <HAS> 37.8 <C> [BOLD] en-de  [BOLD] News <WITH> Oracle model <HAS> 37.8 <C> [BOLD] en-de  [BOLD] TED <WITH> Oracle model <HAS> 27.0 <C> [BOLD] en-de  [BOLD] IT <WITH> Oracle model <HAS> 57.0 <C> <R> <C> [BOLD] es-en  [BOLD] Health <WITH> Uniform <HAS> 36.0 <C> [BOLD] es-en  [BOLD] Bio <WITH> Uniform <HAS> 36.4 <C> [BOLD] en-de  [BOLD] News <WITH> Uniform <HAS> [BOLD] 38.9 <C> [BOLD] en-de  [BOLD] TED <WITH> Uniform <HAS> 26.0 <C> [BOLD] en-de  [BOLD] IT <WITH> Uniform <HAS> 43.5 <C> <R> <C> [BOLD] es-en  [BOLD] Health <WITH> BI + IS <HAS> [BOLD] 36.2 <C> [BOLD] es-en  [BOLD] Bio <WITH> BI + IS <HAS> [BOLD] 38.0 <C> [BOLD] en-de  [BOLD] News <WITH> BI + IS <HAS> 38.7 <C> [BOLD] en-de  [BOLD] TED <WITH> BI + IS <HAS> [BOLD] 26.1 <C> [BOLD] en-de  [BOLD] IT <WITH> BI + IS <HAS> [BOLD] 56.4 <C> <CAP> Table 6: Test BLEU for 2-model es-en and 3-model en-de model ensembling for models adapted with EWC, compared to oracle model last trained on each domain, chosen if test domain is known. BI+IS outperforms uniform ensembling and in some cases outperforms the oracle.
 <R> <C> [BOLD] Model type <WITH> es-en <HAS> Unadapted <C> [BOLD] Oracle model <WITH> es-en <HAS> 36.4 <C> [BOLD] Decoder configuration  [BOLD] Uniform <WITH> es-en <HAS> 34.7 <C> [BOLD] Decoder configuration  [BOLD] BI + IS <WITH> es-en <HAS> 36.6 <C> <R> <C> [BOLD] Model type <WITH> es-en <HAS> No-reg <C> [BOLD] Oracle model <WITH> es-en <HAS> 36.6 <C> [BOLD] Decoder configuration  [BOLD] Uniform <WITH> es-en <HAS> 34.8 <C> [BOLD] Decoder configuration  [BOLD] BI + IS <WITH> es-en <HAS> - <C> <R> <C> [BOLD] Model type <WITH> es-en <HAS> EWC <C> [BOLD] Oracle model <WITH> es-en <HAS> 37.0 <C> [BOLD] Decoder configuration  [BOLD] Uniform <WITH> es-en <HAS> 36.3 <C> [BOLD] Decoder configuration  [BOLD] BI + IS <WITH> es-en <HAS> [BOLD] 37.2 <C> <R> <C> [BOLD] Model type <WITH> en-de <HAS> Unadapted <C> [BOLD] Oracle model <WITH> en-de <HAS> 36.4 <C> [BOLD] Decoder configuration  [BOLD] Uniform <WITH> en-de <HAS> 26.8 <C> [BOLD] Decoder configuration  [BOLD] BI + IS <WITH> en-de <HAS> 38.8 <C> <R> <C> [BOLD] Model type <WITH> en-de <HAS> No-reg <C> [BOLD] Oracle model <WITH> en-de <HAS> 41.7 <C> [BOLD] Decoder configuration  [BOLD] Uniform <WITH> en-de <HAS> 31.8 <C> [BOLD] Decoder configuration  [BOLD] BI + IS <WITH> en-de <HAS> - <C> <R> <C> [BOLD] Model type <WITH> en-de <HAS> EWC <C> [BOLD] Oracle model <WITH> en-de <HAS> 42.1 <C> [BOLD] Decoder configuration  [BOLD] Uniform <WITH> en-de <HAS> 38.6 <C> [BOLD] Decoder configuration  [BOLD] BI + IS <WITH> en-de <HAS> [BOLD] 42.0 <C> <CAP> Table 7: Total BLEU for test data concatenated across domains. Results from 2-model es-en and 3-model en-de ensembles, compared to oracle model chosen if test domain is known. No-reg uniform corresponds to the approach of Freitag and Al-Onaizan (2016). BI+IS performs similarly to strong oracles with no test domain labeling.
 <R> <C> [BOLD] Prec.(%) <WITH> EL <HAS> 96.02 <C> [BOLD] Rec.(%) <WITH> EL <HAS> 81.89 <C> [BOLD] F1(%) <WITH> EL <HAS> 88.39 <C> <R> <C> [BOLD] Prec.(%) <WITH> CMP <HAS> 86.39 <C> [BOLD] Rec.(%) <WITH> CMP <HAS> [BOLD] 88.64 <C> [BOLD] F1(%) <WITH> CMP <HAS> 87.50 <C> <R> <C> [BOLD] Prec.(%) <WITH> Hybrid-EL-CMP1 <HAS> [BOLD] 97.42 <C> [BOLD] Rec.(%) <WITH> Hybrid-EL-CMP1 <HAS> 84.70 <C> [BOLD] F1(%) <WITH> Hybrid-EL-CMP1 <HAS> 90.62 <C> <R> <C> [BOLD] Prec.(%) <WITH> Hybrid-EL-CMP2 <HAS> 95.82 <C> [BOLD] Rec.(%) <WITH> Hybrid-EL-CMP2 <HAS> 86.42 <C> [BOLD] F1(%) <WITH> Hybrid-EL-CMP2 <HAS> [BOLD] 90.87 <C> <CAP> Table 8: Semantic role labeling results. Hybrid-EL-CMP1 represents rule-based model and Hybrid-EL-CMP2 represents probability-based model.
 <R> <C> [BOLD] Prec.(%) <WITH> Max Logits <HAS> 80.19 <C> [BOLD] Rec.(%) <WITH> Max Logits <HAS> 80.50 <C> [BOLD] F1(%) <WITH> Max Logits <HAS> 79.85 <C> <R> <C> [BOLD] Prec.(%) <WITH> Add Logits <HAS> 81.30 <C> [BOLD] Rec.(%) <WITH> Add Logits <HAS> 81.28 <C> [BOLD] F1(%) <WITH> Add Logits <HAS> 80.85 <C> <R> <C> [BOLD] Prec.(%) <WITH> Add Logits+Expert <HAS> [BOLD] 81.30 <C> [BOLD] Rec.(%) <WITH> Add Logits+Expert <HAS> [BOLD] 81.41 <C> [BOLD] F1(%) <WITH> Add Logits+Expert <HAS> [BOLD] 80.90 <C> <R> <C> [BOLD] Prec.(%) <WITH> Concat Hidden <HAS> 80.24 <C> [BOLD] Rec.(%) <WITH> Concat Hidden <HAS> 80.04 <C> [BOLD] F1(%) <WITH> Concat Hidden <HAS> 79.65 <C> <R> <C> [BOLD] Prec.(%) <WITH> Max Hidden <HAS> 80.30 <C> [BOLD] Rec.(%) <WITH> Max Hidden <HAS> 80.04 <C> [BOLD] F1(%) <WITH> Max Hidden <HAS> 79.63 <C> <R> <C> [BOLD] Prec.(%) <WITH> Add Hidden <HAS> 80.82 <C> [BOLD] Rec.(%) <WITH> Add Hidden <HAS> 80.28 <C> [BOLD] F1(%) <WITH> Add Hidden <HAS> 80.08 <C> <CAP> Table 6: Dialog act prediction performance using different selection methods.
 <R> <C> MAP <WITH> CNN + LR (unigram) <HAS> 54.70 <C> MRR <WITH> CNN + LR (unigram) <HAS> 63.29 <C> <R> <C> MAP <WITH> CNN + LR (bigram) <HAS> 56.93 <C> MRR <WITH> CNN + LR (bigram) <HAS> 66.13 <C> <R> <C> MAP <WITH> CNN <HAS> 66.91 <C> MRR <WITH> CNN <HAS> 68.80 <C> <R> <C> MAP <WITH> CNTN <HAS> 65.80 <C> MRR <WITH> CNTN <HAS> 69.78 <C> <R> <C> MAP <WITH> LSTM (1 layer) <HAS> 62.04 <C> MRR <WITH> LSTM (1 layer) <HAS> 66.85 <C> <R> <C> MAP <WITH> LSTM <HAS> 59.75 <C> MRR <WITH> LSTM <HAS> 65.33 <C> <R> <C> MAP <WITH> MV-LSTM <HAS> 64.88 <C> MRR <WITH> MV-LSTM <HAS> 68.24 <C> <R> <C> MAP <WITH> NTN-LSTM <HAS> 63.40 <C> MRR <WITH> NTN-LSTM <HAS> 67.72 <C> <R> <C> MAP <WITH> HD-LSTM <HAS> 67.44 <C> MRR <WITH> HD-LSTM <HAS> <bold>75.11</bold> <C> <R> <C> MAP <WITH> Capsule-Zhao <HAS> 73.63 <C> MRR <WITH> Capsule-Zhao <HAS> 70.12 <C> <R> <C> MAP <WITH> NLP-Capsule <HAS> <bold>77.73</bold> <C> MRR <WITH> NLP-Capsule <HAS> 74.16 <C> <CAP> Table 6: Experimental results on TREC QA dataset.
 <R> <C> <bold>Metrics</bold> <WITH> RCV1 <HAS> PREC@1 <C> <bold>FastXML</bold> <WITH> RCV1 <HAS> 94.62 <C> <bold>PD-Sparse</bold> <WITH> RCV1 <HAS> 95.16 <C> <bold>FastText</bold> <WITH> RCV1 <HAS> 95.40 <C> <bold>Bow-CNN</bold> <WITH> RCV1 <HAS> 96.40 <C> <bold>CNN-Kim</bold> <WITH> RCV1 <HAS> 93.54 <C> <bold>XML-CNN</bold> <WITH> RCV1 <HAS> 96.86 <C> <bold>Cap-Zhao</bold> <WITH> RCV1 <HAS> 96.63 <C> <bold>NLP-Cap</bold> <WITH> RCV1 <HAS> <bold>97.05</bold> <C> <bold>Impv</bold> <WITH> RCV1 <HAS> +0.20% <C> <R> <C> <bold>Metrics</bold> <WITH> RCV1 <HAS> PREC@3 <C> <bold>FastXML</bold> <WITH> RCV1 <HAS> 78.40 <C> <bold>PD-Sparse</bold> <WITH> RCV1 <HAS> 79.46 <C> <bold>FastText</bold> <WITH> RCV1 <HAS> 79.96 <C> <bold>Bow-CNN</bold> <WITH> RCV1 <HAS> 81.17 <C> <bold>CNN-Kim</bold> <WITH> RCV1 <HAS> 76.15 <C> <bold>XML-CNN</bold> <WITH> RCV1 <HAS> 81.11 <C> <bold>Cap-Zhao</bold> <WITH> RCV1 <HAS> 81.02 <C> <bold>NLP-Cap</bold> <WITH> RCV1 <HAS> <bold>81.27</bold> <C> <bold>Impv</bold> <WITH> RCV1 <HAS> +0.20% <C> <R> <C> <bold>Metrics</bold> <WITH> RCV1 <HAS> PREC@5 <C> <bold>FastXML</bold> <WITH> RCV1 <HAS> 54.82 <C> <bold>PD-Sparse</bold> <WITH> RCV1 <HAS> 55.61 <C> <bold>FastText</bold> <WITH> RCV1 <HAS> 55.64 <C> <bold>Bow-CNN</bold> <WITH> RCV1 <HAS> <bold>56.74</bold> <C> <bold>CNN-Kim</bold> <WITH> RCV1 <HAS> 52.94 <C> <bold>XML-CNN</bold> <WITH> RCV1 <HAS> 56.07 <C> <bold>Cap-Zhao</bold> <WITH> RCV1 <HAS> 56.12 <C> <bold>NLP-Cap</bold> <WITH> RCV1 <HAS> 56.33 <C> <bold>Impv</bold> <WITH> RCV1 <HAS> -0.72% <C> <R> <C> <bold>Metrics</bold> <WITH> [EMPTY] <HAS> NDCG@1 <C> <bold>FastXML</bold> <WITH> [EMPTY] <HAS> 94.62 <C> <bold>PD-Sparse</bold> <WITH> [EMPTY] <HAS> 95.16 <C> <bold>FastText</bold> <WITH> [EMPTY] <HAS> 95.40 <C> <bold>Bow-CNN</bold> <WITH> [EMPTY] <HAS> 96.40 <C> <bold>CNN-Kim</bold> <WITH> [EMPTY] <HAS> 93.54 <C> <bold>XML-CNN</bold> <WITH> [EMPTY] <HAS> 96.88 <C> <bold>Cap-Zhao</bold> <WITH> [EMPTY] <HAS> 96.63 <C> <bold>NLP-Cap</bold> <WITH> [EMPTY] <HAS> <bold>97.05</bold> <C> <bold>Impv</bold> <WITH> [EMPTY] <HAS> +0.20% <C> <R> <C> <bold>Metrics</bold> <WITH> [EMPTY] <HAS> NDCG@3 <C> <bold>FastXML</bold> <WITH> [EMPTY] <HAS> 89.21 <C> <bold>PD-Sparse</bold> <WITH> [EMPTY] <HAS> 90.29 <C> <bold>FastText</bold> <WITH> [EMPTY] <HAS> 90.95 <C> <bold>Bow-CNN</bold> <WITH> [EMPTY] <HAS> 92.04 <C> <bold>CNN-Kim</bold> <WITH> [EMPTY] <HAS> 87.26 <C> <bold>XML-CNN</bold> <WITH> [EMPTY] <HAS> 92.22 <C> <bold>Cap-Zhao</bold> <WITH> [EMPTY] <HAS> 92.31 <C> <bold>NLP-Cap</bold> <WITH> [EMPTY] <HAS> <bold>92.47</bold> <C> <bold>Impv</bold> <WITH> [EMPTY] <HAS> +0.17% <C> <R> <C> <bold>Metrics</bold> <WITH> [EMPTY] <HAS> NDCG@5 <C> <bold>FastXML</bold> <WITH> [EMPTY] <HAS> 90.27 <C> <bold>PD-Sparse</bold> <WITH> [EMPTY] <HAS> 91.29 <C> <bold>FastText</bold> <WITH> [EMPTY] <HAS> 91.68 <C> <bold>Bow-CNN</bold> <WITH> [EMPTY] <HAS> 92.89 <C> <bold>CNN-Kim</bold> <WITH> [EMPTY] <HAS> 88.20 <C> <bold>XML-CNN</bold> <WITH> [EMPTY] <HAS> 92.63 <C> <bold>Cap-Zhao</bold> <WITH> [EMPTY] <HAS> 92.75 <C> <bold>NLP-Cap</bold> <WITH> [EMPTY] <HAS> <bold>93.11</bold> <C> <bold>Impv</bold> <WITH> [EMPTY] <HAS> +0.52% <C> <R> <C> <bold>Metrics</bold> <WITH> EUR-Lex <HAS> PREC@1 <C> <bold>FastXML</bold> <WITH> EUR-Lex <HAS> 68.12 <C> <bold>PD-Sparse</bold> <WITH> EUR-Lex <HAS> 72.10 <C> <bold>FastText</bold> <WITH> EUR-Lex <HAS> 71.51 <C> <bold>Bow-CNN</bold> <WITH> EUR-Lex <HAS> 64.99 <C> <bold>CNN-Kim</bold> <WITH> EUR-Lex <HAS> 68.35 <C> <bold>XML-CNN</bold> <WITH> EUR-Lex <HAS> 75.65 <C> <bold>Cap-Zhao</bold> <WITH> EUR-Lex <HAS> - <C> <bold>NLP-Cap</bold> <WITH> EUR-Lex <HAS> <bold>80.20</bold> <C> <bold>Impv</bold> <WITH> EUR-Lex <HAS> +6.01% <C> <R> <C> <bold>Metrics</bold> <WITH> EUR-Lex <HAS> PREC@3 <C> <bold>FastXML</bold> <WITH> EUR-Lex <HAS> 57.93 <C> <bold>PD-Sparse</bold> <WITH> EUR-Lex <HAS> 57.74 <C> <bold>FastText</bold> <WITH> EUR-Lex <HAS> 60.37 <C> <bold>Bow-CNN</bold> <WITH> EUR-Lex <HAS> 51.68 <C> <bold>CNN-Kim</bold> <WITH> EUR-Lex <HAS> 54.45 <C> <bold>XML-CNN</bold> <WITH> EUR-Lex <HAS> 61.81 <C> <bold>Cap-Zhao</bold> <WITH> EUR-Lex <HAS> - <C> <bold>NLP-Cap</bold> <WITH> EUR-Lex <HAS> <bold>65.48</bold> <C> <bold>Impv</bold> <WITH> EUR-Lex <HAS> +5.93% <C> <R> <C> <bold>Metrics</bold> <WITH> EUR-Lex <HAS> PREC@5 <C> <bold>FastXML</bold> <WITH> EUR-Lex <HAS> 48.97 <C> <bold>PD-Sparse</bold> <WITH> EUR-Lex <HAS> 47.48 <C> <bold>FastText</bold> <WITH> EUR-Lex <HAS> 50.41 <C> <bold>Bow-CNN</bold> <WITH> EUR-Lex <HAS> 42.32 <C> <bold>CNN-Kim</bold> <WITH> EUR-Lex <HAS> 44.07 <C> <bold>XML-CNN</bold> <WITH> EUR-Lex <HAS> 50.90 <C> <bold>Cap-Zhao</bold> <WITH> EUR-Lex <HAS> - <C> <bold>NLP-Cap</bold> <WITH> EUR-Lex <HAS> <bold>52.83</bold> <C> <bold>Impv</bold> <WITH> EUR-Lex <HAS> +3.79% <C> <R> <C> <bold>Metrics</bold> <WITH> [EMPTY] <HAS> NDCG@1 <C> <bold>FastXML</bold> <WITH> [EMPTY] <HAS> 68.12 <C> <bold>PD-Sparse</bold> <WITH> [EMPTY] <HAS> 72.10 <C> <bold>FastText</bold> <WITH> [EMPTY] <HAS> 71.51 <C> <bold>Bow-CNN</bold> <WITH> [EMPTY] <HAS> 64.99 <C> <bold>CNN-Kim</bold> <WITH> [EMPTY] <HAS> 68.35 <C> <bold>XML-CNN</bold> <WITH> [EMPTY] <HAS> 75.65 <C> <bold>Cap-Zhao</bold> <WITH> [EMPTY] <HAS> - <C> <bold>NLP-Cap</bold> <WITH> [EMPTY] <HAS> <bold>80.20</bold> <C> <bold>Impv</bold> <WITH> [EMPTY] <HAS> +6.01% <C> <R> <C> <bold>Metrics</bold> <WITH> [EMPTY] <HAS> NDCG@3 <C> <bold>FastXML</bold> <WITH> [EMPTY] <HAS> 60.66 <C> <bold>PD-Sparse</bold> <WITH> [EMPTY] <HAS> 61.33 <C> <bold>FastText</bold> <WITH> [EMPTY] <HAS> 63.32 <C> <bold>Bow-CNN</bold> <WITH> [EMPTY] <HAS> 55.03 <C> <bold>CNN-Kim</bold> <WITH> [EMPTY] <HAS> 59.81 <C> <bold>XML-CNN</bold> <WITH> [EMPTY] <HAS> 66.71 <C> <bold>Cap-Zhao</bold> <WITH> [EMPTY] <HAS> - <C> <bold>NLP-Cap</bold> <WITH> [EMPTY] <HAS> <bold>71.11</bold> <C> <bold>Impv</bold> <WITH> [EMPTY] <HAS> +6.59% <C> <R> <C> <bold>Metrics</bold> <WITH> [EMPTY] <HAS> NDCG@5 <C> <bold>FastXML</bold> <WITH> [EMPTY] <HAS> 56.42 <C> <bold>PD-Sparse</bold> <WITH> [EMPTY] <HAS> 55.93 <C> <bold>FastText</bold> <WITH> [EMPTY] <HAS> 58.56 <C> <bold>Bow-CNN</bold> <WITH> [EMPTY] <HAS> 49.92 <C> <bold>CNN-Kim</bold> <WITH> [EMPTY] <HAS> 57.99 <C> <bold>XML-CNN</bold> <WITH> [EMPTY] <HAS> 64.45 <C> <bold>Cap-Zhao</bold> <WITH> [EMPTY] <HAS> - <C> <bold>NLP-Cap</bold> <WITH> [EMPTY] <HAS> <bold>68.80</bold> <C> <bold>Impv</bold> <WITH> [EMPTY] <HAS> +6.75% <C> <CAP> Table 2: Comparisons of our NLP-Cap approach and baselines on two text classification benchmarks, where ’-’ denotes methods that failed to scale due to memory issues.
 <R> <C> [BOLD] Train <WITH> [BOLD] Suggestion <HAS> 2085 <C> [BOLD] Trial <WITH> [BOLD] Suggestion <HAS> 296 <C> <R> <C> [BOLD] Train <WITH> [BOLD] Non Suggestion <HAS> 6415 <C> [BOLD] Trial <WITH> [BOLD] Non Suggestion <HAS> 296 <C> <CAP> Table 1: Dataset Distribution for Sub Task A - Task 9: Suggestion Mining from Online Reviews.
 <R> <C> [BOLD] F1 (train) <WITH> [BOLD] Multinomial Naive Bayes (using Count Vectorizer) <HAS> 0.641 <C> [BOLD] F1 (test) <WITH> [BOLD] Multinomial Naive Bayes (using Count Vectorizer) <HAS> 0.517 <C> <R> <C> [BOLD] F1 (train) <WITH> [BOLD] Logistic Regression (using Count Vectorizer) <HAS> 0.679 <C> [BOLD] F1 (test) <WITH> [BOLD] Logistic Regression (using Count Vectorizer) <HAS> 0.572 <C> <R> <C> [BOLD] F1 (train) <WITH> [BOLD] SVM (Linear Kernel) (using TfIdf Vectorizer) <HAS> 0.695 <C> [BOLD] F1 (test) <WITH> [BOLD] SVM (Linear Kernel) (using TfIdf Vectorizer) <HAS> 0.576 <C> <R> <C> [BOLD] F1 (train) <WITH> [BOLD] LSTM (128 LSTM Units) <HAS> 0.731 <C> [BOLD] F1 (test) <WITH> [BOLD] LSTM (128 LSTM Units) <HAS> 0.591 <C> <R> <C> [BOLD] F1 (train) <WITH> [BOLD] Provided Baseline <HAS> 0.720 <C> [BOLD] F1 (test) <WITH> [BOLD] Provided Baseline <HAS> 0.267 <C> <R> <C> [BOLD] F1 (train) <WITH> [BOLD] ULMFit* <HAS> 0.861 <C> [BOLD] F1 (test) <WITH> [BOLD] ULMFit* <HAS> 0.701 <C> <CAP> Table 3: Performance of different models on the provided train and test dataset for Sub Task A.
 <R> <C> [BOLD] Team Name <WITH> [BOLD] 1 <HAS> OleNet <C> [BOLD] Performance (F1) <WITH> [BOLD] 1 <HAS> 0.7812 <C> <R> <C> [BOLD] Team Name <WITH> [BOLD] 2 <HAS> ThisIsCompetition <C> [BOLD] Performance (F1) <WITH> [BOLD] 2 <HAS> 0.7778 <C> <R> <C> [BOLD] Team Name <WITH> [BOLD] 3 <HAS> m_y <C> [BOLD] Performance (F1) <WITH> [BOLD] 3 <HAS> 0.7761 <C> <R> <C> [BOLD] Team Name <WITH> [BOLD] 4 <HAS> yimmon <C> [BOLD] Performance (F1) <WITH> [BOLD] 4 <HAS> 0.7629 <C> <R> <C> [BOLD] Team Name <WITH> [BOLD] 5 <HAS> NTUA-ISLab <C> [BOLD] Performance (F1) <WITH> [BOLD] 5 <HAS> 0.7488 <C> <R> <C> [BOLD] Team Name <WITH> [BOLD] 10 <HAS> [BOLD] MIDAS (our team) <C> [BOLD] Performance (F1) <WITH> [BOLD] 10 <HAS> [BOLD] 0.7011* <C> <CAP> Table 4: Best performing models for SemEval Task 9: Sub Task A.
 <R> <C> Training Data <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> simulated <C> Test WER (%) simulated <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> 26.1 <C> Test WER (%) real <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> 25.2 <C> <R> <C> Training Data <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> real <C> Test WER (%) simulated <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> 37.3 <C> Test WER (%) real <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> 35.2 <C> <R> <C> Training Data <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> simulated + real <C> Test WER (%) simulated <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> 25.9 <C> Test WER (%) real <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> 24.7 <C> <R> <C> Training Data <WITH> FSEGAN <HAS> simulated <C> Test WER (%) simulated <WITH> FSEGAN <HAS> 29.1 <C> Test WER (%) real <WITH> FSEGAN <HAS> 29.6 <C> <CAP> TABLE III: WERs (%) of obtained using different training data of CHiME-4
 <R> <C> WER (%) <WITH> No enhancement <HAS> 17.3 <C> DCE <WITH> No enhancement <HAS> 0.828 <C> <R> <C> WER (%) <WITH> Wiener filter <HAS> 19.5 <C> DCE <WITH> Wiener filter <HAS> 0.722 <C> <R> <C> WER (%) <WITH> Minimizing DCE <HAS> 15.8 <C> DCE <WITH> Minimizing DCE <HAS> [BOLD] 0.269 <C> <R> <C> WER (%) <WITH> FSEGAN <HAS> 14.9 <C> DCE <WITH> FSEGAN <HAS> 0.291 <C> <R> <C> WER (%) <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=0) <HAS> 15.6 <C> DCE <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=0) <HAS> 0.330 <C> <R> <C> WER (%) <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> [BOLD] 14.4 <C> DCE <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> 0.303 <C> <R> <C> WER (%) <WITH> Clean speech <HAS> 5.7 <C> DCE <WITH> Clean speech <HAS> 0.0 <C> <CAP> TABLE I: WERs (%) and DCE of different speech enhancement methods on Librispeech + DEMAND test set
 <R> <C> WER (%) <WITH> No enhancement <HAS> 38.4 <C> DCE <WITH> No enhancement <HAS> 0.958 <C> <R> <C> WER (%) <WITH> Wiener filter <HAS> 41.0 <C> DCE <WITH> Wiener filter <HAS> 0.775 <C> <R> <C> WER (%) <WITH> Minimizing DCE <HAS> 31.1 <C> DCE <WITH> Minimizing DCE <HAS> [BOLD] 0.392 <C> <R> <C> WER (%) <WITH> FSEGAN <HAS> 29.1 <C> DCE <WITH> FSEGAN <HAS> 0.421 <C> <R> <C> WER (%) <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=0) <HAS> 27.7 <C> DCE <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=0) <HAS> 0.476 <C> <R> <C> WER (%) <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> [BOLD] 26.1 <C> DCE <WITH> AAS ( [ITALIC] wAC=1, [ITALIC] wAD=105) <HAS> 0.462 <C> <R> <C> WER (%) <WITH> Clean speech <HAS> 9.3 <C> DCE <WITH> Clean speech <HAS> 0.0 <C> <CAP> TABLE II: WERs (%) and DCE of different speech enhancement methods on CHiME4-simulated test set
 <R> <C> Accuracy <WITH> Local <HAS> 56.25% <C> Precision <WITH> Local <HAS> 37.17% <C> Recall <WITH> Local <HAS> 55.71% <C> F-Measure <WITH> Local <HAS> 44.33% <C> <R> <C> Accuracy <WITH> Manual <HAS> 65.00% <C> Precision <WITH> Manual <HAS> 47.82% <C> Recall <WITH> Manual <HAS> [BOLD] 55.77% <C> F-Measure <WITH> Manual <HAS> 50.63% <C> <R> <C> Accuracy <WITH> Wiki <HAS> 63.25% <C> Precision <WITH> Wiki <HAS> 42.07% <C> Recall <WITH> Wiki <HAS> 46.67% <C> F-Measure <WITH> Wiki <HAS> 44.00% <C> <R> <C> Accuracy <WITH> Local-Manual <HAS> 64.50% <C> Precision <WITH> Local-Manual <HAS> 46.90% <C> Recall <WITH> Local-Manual <HAS> 51.86% <C> F-Measure <WITH> Local-Manual <HAS> 48.47% <C> <R> <C> Accuracy <WITH> Wiki-Manual <HAS> 62.25% <C> Precision <WITH> Wiki-Manual <HAS> 43.56% <C> Recall <WITH> Wiki-Manual <HAS> 52.63% <C> F-Measure <WITH> Wiki-Manual <HAS> 46.93% <C> <R> <C> Accuracy <WITH> Wiki-Manual <HAS> [BOLD] 68.75%∗∗∗ <C> Precision <WITH> Wiki-Manual <HAS> 51.04% <C> Recall <WITH> Wiki-Manual <HAS> 54.29% <C> F-Measure <WITH> Wiki-Manual <HAS> [BOLD] 52.20%∗∗ <C> <R> <C> Accuracy <WITH> [ITALIC] Our Approach <HAS> 68.50% <C> Precision <WITH> [ITALIC] Our Approach <HAS> [BOLD] 51.39%∗∗∗ <C> Recall <WITH> [ITALIC] Our Approach <HAS> 52.76% <C> F-Measure <WITH> [ITALIC] Our Approach <HAS> 51.62% <C> <CAP> TABLE IV: Results investigating RQ1 on the Nepal and Kerala datasets. (b) Kerala
 <R> <C> Unlabeled / Labeled Messages <WITH> Nepal <HAS> 6,063/400 <C> Urgent / Non-urgent Messages <WITH> Nepal <HAS> 201/199 <C> Unique Tokens <WITH> Nepal <HAS> 1,641 <C> Avg. Tokens / Message <WITH> Nepal <HAS> 14 <C> Time Range <WITH> Nepal <HAS> 04/05/2015-05/06/2015 <C> <R> <C> Unlabeled / Labeled Messages <WITH> Macedonia <HAS> 0/205 <C> Urgent / Non-urgent Messages <WITH> Macedonia <HAS> 92/113 <C> Unique Tokens <WITH> Macedonia <HAS> 129 <C> Avg. Tokens / Message <WITH> Macedonia <HAS> 18 <C> Time Range <WITH> Macedonia <HAS> 09/18/2018-09/21/2018 <C> <R> <C> Unlabeled / Labeled Messages <WITH> Kerala <HAS> 92,046/400 <C> Urgent / Non-urgent Messages <WITH> Kerala <HAS> 125/275 <C> Unique Tokens <WITH> Kerala <HAS> 19,393 <C> Avg. Tokens / Message <WITH> Kerala <HAS> 15 <C> Time Range <WITH> Kerala <HAS> 08/17/2018-08/22/2018 <C> <CAP> TABLE II: Details on datasets used for experiments.
 <R> <C> Accuracy <WITH> Local <HAS> 63.97% <C> Precision <WITH> Local <HAS> 64.27% <C> Recall <WITH> Local <HAS> 64.50% <C> F-Measure <WITH> Local <HAS> 63.93% <C> <R> <C> Accuracy <WITH> Manual <HAS> 64.25% <C> Precision <WITH> Manual <HAS> [BOLD] 70.84%∗∗ <C> Recall <WITH> Manual <HAS> 48.50% <C> F-Measure <WITH> Manual <HAS> 57.11% <C> <R> <C> Accuracy <WITH> Wiki <HAS> 67.25% <C> Precision <WITH> Wiki <HAS> 66.51% <C> Recall <WITH> Wiki <HAS> 69.50% <C> F-Measure <WITH> Wiki <HAS> 67.76% <C> <R> <C> Accuracy <WITH> Local-Manual <HAS> 65.75% <C> Precision <WITH> Local-Manual <HAS> 67.96% <C> Recall <WITH> Local-Manual <HAS> 59.50% <C> F-Measure <WITH> Local-Manual <HAS> 62.96% <C> <R> <C> Accuracy <WITH> Wiki-Local <HAS> 67.40% <C> Precision <WITH> Wiki-Local <HAS> 65.54% <C> Recall <WITH> Wiki-Local <HAS> 68.50% <C> F-Measure <WITH> Wiki-Local <HAS> 66.80% <C> <R> <C> Accuracy <WITH> Wiki-Manual <HAS> 67.75% <C> Precision <WITH> Wiki-Manual <HAS> 70.38% <C> Recall <WITH> Wiki-Manual <HAS> 63.00% <C> F-Measure <WITH> Wiki-Manual <HAS> 65.79% <C> <R> <C> Accuracy <WITH> [ITALIC] Our Approach <HAS> [BOLD] 69.25%∗∗∗ <C> Precision <WITH> [ITALIC] Our Approach <HAS> 68.76% <C> Recall <WITH> [ITALIC] Our Approach <HAS> [BOLD] 70.50%∗∗ <C> F-Measure <WITH> [ITALIC] Our Approach <HAS> [BOLD] 69.44%∗∗∗ <C> <CAP> TABLE IV: Results investigating RQ1 on the Nepal and Kerala datasets. (a) Nepal
 <R> <C> Accuracy <WITH> Local <HAS> 58.76% <C> Precision <WITH> Local <HAS> 52.96% <C> Recall <WITH> Local <HAS> 59.19% <C> F-Measure <WITH> Local <HAS> 54.95% <C> <R> <C> Accuracy <WITH> Transform <HAS> 58.62% <C> Precision <WITH> Transform <HAS> 51.40% <C> Recall <WITH> Transform <HAS> [BOLD] 60.32%∗ <C> F-Measure <WITH> Transform <HAS> 55.34% <C> <R> <C> Accuracy <WITH> Upsample <HAS> 59.38% <C> Precision <WITH> Upsample <HAS> 52.35% <C> Recall <WITH> Upsample <HAS> 57.58% <C> F-Measure <WITH> Upsample <HAS> 54.76% <C> <R> <C> Accuracy <WITH> [ITALIC] Our Approach <HAS> [BOLD] 61.79%∗ <C> Precision <WITH> [ITALIC] Our Approach <HAS> [BOLD] 55.08% <C> Recall <WITH> [ITALIC] Our Approach <HAS> 59.19% <C> F-Measure <WITH> [ITALIC] Our Approach <HAS> [BOLD] 56.90% <C> <CAP> TABLE V: Results investigating RQ2 using the Nepal dataset as source and Macedonia dataset as target.
 <R> <C> Accuracy <WITH> Local <HAS> 58.76% <C> Precision <WITH> Local <HAS> 52.96% <C> Recall <WITH> Local <HAS> 59.19% <C> F-Measure <WITH> Local <HAS> 54.95% <C> <R> <C> Accuracy <WITH> Transform <HAS> 62.07% <C> Precision <WITH> Transform <HAS> 55.45% <C> Recall <WITH> Transform <HAS> 64.52% <C> F-Measure <WITH> Transform <HAS> 59.09% <C> <R> <C> Accuracy <WITH> Upsample <HAS> [BOLD] 64.90%∗∗∗ <C> Precision <WITH> Upsample <HAS> [BOLD] 57.98%∗ <C> Recall <WITH> Upsample <HAS> [BOLD] 65.48%∗∗∗ <C> F-Measure <WITH> Upsample <HAS> [BOLD] 61.30%∗∗∗ <C> <R> <C> Accuracy <WITH> [ITALIC] Our Approach <HAS> 62.90% <C> Precision <WITH> [ITALIC] Our Approach <HAS> 56.28% <C> Recall <WITH> [ITALIC] Our Approach <HAS> 62.42% <C> F-Measure <WITH> [ITALIC] Our Approach <HAS> 58.91% <C> <CAP> TABLE VI: Results investigating RQ2 using the Kerala dataset as source and Macedonia dataset as target.
 <R> <C> Accuracy <WITH> Local <HAS> 58.65% <C> Precision <WITH> Local <HAS> [BOLD] 42.40% <C> Recall <WITH> Local <HAS> 47.47% <C> F-Measure <WITH> Local <HAS> 36.88% <C> <R> <C> Accuracy <WITH> Transform <HAS> 53.74% <C> Precision <WITH> Transform <HAS> 32.89% <C> Recall <WITH> Transform <HAS> [BOLD] 57.47%∗ <C> F-Measure <WITH> Transform <HAS> 41.42% <C> <R> <C> Accuracy <WITH> Upsample <HAS> 53.88% <C> Precision <WITH> Upsample <HAS> 31.71% <C> Recall <WITH> Upsample <HAS> 56.32% <C> F-Measure <WITH> Upsample <HAS> 40.32% <C> <R> <C> Accuracy <WITH> [ITALIC] Our Approach <HAS> [BOLD] 58.79% <C> Precision <WITH> [ITALIC] Our Approach <HAS> 35.26% <C> Recall <WITH> [ITALIC] Our Approach <HAS> 55.89% <C> F-Measure <WITH> [ITALIC] Our Approach <HAS> [BOLD] 43.03%∗ <C> <CAP> TABLE VII: Results investigating RQ2 using the Nepal dataset as source and Kerala dataset as target.
 <R> <C> [BOLD] Algorithm <WITH> Giga <HAS> Baseline <C> [BOLD] Precision <WITH> Giga <HAS> 0.28 <C> [BOLD] Recall <WITH> Giga <HAS> 0.74 <C> [BOLD] F1 <WITH> Giga <HAS> 0.41 <C> <R> <C> [BOLD] Algorithm <WITH> Giga <HAS> Threshold <C> [BOLD] Precision <WITH> Giga <HAS> 0.60 <C> [BOLD] Recall <WITH> Giga <HAS> 0.69 <C> [BOLD] F1 <WITH> Giga <HAS> [BOLD] 0.63 <C> <R> <C> [BOLD] Algorithm <WITH> NOW <HAS> Baseline <C> [BOLD] Precision <WITH> NOW <HAS> 0.39 <C> [BOLD] Recall <WITH> NOW <HAS> 0.88 <C> [BOLD] F1 <WITH> NOW <HAS> 0.53 <C> <R> <C> [BOLD] Algorithm <WITH> NOW <HAS> Threshold <C> [BOLD] Precision <WITH> NOW <HAS> 0.50 <C> [BOLD] Recall <WITH> NOW <HAS> 0.77 <C> [BOLD] F1 <WITH> NOW <HAS> [BOLD] 0.60 <C> <CAP> Table 4: Average synchronic performance
 <R> <C> [BOLD] @1 <WITH> Gigaword <HAS> 0.356 <C> [BOLD] @5 <WITH> Gigaword <HAS> 0.555 <C> [BOLD] @10 <WITH> Gigaword <HAS> 0.610 <C> <R> <C> [BOLD] @1 <WITH> NOW <HAS> 0.442 <C> [BOLD] @5 <WITH> NOW <HAS> 0.557 <C> [BOLD] @10 <WITH> NOW <HAS> 0.578 <C> <CAP> Table 2: Average recall of diachronic analogy inference
 <R> <C> [BOLD] Algorithm <WITH> Giga <HAS> Baseline <C> [BOLD] Precision <WITH> Giga <HAS> 0.19 <C> [BOLD] Recall <WITH> Giga <HAS> 0.51 <C> [BOLD] F1 <WITH> Giga <HAS> 0.28 <C> <R> <C> [BOLD] Algorithm <WITH> Giga <HAS> Threshold <C> [BOLD] Precision <WITH> Giga <HAS> 0.46 <C> [BOLD] Recall <WITH> Giga <HAS> 0.41 <C> [BOLD] F1 <WITH> Giga <HAS> [BOLD] 0.41 <C> <R> <C> [BOLD] Algorithm <WITH> NOW <HAS> Baseline <C> [BOLD] Precision <WITH> NOW <HAS> 0.26 <C> [BOLD] Recall <WITH> NOW <HAS> 0.53 <C> [BOLD] F1 <WITH> NOW <HAS> 0.34 <C> <R> <C> [BOLD] Algorithm <WITH> NOW <HAS> Threshold <C> [BOLD] Precision <WITH> NOW <HAS> 0.42 <C> [BOLD] Recall <WITH> NOW <HAS> 0.41 <C> [BOLD] F1 <WITH> NOW <HAS> [BOLD] 0.41 <C> <CAP> Table 3: Average diachronic performance
 <R> <C> [BOLD] Joint Acc. <WITH> COMER <HAS> 88.64% <C> <R> <C> [BOLD] Joint Acc. <WITH> - Hierachical-Attn <HAS> 86.69% <C> <R> <C> [BOLD] Joint Acc. <WITH> - MLP <HAS> 83.24% <C> <CAP> Table 4: The ablation study on the WoZ2.0 dataset with the joint goal accuracy on the test set. For “- Hierachical-Attn”, we remove the residual connections between the attention modules in the CMR decoders and all the attention memory access are based on the output from the LSTM. For “- MLP”, we further replace the MLP with a single linear layer with the non-linear activation.
 <R> <C> [BOLD] Joint Acc. WoZ 2.0 <WITH> Baselines Mrksic et al. ( 2017 ) <HAS> 70.8% <C> [BOLD] Joint Acc. MultiWoZ <WITH> Baselines Mrksic et al. ( 2017 ) <HAS> 25.83% <C> [BOLD] ITC <WITH> Baselines Mrksic et al. ( 2017 ) <HAS> [ITALIC] O( [ITALIC] mn) <C> <R> <C> [BOLD] Joint Acc. WoZ 2.0 <WITH> NBT-CNN Mrksic et al. ( 2017 ) <HAS> 84.2% <C> [BOLD] Joint Acc. MultiWoZ <WITH> NBT-CNN Mrksic et al. ( 2017 ) <HAS> - <C> [BOLD] ITC <WITH> NBT-CNN Mrksic et al. ( 2017 ) <HAS> [ITALIC] O( [ITALIC] mn) <C> <R> <C> [BOLD] Joint Acc. WoZ 2.0 <WITH> StateNet_PSI Ren et al. ( 2018 ) <HAS> [BOLD] 88.9% <C> [BOLD] Joint Acc. MultiWoZ <WITH> StateNet_PSI Ren et al. ( 2018 ) <HAS> - <C> [BOLD] ITC <WITH> StateNet_PSI Ren et al. ( 2018 ) <HAS> [ITALIC] O( [ITALIC] n) <C> <R> <C> [BOLD] Joint Acc. WoZ 2.0 <WITH> GLAD Nouri and Hosseini-Asl ( 2018 ) <HAS> 88.5% <C> [BOLD] Joint Acc. MultiWoZ <WITH> GLAD Nouri and Hosseini-Asl ( 2018 ) <HAS> 35.58% <C> [BOLD] ITC <WITH> GLAD Nouri and Hosseini-Asl ( 2018 ) <HAS> [ITALIC] O( [ITALIC] mn) <C> <R> <C> [BOLD] Joint Acc. WoZ 2.0 <WITH> HyST (ensemble) Goel et al. ( 2019 ) <HAS> - <C> [BOLD] Joint Acc. MultiWoZ <WITH> HyST (ensemble) Goel et al. ( 2019 ) <HAS> 44.22% <C> [BOLD] ITC <WITH> HyST (ensemble) Goel et al. ( 2019 ) <HAS> [ITALIC] O( [ITALIC] n) <C> <R> <C> [BOLD] Joint Acc. WoZ 2.0 <WITH> DSTRead (ensemble) Gao et al. ( 2019 ) <HAS> - <C> [BOLD] Joint Acc. MultiWoZ <WITH> DSTRead (ensemble) Gao et al. ( 2019 ) <HAS> 42.12% <C> [BOLD] ITC <WITH> DSTRead (ensemble) Gao et al. ( 2019 ) <HAS> [ITALIC] O( [ITALIC] n) <C> <R> <C> [BOLD] Joint Acc. WoZ 2.0 <WITH> TRADE Wu et al. ( 2019 ) <HAS> - <C> [BOLD] Joint Acc. MultiWoZ <WITH> TRADE Wu et al. ( 2019 ) <HAS> 48.62% <C> [BOLD] ITC <WITH> TRADE Wu et al. ( 2019 ) <HAS> [ITALIC] O( [ITALIC] n) <C> <R> <C> [BOLD] Joint Acc. WoZ 2.0 <WITH> COMER <HAS> 88.6% <C> [BOLD] Joint Acc. MultiWoZ <WITH> COMER <HAS> [BOLD] 48.79% <C> [BOLD] ITC <WITH> COMER <HAS> [ITALIC] O(1) <C> <CAP> Table 3: The joint goal accuracy of the DST models on the WoZ2.0 test set and the MultiWoZ test set. We also include the Inference Time Complexity (ITC) for each model as a metric for scalability. The baseline accuracy for the WoZ2.0 dataset is the Delexicalisation-Based (DB) Model Mrksic et al. (2017), while the baseline for the MultiWoZ dataset is taken from the official website of MultiWoZ Budzianowski et al. (2018).
 <R> <C> [BOLD] JD Acc. <WITH> COMER <HAS> 95.52% <C> [BOLD] JDS Acc. <WITH> COMER <HAS> 55.81% <C> [BOLD] JG Acc. <WITH> COMER <HAS> 48.79% <C> <R> <C> [BOLD] JD Acc. <WITH> - moveDrop <HAS> 95.34% <C> [BOLD] JDS Acc. <WITH> - moveDrop <HAS> 55.08% <C> [BOLD] JG Acc. <WITH> - moveDrop <HAS> 47.19% <C> <R> <C> [BOLD] JD Acc. <WITH> - postprocess <HAS> 95.53% <C> [BOLD] JDS Acc. <WITH> - postprocess <HAS> 54.74% <C> [BOLD] JG Acc. <WITH> - postprocess <HAS> 45.72% <C> <R> <C> [BOLD] JD Acc. <WITH> - ShareParam <HAS> 94.96% <C> [BOLD] JDS Acc. <WITH> - ShareParam <HAS> 54.40% <C> [BOLD] JG Acc. <WITH> - ShareParam <HAS> 44.38% <C> <R> <C> [BOLD] JD Acc. <WITH> - Order <HAS> 95.55% <C> [BOLD] JDS Acc. <WITH> - Order <HAS> 55.06% <C> [BOLD] JG Acc. <WITH> - Order <HAS> 42.84% <C> <R> <C> [BOLD] JD Acc. <WITH> - Nested <HAS> - <C> [BOLD] JDS Acc. <WITH> - Nested <HAS> 49.58% <C> [BOLD] JG Acc. <WITH> - Nested <HAS> 40.57% <C> <R> <C> [BOLD] JD Acc. <WITH> - BlockGrad <HAS> - <C> [BOLD] JDS Acc. <WITH> - BlockGrad <HAS> 49.36% <C> [BOLD] JG Acc. <WITH> - BlockGrad <HAS> 39.15% <C> <CAP> Table 5: The ablation study on the MultiWoZ dataset with the joint domain accuracy (JD Acc.), joint domain-slot accuracy (JDS Acc.) and joint goal accuracy (JG Acc.) on the test set. For “- moveDrop”, we move the dropout layer to be in front of the final linear layer before the Softmax. For “- postprocess”, we further fix the decoder embedding layer and remove the post-processing during model evaluation. For “- ShareParam”, we further remove the parameter sharing mechanism on the encoders and the attention modules. For “- Order”, we further arrange the order of the slots according to its global frequencies in the training set instead of the local frequencies given the domain it belongs to. For “- Nested”, we do not generate domain sequences but generate combined slot sequences which combines the domain and the slot together. For “- BlockGrad”, we further remove the gradient blocking mechanism in the CMR decoder.
 <R> <C> Target <WITH> Beer look + Beer aroma + Beer palate <HAS> Hotel location <C> Svm <WITH> Beer look + Beer aroma + Beer palate <HAS> 78.65 <C> Ra-Svm‡ <WITH> Beer look + Beer aroma + Beer palate <HAS> 79.09 <C> Ra-Cnn‡ <WITH> Beer look + Beer aroma + Beer palate <HAS> 79.28 <C> Trans† <WITH> Beer look + Beer aroma + Beer palate <HAS> 80.42 <C> Ra-Trans‡† <WITH> Beer look + Beer aroma + Beer palate <HAS> 82.10 <C> Ours‡† <WITH> Beer look + Beer aroma + Beer palate <HAS> [BOLD] 84.52 <C> Oracle† <WITH> Beer look + Beer aroma + Beer palate <HAS> 85.43 <C> <R> <C> Target <WITH> Beer look + Beer aroma + Beer palate <HAS> Hotel cleanliness <C> Svm <WITH> Beer look + Beer aroma + Beer palate <HAS> 86.44 <C> Ra-Svm‡ <WITH> Beer look + Beer aroma + Beer palate <HAS> 86.68 <C> Ra-Cnn‡ <WITH> Beer look + Beer aroma + Beer palate <HAS> 89.01 <C> Trans† <WITH> Beer look + Beer aroma + Beer palate <HAS> 86.95 <C> Ra-Trans‡† <WITH> Beer look + Beer aroma + Beer palate <HAS> 87.15 <C> Ours‡† <WITH> Beer look + Beer aroma + Beer palate <HAS> [BOLD] 90.66 <C> Oracle† <WITH> Beer look + Beer aroma + Beer palate <HAS> 92.09 <C> <R> <C> Target <WITH> Beer look + Beer aroma + Beer palate <HAS> Hotel service <C> Svm <WITH> Beer look + Beer aroma + Beer palate <HAS> 85.34 <C> Ra-Svm‡ <WITH> Beer look + Beer aroma + Beer palate <HAS> 86.61 <C> Ra-Cnn‡ <WITH> Beer look + Beer aroma + Beer palate <HAS> 87.91 <C> Trans† <WITH> Beer look + Beer aroma + Beer palate <HAS> 87.37 <C> Ra-Trans‡† <WITH> Beer look + Beer aroma + Beer palate <HAS> 86.40 <C> Ours‡† <WITH> Beer look + Beer aroma + Beer palate <HAS> [BOLD] 89.93 <C> Oracle† <WITH> Beer look + Beer aroma + Beer palate <HAS> 92.42 <C> <CAP> Table 4: Accuracy of transferring between domains. Models with † use labeled data from source domains and unlabeled data from the target domain. Models with ‡ use human rationales on the target task.
 <R> <C> Target <WITH> Beer aroma+palate <HAS> Beer look <C> Svm <WITH> Beer aroma+palate <HAS> 74.41 <C> Ra-Svm‡ <WITH> Beer aroma+palate <HAS> 74.83 <C> Ra-Cnn‡ <WITH> Beer aroma+palate <HAS> 74.94 <C> Trans† <WITH> Beer aroma+palate <HAS> 72.75 <C> Ra-Trans‡† <WITH> Beer aroma+palate <HAS> 76.41 <C> Ours‡† <WITH> Beer aroma+palate <HAS> [BOLD] 79.53 <C> Oracle† <WITH> Beer aroma+palate <HAS> 80.29 <C> <R> <C> Target <WITH> Beer look+palate <HAS> Beer aroma <C> Svm <WITH> Beer look+palate <HAS> 68.57 <C> Ra-Svm‡ <WITH> Beer look+palate <HAS> 69.23 <C> Ra-Cnn‡ <WITH> Beer look+palate <HAS> 67.55 <C> Trans† <WITH> Beer look+palate <HAS> 69.92 <C> Ra-Trans‡† <WITH> Beer look+palate <HAS> 76.45 <C> Ours‡† <WITH> Beer look+palate <HAS> [BOLD] 77.94 <C> Oracle† <WITH> Beer look+palate <HAS> 78.11 <C> <R> <C> Target <WITH> Beer look+aroma <HAS> Beer palate <C> Svm <WITH> Beer look+aroma <HAS> 63.88 <C> Ra-Svm‡ <WITH> Beer look+aroma <HAS> 67.82 <C> Ra-Cnn‡ <WITH> Beer look+aroma <HAS> 65.72 <C> Trans† <WITH> Beer look+aroma <HAS> 74.66 <C> Ra-Trans‡† <WITH> Beer look+aroma <HAS> 73.40 <C> Ours‡† <WITH> Beer look+aroma <HAS> [BOLD] 75.24 <C> Oracle† <WITH> Beer look+aroma <HAS> 75.50 <C> <CAP> Table 3: Accuracy of transferring between aspects. Models with † use labeled data from source aspects. Models with ‡ use human rationales on the target aspect.
 <R> <C> Hotel location <WITH> Ours <HAS> [BOLD] 84.52 <C> Hotel cleanliness <WITH> Ours <HAS> [BOLD] 90.66 <C> Hotel service <WITH> Ours <HAS> [BOLD] 89.93 <C> <R> <C> Hotel location <WITH> w/o L [ITALIC] wd <HAS> 82.36 <C> Hotel cleanliness <WITH> w/o L [ITALIC] wd <HAS> 89.79 <C> Hotel service <WITH> w/o L [ITALIC] wd <HAS> 89.61 <C> <R> <C> Hotel location <WITH> w/o L [ITALIC] lm <HAS> 82.47 <C> Hotel cleanliness <WITH> w/o L [ITALIC] lm <HAS> 90.05 <C> Hotel service <WITH> w/o L [ITALIC] lm <HAS> 89.75 <C> <CAP> Table 5: Ablation study on domain transfer from beer to hotel.
 <R> <C> Score <WITH> Catseq(Ex) <HAS> F1@5 <C> Inspec <WITH> Catseq(Ex) <HAS> 0.2350 <C> Krapivin <WITH> Catseq(Ex) <HAS> 0.2680 <C> NUS <WITH> Catseq(Ex) <HAS> 0.3330 <C> KP20k <WITH> Catseq(Ex) <HAS> 0.2840 <C> <R> <C> Score <WITH> [EMPTY] <HAS> F1@M <C> Inspec <WITH> [EMPTY] <HAS> 0.2864 <C> Krapivin <WITH> [EMPTY] <HAS> 0.3610 <C> NUS <WITH> [EMPTY] <HAS> 0.3982 <C> KP20k <WITH> [EMPTY] <HAS> 0.3661 <C> <R> <C> Score <WITH> catSeq-RL(Ex.) <HAS> F1@5 <C> Inspec <WITH> catSeq-RL(Ex.) <HAS> [BOLD] 0.2501 <C> Krapivin <WITH> catSeq-RL(Ex.) <HAS> [BOLD] 0.2870 <C> NUS <WITH> catSeq-RL(Ex.) <HAS> [BOLD] 0.3750 <C> KP20k <WITH> catSeq-RL(Ex.) <HAS> [BOLD] 0.3100 <C> <R> <C> Score <WITH> [EMPTY] <HAS> F1@M <C> Inspec <WITH> [EMPTY] <HAS> [BOLD] 0.3000 <C> Krapivin <WITH> [EMPTY] <HAS> 0.3630 <C> NUS <WITH> [EMPTY] <HAS> [BOLD] 0.4330 <C> KP20k <WITH> [EMPTY] <HAS> [BOLD] 0.3830 <C> <R> <C> Score <WITH> GAN(Ex.) <HAS> F1@5 <C> Inspec <WITH> GAN(Ex.) <HAS> 0.2481 <C> Krapivin <WITH> GAN(Ex.) <HAS> 0.2862 <C> NUS <WITH> GAN(Ex.) <HAS> 0.3681 <C> KP20k <WITH> GAN(Ex.) <HAS> 0.3002 <C> <R> <C> Score <WITH> [EMPTY] <HAS> F1@M <C> Inspec <WITH> [EMPTY] <HAS> 0.2970 <C> Krapivin <WITH> [EMPTY] <HAS> [BOLD] 0.3700 <C> NUS <WITH> [EMPTY] <HAS> 0.4300 <C> KP20k <WITH> [EMPTY] <HAS> 0.3810 <C> <R> <C> Score <WITH> catSeq(Abs.) <HAS> F1@5 <C> Inspec <WITH> catSeq(Abs.) <HAS> 0.0045 <C> Krapivin <WITH> catSeq(Abs.) <HAS> 0.0168 <C> NUS <WITH> catSeq(Abs.) <HAS> 0.0126 <C> KP20k <WITH> catSeq(Abs.) <HAS> 0.0200 <C> <R> <C> Score <WITH> [EMPTY] <HAS> F1@M <C> Inspec <WITH> [EMPTY] <HAS> 0.0085 <C> Krapivin <WITH> [EMPTY] <HAS> 0.0320 <C> NUS <WITH> [EMPTY] <HAS> 0.0170 <C> KP20k <WITH> [EMPTY] <HAS> 0.0360 <C> <R> <C> Score <WITH> catSeq-RL(Abs.) <HAS> F1@5 <C> Inspec <WITH> catSeq-RL(Abs.) <HAS> 0.0090 <C> Krapivin <WITH> catSeq-RL(Abs.) <HAS> [BOLD] 0.0262 <C> NUS <WITH> catSeq-RL(Abs.) <HAS> 0.0190 <C> KP20k <WITH> catSeq-RL(Abs.) <HAS> 0.0240 <C> <R> <C> Score <WITH> [EMPTY] <HAS> F1@M <C> Inspec <WITH> [EMPTY] <HAS> 0.0017 <C> Krapivin <WITH> [EMPTY] <HAS> [BOLD] 0.0460 <C> NUS <WITH> [EMPTY] <HAS> 0.0310 <C> KP20k <WITH> [EMPTY] <HAS> 0.0440 <C> <R> <C> Score <WITH> GAN(Abs.) <HAS> F1@5 <C> Inspec <WITH> GAN(Abs.) <HAS> [BOLD] 0.0100 <C> Krapivin <WITH> GAN(Abs.) <HAS> 0.0240 <C> NUS <WITH> GAN(Abs.) <HAS> [BOLD] 0.0193 <C> KP20k <WITH> GAN(Abs.) <HAS> [BOLD] 0.0250 <C> <R> <C> Score <WITH> [EMPTY] <HAS> F1@M <C> Inspec <WITH> [EMPTY] <HAS> [BOLD] 0.0190 <C> Krapivin <WITH> [EMPTY] <HAS> 0.0440 <C> NUS <WITH> [EMPTY] <HAS> [BOLD] 0.0340 <C> KP20k <WITH> [EMPTY] <HAS> [BOLD] 0.0450 <C> <CAP> Table 1: Extractive and Abstractive Keyphrase Metrics
 <R> <C> Inspec <WITH> Catseq <HAS> 0.87803 <C> Krapivin <WITH> Catseq <HAS> 0.781 <C> NUS <WITH> Catseq <HAS> 0.82118 <C> KP20k <WITH> Catseq <HAS> 0.804 <C> <R> <C> Inspec <WITH> Catseq-RL <HAS> 0.8602 <C> Krapivin <WITH> Catseq-RL <HAS> [BOLD] 0.786 <C> NUS <WITH> Catseq-RL <HAS> 0.83 <C> KP20k <WITH> Catseq-RL <HAS> 0.809 <C> <R> <C> Inspec <WITH> GAN <HAS> [BOLD] 0.891 <C> Krapivin <WITH> GAN <HAS> 0.771 <C> NUS <WITH> GAN <HAS> [BOLD] 0.853 <C> KP20k <WITH> GAN <HAS> [BOLD] 0.85 <C> <CAP> Table 2: α-nDCG@5 metrics
 <R> <C> Female (%) <WITH> Service <HAS> 10.5 <C> Male (%) <WITH> Service <HAS> 59.548 <C> Neutral (%) <WITH> Service <HAS> 16.476 <C> <R> <C> Female (%) <WITH> STEM <HAS> 4.219 <C> Male (%) <WITH> STEM <HAS> 71.624 <C> Neutral (%) <WITH> STEM <HAS> 11.181 <C> <R> <C> Female (%) <WITH> Farming / Fishing / Forestry <HAS> 12.179 <C> Male (%) <WITH> Farming / Fishing / Forestry <HAS> 62.179 <C> Neutral (%) <WITH> Farming / Fishing / Forestry <HAS> 14.744 <C> <R> <C> Female (%) <WITH> Corporate <HAS> 9.167 <C> Male (%) <WITH> Corporate <HAS> 66.042 <C> Neutral (%) <WITH> Corporate <HAS> 14.861 <C> <R> <C> Female (%) <WITH> Healthcare <HAS> 23.305 <C> Male (%) <WITH> Healthcare <HAS> 49.576 <C> Neutral (%) <WITH> Healthcare <HAS> 15.537 <C> <R> <C> Female (%) <WITH> Legal <HAS> 11.905 <C> Male (%) <WITH> Legal <HAS> 72.619 <C> Neutral (%) <WITH> Legal <HAS> 10.714 <C> <R> <C> Female (%) <WITH> Arts / Entertainment <HAS> 10.36 <C> Male (%) <WITH> Arts / Entertainment <HAS> 67.342 <C> Neutral (%) <WITH> Arts / Entertainment <HAS> 11.486 <C> <R> <C> Female (%) <WITH> Education <HAS> 23.485 <C> Male (%) <WITH> Education <HAS> 53.03 <C> Neutral (%) <WITH> Education <HAS> 9.091 <C> <R> <C> Female (%) <WITH> Production <HAS> 14.331 <C> Male (%) <WITH> Production <HAS> 51.199 <C> Neutral (%) <WITH> Production <HAS> 18.245 <C> <R> <C> Female (%) <WITH> Construction / Extraction <HAS> 8.578 <C> Male (%) <WITH> Construction / Extraction <HAS> 61.887 <C> Neutral (%) <WITH> Construction / Extraction <HAS> 17.525 <C> <R> <C> Female (%) <WITH> Total <HAS> 11.76 <C> Male (%) <WITH> Total <HAS> 58.93 <C> Neutral (%) <WITH> Total <HAS> 15.939 <C> <CAP> Table 7: Percentage of female, male and neutral gender pronouns obtained for each of the merged occupation category, averaged over all occupations in said category and tested languages detailed in Table
 <R> <C> Female (%) <WITH> Office and administrative support <HAS> 11.015 <C> Male (%) <WITH> Office and administrative support <HAS> 58.812 <C> Neutral (%) <WITH> Office and administrative support <HAS> 16.954 <C> <R> <C> Female (%) <WITH> Architecture and engineering <HAS> 2.299 <C> Male (%) <WITH> Architecture and engineering <HAS> 72.701 <C> Neutral (%) <WITH> Architecture and engineering <HAS> 10.92 <C> <R> <C> Female (%) <WITH> Farming, fishing, and forestry <HAS> 12.179 <C> Male (%) <WITH> Farming, fishing, and forestry <HAS> 62.179 <C> Neutral (%) <WITH> Farming, fishing, and forestry <HAS> 14.744 <C> <R> <C> Female (%) <WITH> Management <HAS> 11.232 <C> Male (%) <WITH> Management <HAS> 66.667 <C> Neutral (%) <WITH> Management <HAS> 12.681 <C> <R> <C> Female (%) <WITH> Community and social service <HAS> 20.238 <C> Male (%) <WITH> Community and social service <HAS> 62.5 <C> Neutral (%) <WITH> Community and social service <HAS> 10.119 <C> <R> <C> Female (%) <WITH> Healthcare support <HAS> 25.0 <C> Male (%) <WITH> Healthcare support <HAS> 43.75 <C> Neutral (%) <WITH> Healthcare support <HAS> 17.188 <C> <R> <C> Female (%) <WITH> Sales and related <HAS> 8.929 <C> Male (%) <WITH> Sales and related <HAS> 62.202 <C> Neutral (%) <WITH> Sales and related <HAS> 16.964 <C> <R> <C> Female (%) <WITH> Installation, maintenance, and repair <HAS> 5.22 <C> Male (%) <WITH> Installation, maintenance, and repair <HAS> 58.333 <C> Neutral (%) <WITH> Installation, maintenance, and repair <HAS> 17.125 <C> <R> <C> Female (%) <WITH> Transportation and material moving <HAS> 8.81 <C> Male (%) <WITH> Transportation and material moving <HAS> 62.976 <C> Neutral (%) <WITH> Transportation and material moving <HAS> 17.5 <C> <R> <C> Female (%) <WITH> Legal <HAS> 11.905 <C> Male (%) <WITH> Legal <HAS> 72.619 <C> Neutral (%) <WITH> Legal <HAS> 10.714 <C> <R> <C> Female (%) <WITH> Business and financial operations <HAS> 7.065 <C> Male (%) <WITH> Business and financial operations <HAS> 67.935 <C> Neutral (%) <WITH> Business and financial operations <HAS> 15.58 <C> <R> <C> Female (%) <WITH> Life, physical, and social science <HAS> 5.882 <C> Male (%) <WITH> Life, physical, and social science <HAS> 73.284 <C> Neutral (%) <WITH> Life, physical, and social science <HAS> 10.049 <C> <R> <C> Female (%) <WITH> Arts, design, entertainment, sports, and media <HAS> 10.36 <C> Male (%) <WITH> Arts, design, entertainment, sports, and media <HAS> 67.342 <C> Neutral (%) <WITH> Arts, design, entertainment, sports, and media <HAS> 11.486 <C> <R> <C> Female (%) <WITH> Education, training, and library <HAS> 23.485 <C> Male (%) <WITH> Education, training, and library <HAS> 53.03 <C> Neutral (%) <WITH> Education, training, and library <HAS> 9.091 <C> <R> <C> Female (%) <WITH> Building and grounds cleaning and maintenance <HAS> 12.5 <C> Male (%) <WITH> Building and grounds cleaning and maintenance <HAS> 68.333 <C> Neutral (%) <WITH> Building and grounds cleaning and maintenance <HAS> 11.667 <C> <R> <C> Female (%) <WITH> Personal care and service <HAS> 18.939 <C> Male (%) <WITH> Personal care and service <HAS> 49.747 <C> Neutral (%) <WITH> Personal care and service <HAS> 18.434 <C> <R> <C> Female (%) <WITH> Healthcare practitioners and technical <HAS> 22.674 <C> Male (%) <WITH> Healthcare practitioners and technical <HAS> 51.744 <C> Neutral (%) <WITH> Healthcare practitioners and technical <HAS> 15.116 <C> <R> <C> Female (%) <WITH> Production <HAS> 14.331 <C> Male (%) <WITH> Production <HAS> 51.199 <C> Neutral (%) <WITH> Production <HAS> 18.245 <C> <R> <C> Female (%) <WITH> Computer and mathematical <HAS> 4.167 <C> Male (%) <WITH> Computer and mathematical <HAS> 66.146 <C> Neutral (%) <WITH> Computer and mathematical <HAS> 14.062 <C> <R> <C> Female (%) <WITH> Construction and extraction <HAS> 8.578 <C> Male (%) <WITH> Construction and extraction <HAS> 61.887 <C> Neutral (%) <WITH> Construction and extraction <HAS> 17.525 <C> <R> <C> Female (%) <WITH> Protective service <HAS> 8.631 <C> Male (%) <WITH> Protective service <HAS> 65.179 <C> Neutral (%) <WITH> Protective service <HAS> 12.5 <C> <R> <C> Female (%) <WITH> Food preparation and serving related <HAS> 21.078 <C> Male (%) <WITH> Food preparation and serving related <HAS> 58.333 <C> Neutral (%) <WITH> Food preparation and serving related <HAS> 17.647 <C> <R> <C> Female (%) <WITH> Total <HAS> 11.76 <C> Male (%) <WITH> Total <HAS> 58.93 <C> Neutral (%) <WITH> Total <HAS> 15.939 <C> <CAP> Table 6: Percentage of female, male and neutral gender pronouns obtained for each BLS occupation category, averaged over all occupations in said category and tested languages detailed in Table
 <R> <C> Class <WITH> [ITALIC] Waseem and Hovy <HAS> Racism <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Waseem and Hovy <HAS> 0.010 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Waseem and Hovy <HAS> 0.010 <C> [ITALIC] t <WITH> [ITALIC] Waseem and Hovy <HAS> -0.632 <C> [ITALIC] p <WITH> [ITALIC] Waseem and Hovy <HAS> [EMPTY] <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Waseem and Hovy <HAS> 0.978 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Sexism <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.963 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.944 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 20.064 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.020 <C> <R> <C> Class <WITH> [ITALIC] Waseem <HAS> Racism <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Waseem <HAS> 0.011 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Waseem <HAS> 0.011 <C> [ITALIC] t <WITH> [ITALIC] Waseem <HAS> -1.254 <C> [ITALIC] p <WITH> [ITALIC] Waseem <HAS> [EMPTY] <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Waseem <HAS> 0.955 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Sexism <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.349 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.290 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 28.803 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.203 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Racism and sexism <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.012 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.012 <C> [ITALIC] t <WITH> [EMPTY] <HAS> -0.162 <C> [ITALIC] p <WITH> [EMPTY] <HAS> [EMPTY] <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.995 <C> <R> <C> Class <WITH> [ITALIC] Davidson et al. <HAS> Hate <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Davidson et al. <HAS> 0.017 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Davidson et al. <HAS> 0.015 <C> [ITALIC] t <WITH> [ITALIC] Davidson et al. <HAS> 4.698 <C> [ITALIC] p <WITH> [ITALIC] Davidson et al. <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Davidson et al. <HAS> 1.152 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Offensive <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.988 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.991 <C> [ITALIC] t <WITH> [EMPTY] <HAS> -6.289 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.997 <C> <R> <C> Class <WITH> [ITALIC] Golbeck et al. <HAS> Harassment <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Golbeck et al. <HAS> 0.099 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Golbeck et al. <HAS> 0.091 <C> [ITALIC] t <WITH> [ITALIC] Golbeck et al. <HAS> 6.273 <C> [ITALIC] p <WITH> [ITALIC] Golbeck et al. <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Golbeck et al. <HAS> 1.091 <C> <R> <C> Class <WITH> [ITALIC] Founta et al. <HAS> Hate <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Founta et al. <HAS> 0.074 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Founta et al. <HAS> 0.027 <C> [ITALIC] t <WITH> [ITALIC] Founta et al. <HAS> 46.054 <C> [ITALIC] p <WITH> [ITALIC] Founta et al. <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Founta et al. <HAS> 2.728 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Abusive <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.925 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.968 <C> [ITALIC] t <WITH> [EMPTY] <HAS> -41.396 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.956 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Spam <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.010 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.010 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 0.000 <C> [ITALIC] p <WITH> [EMPTY] <HAS> [EMPTY] <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.000 <C> <CAP> Table 4: Experiment 2, t= “b*tch”
 <R> <C> Class <WITH> [ITALIC] W. & H. <HAS> Racism <C> Precision <WITH> [ITALIC] W. & H. <HAS> 0.73 <C> Recall <WITH> [ITALIC] W. & H. <HAS> 0.79 <C> F1 <WITH> [ITALIC] W. & H. <HAS> 0.76 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Sexism <C> Precision <WITH> [EMPTY] <HAS> 0.69 <C> Recall <WITH> [EMPTY] <HAS> 0.73 <C> F1 <WITH> [EMPTY] <HAS> 0.71 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Neither <C> Precision <WITH> [EMPTY] <HAS> 0.88 <C> Recall <WITH> [EMPTY] <HAS> 0.85 <C> F1 <WITH> [EMPTY] <HAS> 0.86 <C> <R> <C> Class <WITH> [ITALIC] W. <HAS> Racism <C> Precision <WITH> [ITALIC] W. <HAS> 0.56 <C> Recall <WITH> [ITALIC] W. <HAS> 0.77 <C> F1 <WITH> [ITALIC] W. <HAS> 0.65 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Sexism <C> Precision <WITH> [EMPTY] <HAS> 0.62 <C> Recall <WITH> [EMPTY] <HAS> 0.73 <C> F1 <WITH> [EMPTY] <HAS> 0.67 <C> <R> <C> Class <WITH> [EMPTY] <HAS> R. & S. <C> Precision <WITH> [EMPTY] <HAS> 0.56 <C> Recall <WITH> [EMPTY] <HAS> 0.62 <C> F1 <WITH> [EMPTY] <HAS> 0.59 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Neither <C> Precision <WITH> [EMPTY] <HAS> 0.95 <C> Recall <WITH> [EMPTY] <HAS> 0.92 <C> F1 <WITH> [EMPTY] <HAS> 0.94 <C> <R> <C> Class <WITH> [ITALIC] D. et al. <HAS> Hate <C> Precision <WITH> [ITALIC] D. et al. <HAS> 0.32 <C> Recall <WITH> [ITALIC] D. et al. <HAS> 0.53 <C> F1 <WITH> [ITALIC] D. et al. <HAS> 0.4 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Offensive <C> Precision <WITH> [EMPTY] <HAS> 0.96 <C> Recall <WITH> [EMPTY] <HAS> 0.88 <C> F1 <WITH> [EMPTY] <HAS> 0.92 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Neither <C> Precision <WITH> [EMPTY] <HAS> 0.81 <C> Recall <WITH> [EMPTY] <HAS> 0.95 <C> F1 <WITH> [EMPTY] <HAS> 0.87 <C> <R> <C> Class <WITH> [ITALIC] G. et al. <HAS> Harass. <C> Precision <WITH> [ITALIC] G. et al. <HAS> 0.41 <C> Recall <WITH> [ITALIC] G. et al. <HAS> 0.19 <C> F1 <WITH> [ITALIC] G. et al. <HAS> 0.26 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Non. <C> Precision <WITH> [EMPTY] <HAS> 0.75 <C> Recall <WITH> [EMPTY] <HAS> 0.9 <C> F1 <WITH> [EMPTY] <HAS> 0.82 <C> <R> <C> Class <WITH> [ITALIC] F. et al. <HAS> Hate <C> Precision <WITH> [ITALIC] F. et al. <HAS> 0.33 <C> Recall <WITH> [ITALIC] F. et al. <HAS> 0.42 <C> F1 <WITH> [ITALIC] F. et al. <HAS> 0.37 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Abusive <C> Precision <WITH> [EMPTY] <HAS> 0.87 <C> Recall <WITH> [EMPTY] <HAS> 0.88 <C> F1 <WITH> [EMPTY] <HAS> 0.88 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Spam <C> Precision <WITH> [EMPTY] <HAS> 0.5 <C> Recall <WITH> [EMPTY] <HAS> 0.7 <C> F1 <WITH> [EMPTY] <HAS> 0.58 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Neither <C> Precision <WITH> [EMPTY] <HAS> 0.88 <C> Recall <WITH> [EMPTY] <HAS> 0.77 <C> F1 <WITH> [EMPTY] <HAS> 0.82 <C> <CAP> Table 1: Classifier performance
 <R> <C> Class <WITH> [ITALIC] Waseem and Hovy <HAS> Racism <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Waseem and Hovy <HAS> 0.001 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Waseem and Hovy <HAS> 0.003 <C> [ITALIC] t <WITH> [ITALIC] Waseem and Hovy <HAS> -20.818 <C> [ITALIC] p <WITH> [ITALIC] Waseem and Hovy <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Waseem and Hovy <HAS> 0.505 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Sexism <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.083 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.048 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 101.636 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.724 <C> <R> <C> Class <WITH> [ITALIC] Waseem <HAS> Racism <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Waseem <HAS> 0.001 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Waseem <HAS> 0.001 <C> [ITALIC] t <WITH> [ITALIC] Waseem <HAS> 0.035 <C> [ITALIC] p <WITH> [ITALIC] Waseem <HAS> [EMPTY] <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Waseem <HAS> 1.001 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Sexism <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.023 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.012 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 64.418 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.993 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Racism and sexism <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.002 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.001 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 4.047 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.120 <C> <R> <C> Class <WITH> [ITALIC] Davidson et al. <HAS> Hate <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Davidson et al. <HAS> 0.049 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Davidson et al. <HAS> 0.019 <C> [ITALIC] t <WITH> [ITALIC] Davidson et al. <HAS> 120.986 <C> [ITALIC] p <WITH> [ITALIC] Davidson et al. <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Davidson et al. <HAS> 2.573 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Offensive <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.173 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.065 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 243.285 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 2.653 <C> <R> <C> Class <WITH> [ITALIC] Golbeck et al. <HAS> Harassment <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Golbeck et al. <HAS> 0.032 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Golbeck et al. <HAS> 0.023 <C> [ITALIC] t <WITH> [ITALIC] Golbeck et al. <HAS> 39.483 <C> [ITALIC] p <WITH> [ITALIC] Golbeck et al. <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Golbeck et al. <HAS> 1.396 <C> <R> <C> Class <WITH> [ITALIC] Founta et al. <HAS> Hate <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Founta et al. <HAS> 0.111 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Founta et al. <HAS> 0.061 <C> [ITALIC] t <WITH> [ITALIC] Founta et al. <HAS> 122.707 <C> [ITALIC] p <WITH> [ITALIC] Founta et al. <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Founta et al. <HAS> 1.812 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Abusive <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.178 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.080 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 211.319 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 2.239 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Spam <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.028 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.015 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 63.131 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.854 <C> <CAP> Table 2: Experiment 1
 <R> <C> Class <WITH> [ITALIC] Waseem and Hovy <HAS> Racism <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Waseem and Hovy <HAS> 0.010 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Waseem and Hovy <HAS> 0.011 <C> [ITALIC] t <WITH> [ITALIC] Waseem and Hovy <HAS> -1.462 <C> [ITALIC] p <WITH> [ITALIC] Waseem and Hovy <HAS> [EMPTY] <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Waseem and Hovy <HAS> 0.960 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Sexism <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.147 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.100 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 31.932 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.479 <C> <R> <C> Class <WITH> [ITALIC] Waseem <HAS> Racism <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Waseem <HAS> 0.010 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Waseem <HAS> 0.010 <C> [ITALIC] t <WITH> [ITALIC] Waseem <HAS> 0.565 <C> [ITALIC] p <WITH> [ITALIC] Waseem <HAS> [EMPTY] <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Waseem <HAS> 1.027 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Sexism <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.040 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.026 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 18.569 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.554 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Racism and sexism <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.011 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.010 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 0.835 <C> [ITALIC] p <WITH> [EMPTY] <HAS> [EMPTY] <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.026 <C> <R> <C> Class <WITH> [ITALIC] Davidson et al. <HAS> Hate <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Davidson et al. <HAS> 0.578 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Davidson et al. <HAS> 0.645 <C> [ITALIC] t <WITH> [ITALIC] Davidson et al. <HAS> -31.248 <C> [ITALIC] p <WITH> [ITALIC] Davidson et al. <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Davidson et al. <HAS> 0.896 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Offensive <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.418 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.347 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 32.895 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.202 <C> <R> <C> Class <WITH> [ITALIC] Golbeck et al. <HAS> Harassment <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Golbeck et al. <HAS> 0.085 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Golbeck et al. <HAS> 0.078 <C> [ITALIC] t <WITH> [ITALIC] Golbeck et al. <HAS> 5.984 <C> [ITALIC] p <WITH> [ITALIC] Golbeck et al. <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Golbeck et al. <HAS> 1.096 <C> <R> <C> Class <WITH> [ITALIC] Founta et al. <HAS> Hate <C> ˆ [ITALIC] piblack <WITH> [ITALIC] Founta et al. <HAS> 0.912 <C> ˆ [ITALIC] piwhite <WITH> [ITALIC] Founta et al. <HAS> 0.930 <C> [ITALIC] t <WITH> [ITALIC] Founta et al. <HAS> -15.037 <C> [ITALIC] p <WITH> [ITALIC] Founta et al. <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [ITALIC] Founta et al. <HAS> 0.980 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Abusive <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.086 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.067 <C> [ITALIC] t <WITH> [EMPTY] <HAS> 16.131 <C> [ITALIC] p <WITH> [EMPTY] <HAS> *** <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.296 <C> <R> <C> Class <WITH> [EMPTY] <HAS> Spam <C> ˆ [ITALIC] piblack <WITH> [EMPTY] <HAS> 0.010 <C> ˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 0.010 <C> [ITALIC] t <WITH> [EMPTY] <HAS> -1.593 <C> [ITALIC] p <WITH> [EMPTY] <HAS> [EMPTY] <C> ˆ [ITALIC] piblackˆ [ITALIC] piwhite <WITH> [EMPTY] <HAS> 1.000 <C> <CAP> Table 3: Experiment 2, t= “n*gga”
 <R> <C> MSCOCO spice <WITH> softmax <HAS> 18.4 <C> MSCOCO cider <WITH> softmax <HAS> 0.967 <C> MSCOCO rouge [ITALIC] L <WITH> softmax <HAS> 52.9 <C> MSCOCO bleu4 <WITH> softmax <HAS> 29.9 <C> MSCOCO meteor <WITH> softmax <HAS> 24.9 <C> MSCOCO rep↓ <WITH> softmax <HAS> 3.76 <C> Flickr30k spice <WITH> softmax <HAS> 13.5 <C> Flickr30k cider <WITH> softmax <HAS> 0.443 <C> Flickr30k rouge [ITALIC] L <WITH> softmax <HAS> 44.2 <C> Flickr30k bleu4 <WITH> softmax <HAS> 19.9 <C> Flickr30k meteor <WITH> softmax <HAS> 19.1 <C> Flickr30k rep↓ <WITH> softmax <HAS> 6.09 <C> <R> <C> MSCOCO spice <WITH> sparsemax <HAS> [BOLD] 18.9 <C> MSCOCO cider <WITH> sparsemax <HAS> [BOLD] 0.990 <C> MSCOCO rouge [ITALIC] L <WITH> sparsemax <HAS> [BOLD] 53.5 <C> MSCOCO bleu4 <WITH> sparsemax <HAS> [BOLD] 31.5 <C> MSCOCO meteor <WITH> sparsemax <HAS> [BOLD] 25.3 <C> MSCOCO rep↓ <WITH> sparsemax <HAS> 3.69 <C> Flickr30k spice <WITH> sparsemax <HAS> [BOLD] 13.7 <C> Flickr30k cider <WITH> sparsemax <HAS> [BOLD] 0.444 <C> Flickr30k rouge [ITALIC] L <WITH> sparsemax <HAS> [BOLD] 44.3 <C> Flickr30k bleu4 <WITH> sparsemax <HAS> [BOLD] 20.7 <C> Flickr30k meteor <WITH> sparsemax <HAS> [BOLD] 19.3 <C> Flickr30k rep↓ <WITH> sparsemax <HAS> 5.84 <C> <R> <C> MSCOCO spice <WITH> TVmax <HAS> 18.5 <C> MSCOCO cider <WITH> TVmax <HAS> 0.974 <C> MSCOCO rouge [ITALIC] L <WITH> TVmax <HAS> 53.1 <C> MSCOCO bleu4 <WITH> TVmax <HAS> 29.9 <C> MSCOCO meteor <WITH> TVmax <HAS> 25.1 <C> MSCOCO rep↓ <WITH> TVmax <HAS> [BOLD] 3.17 <C> Flickr30k spice <WITH> TVmax <HAS> 13.3 <C> Flickr30k cider <WITH> TVmax <HAS> 0.438 <C> Flickr30k rouge [ITALIC] L <WITH> TVmax <HAS> 44.2 <C> Flickr30k bleu4 <WITH> TVmax <HAS> 20.5 <C> Flickr30k meteor <WITH> TVmax <HAS> 19.0 <C> Flickr30k rep↓ <WITH> TVmax <HAS> [BOLD] 3.97 <C> <CAP> Table 1: Automatic evaluation of caption generation on MSCOCO and Flickr30k.
 <R> <C> caption <WITH> softmax <HAS> 3.50 <C> attention relevance <WITH> softmax <HAS> 3.38 <C> <R> <C> caption <WITH> sparsemax <HAS> 3.71 <C> attention relevance <WITH> sparsemax <HAS> 3.89 <C> <R> <C> caption <WITH> TVmax <HAS> [BOLD] 3.87 <C> attention relevance <WITH> TVmax <HAS> [BOLD] 4.10 <C> <CAP> Table 2: Human evaluation results on MSCOCO.
 <R> <C> Att. to image <WITH> softmax <HAS> ✓ <C> Att. to bounding boxes <WITH> softmax <HAS> [EMPTY] <C> Test-Dev Yes/No <WITH> softmax <HAS> 83.08 <C> Test-Dev Number <WITH> softmax <HAS> 42.65 <C> Test-Dev Other <WITH> softmax <HAS> 55.74 <C> Test-Dev Overall <WITH> softmax <HAS> 65.52 <C> Test-Standard Yes/No <WITH> softmax <HAS> 83.55 <C> Test-Standard Number <WITH> softmax <HAS> 42.68 <C> Test-Standard Other <WITH> softmax <HAS> 56.01 <C> Test-Standard Overall <WITH> softmax <HAS> 65.97 <C> <R> <C> Att. to image <WITH> sparsemax <HAS> ✓ <C> Att. to bounding boxes <WITH> sparsemax <HAS> [EMPTY] <C> Test-Dev Yes/No <WITH> sparsemax <HAS> 83.08 <C> Test-Dev Number <WITH> sparsemax <HAS> 43.19 <C> Test-Dev Other <WITH> sparsemax <HAS> 55.79 <C> Test-Dev Overall <WITH> sparsemax <HAS> 65.60 <C> Test-Standard Yes/No <WITH> sparsemax <HAS> 83.33 <C> Test-Standard Number <WITH> sparsemax <HAS> 42.99 <C> Test-Standard Other <WITH> sparsemax <HAS> 56.06 <C> Test-Standard Overall <WITH> sparsemax <HAS> 65.94 <C> <R> <C> Att. to image <WITH> soft-TVmax <HAS> ✓ <C> Att. to bounding boxes <WITH> soft-TVmax <HAS> [EMPTY] <C> Test-Dev Yes/No <WITH> soft-TVmax <HAS> 83.13 <C> Test-Dev Number <WITH> soft-TVmax <HAS> 43.53 <C> Test-Dev Other <WITH> soft-TVmax <HAS> 56.01 <C> Test-Dev Overall <WITH> soft-TVmax <HAS> 65.76 <C> Test-Standard Yes/No <WITH> soft-TVmax <HAS> 83.63 <C> Test-Standard Number <WITH> soft-TVmax <HAS> 43.24 <C> Test-Standard Other <WITH> soft-TVmax <HAS> 56.10 <C> Test-Standard Overall <WITH> soft-TVmax <HAS> 66.11 <C> <R> <C> Att. to image <WITH> sparse-TVmax <HAS> ✓ <C> Att. to bounding boxes <WITH> sparse-TVmax <HAS> [EMPTY] <C> Test-Dev Yes/No <WITH> sparse-TVmax <HAS> 83.10 <C> Test-Dev Number <WITH> sparse-TVmax <HAS> 43.30 <C> Test-Dev Other <WITH> sparse-TVmax <HAS> 56.14 <C> Test-Dev Overall <WITH> sparse-TVmax <HAS> 65.79 <C> Test-Standard Yes/No <WITH> sparse-TVmax <HAS> 83.66 <C> Test-Standard Number <WITH> sparse-TVmax <HAS> 43.18 <C> Test-Standard Other <WITH> sparse-TVmax <HAS> 56.21 <C> Test-Standard Overall <WITH> sparse-TVmax <HAS> 66.17 <C> <R> <C> Att. to image <WITH> softmax <HAS> [EMPTY] <C> Att. to bounding boxes <WITH> softmax <HAS> ✓ <C> Test-Dev Yes/No <WITH> softmax <HAS> 85.14 <C> Test-Dev Number <WITH> softmax <HAS> 49.59 <C> Test-Dev Other <WITH> softmax <HAS> 58.72 <C> Test-Dev Overall <WITH> softmax <HAS> 68.57 <C> Test-Standard Yes/No <WITH> softmax <HAS> 85.56 <C> Test-Standard Number <WITH> softmax <HAS> 49.54 <C> Test-Standard Other <WITH> softmax <HAS> 59.11 <C> Test-Standard Overall <WITH> softmax <HAS> 69.04 <C> <R> <C> Att. to image <WITH> sparsemax <HAS> [EMPTY] <C> Att. to bounding boxes <WITH> sparsemax <HAS> ✓ <C> Test-Dev Yes/No <WITH> sparsemax <HAS> [BOLD] 85.40 <C> Test-Dev Number <WITH> sparsemax <HAS> [BOLD] 50.87 <C> Test-Dev Other <WITH> sparsemax <HAS> 58.67 <C> Test-Dev Overall <WITH> sparsemax <HAS> 68.79 <C> Test-Standard Yes/No <WITH> sparsemax <HAS> [BOLD] 85.80 <C> Test-Standard Number <WITH> sparsemax <HAS> 50.18 <C> Test-Standard Other <WITH> sparsemax <HAS> 59.08 <C> Test-Standard Overall <WITH> sparsemax <HAS> 69.19 <C> <R> <C> Att. to image <WITH> softmax <HAS> ✓ <C> Att. to bounding boxes <WITH> softmax <HAS> ✓ <C> Test-Dev Yes/No <WITH> softmax <HAS> 85.33 <C> Test-Dev Number <WITH> softmax <HAS> 50.49 <C> Test-Dev Other <WITH> softmax <HAS> 58.88 <C> Test-Dev Overall <WITH> softmax <HAS> 68.82 <C> Test-Standard Yes/No <WITH> softmax <HAS> 85.58 <C> Test-Standard Number <WITH> softmax <HAS> 50.42 <C> Test-Standard Other <WITH> softmax <HAS> 59.18 <C> Test-Standard Overall <WITH> softmax <HAS> 69.17 <C> <R> <C> Att. to image <WITH> sparse-TVmax <HAS> ✓ <C> Att. to bounding boxes <WITH> sparse-TVmax <HAS> ✓ <C> Test-Dev Yes/No <WITH> sparse-TVmax <HAS> 85.35 <C> Test-Dev Number <WITH> sparse-TVmax <HAS> 50.52 <C> Test-Dev Other <WITH> sparse-TVmax <HAS> [BOLD] 59.15 <C> Test-Dev Overall <WITH> sparse-TVmax <HAS> [BOLD] 68.96 <C> Test-Standard Yes/No <WITH> sparse-TVmax <HAS> 85.72 <C> Test-Standard Number <WITH> sparse-TVmax <HAS> [BOLD] 50.66 <C> Test-Standard Other <WITH> sparse-TVmax <HAS> [BOLD] 59.22 <C> Test-Standard Overall <WITH> sparse-TVmax <HAS> [BOLD] 69.28 <C> <CAP> Table 3: Automatic evaluation of VQA on VQA-2.0. Sparse-TVmax and soft-TVmax correspond to using sparsemax or softmax on the image self-attention and TVmax on the output attention. Other models use softmax or sparsemax on self-attention and output attention.
 <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Bengali <HAS> 91.243 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Bengali <HAS> 99.493 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Bengali <HAS> 82.580 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Bengali <HAS> 99.170 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Bengali <HAS> 93.694 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Bengali <HAS> 99.865 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Czech <HAS> 94.035 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Czech <HAS> 99.264 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Czech <HAS> 91.560 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Czech <HAS> 99.154 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Czech <HAS> 97.795 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Czech <HAS> 99.909 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Danish <HAS> 84.605 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Danish <HAS> 98.435 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Danish <HAS> 71.805 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Danish <HAS> 97.160 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Danish <HAS> 90.103 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Danish <HAS> 99.444 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Dutch <HAS> 85.332 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Dutch <HAS> 98.448 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Dutch <HAS> 72.800 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Dutch <HAS> 96.675 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Dutch <HAS> 91.159 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Dutch <HAS> 99.305 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> English <HAS> 97.260 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> English <HAS> 99.897 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> English <HAS> 93.220 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> English <HAS> 99.700 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> English <HAS> 98.050 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> English <HAS> 99.884 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Finnish <HAS> 97.735 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Finnish <HAS> 99.855 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Finnish <HAS> 94.510 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Finnish <HAS> 99.685 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Finnish <HAS> 98.681 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Finnish <HAS> 99.972 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> French <HAS> 84.332 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> French <HAS> 98.483 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> French <HAS> 72.570 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> French <HAS> 97.215 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> French <HAS> 91.165 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> French <HAS> 99.412 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> German <HAS> 86.870 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> German <HAS> 98.882 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> German <HAS> 73.920 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> German <HAS> 97.550 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> German <HAS> 91.448 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> German <HAS> 99.509 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Greek <HAS> 82.549 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Greek <HAS> 97.800 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Greek <HAS> 71.925 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Greek <HAS> 96.910 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Greek <HAS> 90.291 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Greek <HAS> 99.386 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Hebrew <HAS> 94.180 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Hebrew <HAS> 99.672 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Hebrew <HAS> 88.491 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Hebrew <HAS> 99.201 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Hebrew <HAS> 95.414 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Hebrew <HAS> 99.706 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Hindi <HAS> 81.610 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Hindi <HAS> 97.638 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Hindi <HAS> 67.730 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Hindi <HAS> 96.200 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Hindi <HAS> 86.274 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Hindi <HAS> 99.169 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Indonesian <HAS> 94.735 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Indonesian <HAS> 99.838 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Indonesian <HAS> 89.035 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Indonesian <HAS> 99.560 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Indonesian <HAS> 96.745 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Indonesian <HAS> 99.910 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Italian <HAS> 88.865 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Italian <HAS> 99.142 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Italian <HAS> 78.765 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Italian <HAS> 98.270 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Italian <HAS> 93.400 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Italian <HAS> 99.775 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Marathi <HAS> 92.392 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Marathi <HAS> 99.493 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Marathi <HAS> 85.145 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Marathi <HAS> 99.025 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Marathi <HAS> 95.449 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Marathi <HAS> 99.905 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Polish <HAS> 94.918 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Polish <HAS> 99.743 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Polish <HAS> 90.280 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Polish <HAS> 99.705 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Polish <HAS> 97.454 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Polish <HAS> 99.954 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Portuguese <HAS> 86.422 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Portuguese <HAS> 98.903 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Portuguese <HAS> 71.735 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Portuguese <HAS> 97.685 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Portuguese <HAS> 90.787 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Portuguese <HAS> 99.562 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Romanian <HAS> 94.925 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Romanian <HAS> 99.575 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Romanian <HAS> 90.805 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Romanian <HAS> 99.245 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Romanian <HAS> 97.119 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Romanian <HAS> 99.845 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Russian <HAS> 93.285 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Russian <HAS> 99.502 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Russian <HAS> 89.000 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Russian <HAS> 99.240 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Russian <HAS> 97.196 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Russian <HAS> 99.942 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Spanish <HAS> 84.535 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Spanish <HAS> 98.210 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Spanish <HAS> 71.345 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Spanish <HAS> 96.645 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Spanish <HAS> 90.395 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Spanish <HAS> 99.246 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Swedish <HAS> 87.195 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Swedish <HAS> 98.865 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Swedish <HAS> 76.940 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Swedish <HAS> 97.645 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Swedish <HAS> 92.828 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Swedish <HAS> 99.656 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Tamil <HAS> 98.118 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Tamil <HAS> 99.990 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Tamil <HAS> 96.920 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Tamil <HAS> 99.990 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Tamil <HAS> 99.284 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Tamil <HAS> 99.999 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Telugu <HAS> 97.323 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Telugu <HAS> 99.990 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Telugu <HAS> 93.935 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Telugu <HAS> 99.985 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Telugu <HAS> 97.897 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Telugu <HAS> 99.998 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Thai <HAS> 97.989 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Thai <HAS> 99.755 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Thai <HAS> 97.238 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Thai <HAS> 99.448 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Thai <HAS> 98.859 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Thai <HAS> 99.986 <C> <R> <C> [BOLD] Random Character  [BOLD] P@1 <WITH> Turkish <HAS> 97.045 <C> [BOLD] Random Character  [BOLD] P@10 <WITH> Turkish <HAS> 99.880 <C> [BOLD] Characters Swap  [BOLD] P@1 <WITH> Turkish <HAS> 93.195 <C> [BOLD] Characters Swap  [BOLD] P@10 <WITH> Turkish <HAS> 99.815 <C> [BOLD] Character Bigrams  [BOLD] P@1 <WITH> Turkish <HAS> 98.257 <C> [BOLD] Character Bigrams  [BOLD] P@10 <WITH> Turkish <HAS> 99.972 <C> <CAP> TABLE IV: Synthetic Data Performance on three error generation algorithm
 <R> <C> [BOLD] Trie <WITH> 3 <HAS> 170.50 <C> [BOLD] DAWGs <WITH> 3 <HAS> 180.98 <C> [BOLD] SDA <WITH> 3 <HAS> 112.31 <C> <R> <C> [BOLD] Trie <WITH> 4 <HAS> 175.04 <C> [BOLD] DAWGs <WITH> 4 <HAS> 178.78 <C> [BOLD] SDA <WITH> 4 <HAS> 52.97 <C> <R> <C> [BOLD] Trie <WITH> 5 <HAS> 220.44 <C> [BOLD] DAWGs <WITH> 5 <HAS> 225.10 <C> [BOLD] SDA <WITH> 5 <HAS> 25.44 <C> <R> <C> [BOLD] Trie <WITH> 6 <HAS> 254.57 <C> [BOLD] DAWGs <WITH> 6 <HAS> 259.54 <C> [BOLD] SDA <WITH> 6 <HAS> 7.44 <C> <R> <C> [BOLD] Trie <WITH> 7 <HAS> 287.19 <C> [BOLD] DAWGs <WITH> 7 <HAS> 291.99 <C> [BOLD] SDA <WITH> 7 <HAS> 4.59 <C> <R> <C> [BOLD] Trie <WITH> 8 <HAS> 315.78 <C> [BOLD] DAWGs <WITH> 8 <HAS> 321.58 <C> [BOLD] SDA <WITH> 8 <HAS> 2.58 <C> <R> <C> [BOLD] Trie <WITH> 9 <HAS> 351.19 <C> [BOLD] DAWGs <WITH> 9 <HAS> 356.76 <C> [BOLD] SDA <WITH> 9 <HAS> 1.91 <C> <R> <C> [BOLD] Trie <WITH> 10 <HAS> 379.99 <C> [BOLD] DAWGs <WITH> 10 <HAS> 386.04 <C> [BOLD] SDA <WITH> 10 <HAS> 1.26 <C> <R> <C> [BOLD] Trie <WITH> 11 <HAS> 412.02 <C> [BOLD] DAWGs <WITH> 11 <HAS> 419.55 <C> [BOLD] SDA <WITH> 11 <HAS> 1.18 <C> <R> <C> [BOLD] Trie <WITH> 12 <HAS> 436.54 <C> [BOLD] DAWGs <WITH> 12 <HAS> 443.85 <C> [BOLD] SDA <WITH> 12 <HAS> 1.06 <C> <R> <C> [BOLD] Trie <WITH> 13 <HAS> 473.45 <C> [BOLD] DAWGs <WITH> 13 <HAS> 480.26 <C> [BOLD] SDA <WITH> 13 <HAS> 1.16 <C> <R> <C> [BOLD] Trie <WITH> 14 <HAS> 508.08 <C> [BOLD] DAWGs <WITH> 14 <HAS> 515.04 <C> [BOLD] SDA <WITH> 14 <HAS> 0.97 <C> <R> <C> [BOLD] Trie <WITH> 15 <HAS> 548.04 <C> [BOLD] DAWGs <WITH> 15 <HAS> 553.49 <C> [BOLD] SDA <WITH> 15 <HAS> 0.66 <C> <R> <C> [BOLD] Trie <WITH> 16 <HAS> 580.44 <C> [BOLD] DAWGs <WITH> 16 <HAS> 584.99 <C> [BOLD] SDA <WITH> 16 <HAS> 0.37 <C> <CAP> TABLE I: Average Time taken by suggestion generation algorithms (Edit Distance = 2) (in millisecond)
 <R> <C> [BOLD] # Test <WITH> [BOLD] Language <HAS> [BOLD] Samples <C> [BOLD] P@1 <WITH> [BOLD] Language <HAS> [BOLD] P@1 <C> [BOLD] P@3 <WITH> [BOLD] Language <HAS> [BOLD] P@3 <C> [BOLD] P@5 <WITH> [BOLD] Language <HAS> [BOLD] P@5 <C> [BOLD] P@10 <WITH> [BOLD] Language <HAS> [BOLD] P@10 <C> [BOLD] MRR <WITH> [BOLD] Language <HAS> [BOLD] MRR <C> <R> <C> [BOLD] # Test <WITH> Bengali <HAS> 140000 <C> [BOLD] P@1 <WITH> Bengali <HAS> 91.30 <C> [BOLD] P@3 <WITH> Bengali <HAS> 97.83 <C> [BOLD] P@5 <WITH> Bengali <HAS> 98.94 <C> [BOLD] P@10 <WITH> Bengali <HAS> 99.65 <C> [BOLD] MRR <WITH> Bengali <HAS> 94.68 <C> <R> <C> [BOLD] # Test <WITH> Czech <HAS> 94205 <C> [BOLD] P@1 <WITH> Czech <HAS> 95.84 <C> [BOLD] P@3 <WITH> Czech <HAS> 98.72 <C> [BOLD] P@5 <WITH> Czech <HAS> 99.26 <C> [BOLD] P@10 <WITH> Czech <HAS> 99.62 <C> [BOLD] MRR <WITH> Czech <HAS> 97.37 <C> <R> <C> [BOLD] # Test <WITH> Danish <HAS> 140000 <C> [BOLD] P@1 <WITH> Danish <HAS> 85.84 <C> [BOLD] P@3 <WITH> Danish <HAS> 95.19 <C> [BOLD] P@5 <WITH> Danish <HAS> 97.28 <C> [BOLD] P@10 <WITH> Danish <HAS> 98.83 <C> [BOLD] MRR <WITH> Danish <HAS> 90.85 <C> <R> <C> [BOLD] # Test <WITH> Dutch <HAS> 140000 <C> [BOLD] P@1 <WITH> Dutch <HAS> 86.83 <C> [BOLD] P@3 <WITH> Dutch <HAS> 95.01 <C> [BOLD] P@5 <WITH> Dutch <HAS> 97.04 <C> [BOLD] P@10 <WITH> Dutch <HAS> 98.68 <C> [BOLD] MRR <WITH> Dutch <HAS> 91.32 <C> <R> <C> [BOLD] # Test <WITH> English <HAS> 140000 <C> [BOLD] P@1 <WITH> English <HAS> 97.08 <C> [BOLD] P@3 <WITH> English <HAS> 99.39 <C> [BOLD] P@5 <WITH> English <HAS> 99.67 <C> [BOLD] P@10 <WITH> English <HAS> 99.86 <C> [BOLD] MRR <WITH> English <HAS> 98.27 <C> <R> <C> [BOLD] # Test <WITH> Finnish <HAS> 140000 <C> [BOLD] P@1 <WITH> Finnish <HAS> 97.77 <C> [BOLD] P@3 <WITH> Finnish <HAS> 99.58 <C> [BOLD] P@5 <WITH> Finnish <HAS> 99.79 <C> [BOLD] P@10 <WITH> Finnish <HAS> 99.90 <C> [BOLD] MRR <WITH> Finnish <HAS> 98.69 <C> <R> <C> [BOLD] # Test <WITH> French <HAS> 140000 <C> [BOLD] P@1 <WITH> French <HAS> 86.52 <C> [BOLD] P@3 <WITH> French <HAS> 95.66 <C> [BOLD] P@5 <WITH> French <HAS> 97.52 <C> [BOLD] P@10 <WITH> French <HAS> 98.83 <C> [BOLD] MRR <WITH> French <HAS> 91.38 <C> <R> <C> [BOLD] # Test <WITH> German <HAS> 140000 <C> [BOLD] P@1 <WITH> German <HAS> 87.58 <C> [BOLD] P@3 <WITH> German <HAS> 96.16 <C> [BOLD] P@5 <WITH> German <HAS> 97.86 <C> [BOLD] P@10 <WITH> German <HAS> 99.05 <C> [BOLD] MRR <WITH> German <HAS> 92.10 <C> <R> <C> [BOLD] # Test <WITH> Greek <HAS> 30022 <C> [BOLD] P@1 <WITH> Greek <HAS> 84.95 <C> [BOLD] P@3 <WITH> Greek <HAS> 94.99 <C> [BOLD] P@5 <WITH> Greek <HAS> 96.88 <C> [BOLD] P@10 <WITH> Greek <HAS> 98.44 <C> [BOLD] MRR <WITH> Greek <HAS> 90.27 <C> <R> <C> [BOLD] # Test <WITH> Hebrew <HAS> 132596 <C> [BOLD] P@1 <WITH> Hebrew <HAS> 94.00 <C> [BOLD] P@3 <WITH> Hebrew <HAS> 98.26 <C> [BOLD] P@5 <WITH> Hebrew <HAS> 99.05 <C> [BOLD] P@10 <WITH> Hebrew <HAS> 99.62 <C> [BOLD] MRR <WITH> Hebrew <HAS> 96.24 <C> <R> <C> [BOLD] # Test <WITH> Hindi <HAS> 140000 <C> [BOLD] P@1 <WITH> Hindi <HAS> 82.19 <C> [BOLD] P@3 <WITH> Hindi <HAS> 93.71 <C> [BOLD] P@5 <WITH> Hindi <HAS> 96.28 <C> [BOLD] P@10 <WITH> Hindi <HAS> 98.30 <C> [BOLD] MRR <WITH> Hindi <HAS> 88.40 <C> <R> <C> [BOLD] # Test <WITH> Indonesian <HAS> 140000 <C> [BOLD] P@1 <WITH> Indonesian <HAS> 95.01 <C> [BOLD] P@3 <WITH> Indonesian <HAS> 98.98 <C> [BOLD] P@5 <WITH> Indonesian <HAS> 99.50 <C> [BOLD] P@10 <WITH> Indonesian <HAS> 99.84 <C> [BOLD] MRR <WITH> Indonesian <HAS> 97.04 <C> <R> <C> [BOLD] # Test <WITH> Italian <HAS> 140000 <C> [BOLD] P@1 <WITH> Italian <HAS> 89.93 <C> [BOLD] P@3 <WITH> Italian <HAS> 97.31 <C> [BOLD] P@5 <WITH> Italian <HAS> 98.54 <C> [BOLD] P@10 <WITH> Italian <HAS> 99.38 <C> [BOLD] MRR <WITH> Italian <HAS> 93.76 <C> <R> <C> [BOLD] # Test <WITH> Marathi <HAS> 140000 <C> [BOLD] P@1 <WITH> Marathi <HAS> 93.01 <C> [BOLD] P@3 <WITH> Marathi <HAS> 98.16 <C> [BOLD] P@5 <WITH> Marathi <HAS> 99.06 <C> [BOLD] P@10 <WITH> Marathi <HAS> 99.66 <C> [BOLD] MRR <WITH> Marathi <HAS> 95.69 <C> <R> <C> [BOLD] # Test <WITH> Polish <HAS> 140000 <C> [BOLD] P@1 <WITH> Polish <HAS> 95.65 <C> [BOLD] P@3 <WITH> Polish <HAS> 99.17 <C> [BOLD] P@5 <WITH> Polish <HAS> 99.62 <C> [BOLD] P@10 <WITH> Polish <HAS> 99.86 <C> [BOLD] MRR <WITH> Polish <HAS> 97.44 <C> <R> <C> [BOLD] # Test <WITH> Portuguese <HAS> 140000 <C> [BOLD] P@1 <WITH> Portuguese <HAS> 86.73 <C> [BOLD] P@3 <WITH> Portuguese <HAS> 96.29 <C> [BOLD] P@5 <WITH> Portuguese <HAS> 97.94 <C> [BOLD] P@10 <WITH> Portuguese <HAS> 99.10 <C> [BOLD] MRR <WITH> Portuguese <HAS> 91.74 <C> <R> <C> [BOLD] # Test <WITH> Romanian <HAS> 140000 <C> [BOLD] P@1 <WITH> Romanian <HAS> 95.52 <C> [BOLD] P@3 <WITH> Romanian <HAS> 98.79 <C> [BOLD] P@5 <WITH> Romanian <HAS> 99.32 <C> [BOLD] P@10 <WITH> Romanian <HAS> 99.68 <C> [BOLD] MRR <WITH> Romanian <HAS> 97.22 <C> <R> <C> [BOLD] # Test <WITH> Russian <HAS> 140000 <C> [BOLD] P@1 <WITH> Russian <HAS> 94.85 <C> [BOLD] P@3 <WITH> Russian <HAS> 98.74 <C> [BOLD] P@5 <WITH> Russian <HAS> 99.33 <C> [BOLD] P@10 <WITH> Russian <HAS> 99.71 <C> [BOLD] MRR <WITH> Russian <HAS> 96.86 <C> <R> <C> [BOLD] # Test <WITH> Spanish <HAS> 140000 <C> [BOLD] P@1 <WITH> Spanish <HAS> 85.91 <C> [BOLD] P@3 <WITH> Spanish <HAS> 95.35 <C> [BOLD] P@5 <WITH> Spanish <HAS> 97.18 <C> [BOLD] P@10 <WITH> Spanish <HAS> 98.57 <C> [BOLD] MRR <WITH> Spanish <HAS> 90.92 <C> <R> <C> [BOLD] # Test <WITH> Swedish <HAS> 140000 <C> [BOLD] P@1 <WITH> Swedish <HAS> 88.86 <C> [BOLD] P@3 <WITH> Swedish <HAS> 96.40 <C> [BOLD] P@5 <WITH> Swedish <HAS> 98.00 <C> [BOLD] P@10 <WITH> Swedish <HAS> 99.14 <C> [BOLD] MRR <WITH> Swedish <HAS> 92.87 <C> <R> <C> [BOLD] # Test <WITH> Tamil <HAS> 140000 <C> [BOLD] P@1 <WITH> Tamil <HAS> 98.05 <C> [BOLD] P@3 <WITH> Tamil <HAS> 99.70 <C> [BOLD] P@5 <WITH> Tamil <HAS> 99.88 <C> [BOLD] P@10 <WITH> Tamil <HAS> 99.98 <C> [BOLD] MRR <WITH> Tamil <HAS> 98.88 <C> <R> <C> [BOLD] # Test <WITH> Telugu <HAS> 140000 <C> [BOLD] P@1 <WITH> Telugu <HAS> 97.11 <C> [BOLD] P@3 <WITH> Telugu <HAS> 99.68 <C> [BOLD] P@5 <WITH> Telugu <HAS> 99.92 <C> [BOLD] P@10 <WITH> Telugu <HAS> 99.99 <C> [BOLD] MRR <WITH> Telugu <HAS> 98.38 <C> <R> <C> [BOLD] # Test <WITH> Thai <HAS> 12403 <C> [BOLD] P@1 <WITH> Thai <HAS> 98.73 <C> [BOLD] P@3 <WITH> Thai <HAS> 99.71 <C> [BOLD] P@5 <WITH> Thai <HAS> 99.78 <C> [BOLD] P@10 <WITH> Thai <HAS> 99.85 <C> [BOLD] MRR <WITH> Thai <HAS> 99.22 <C> <R> <C> [BOLD] # Test <WITH> Turkish <HAS> 140000 <C> [BOLD] P@1 <WITH> Turkish <HAS> 97.13 <C> [BOLD] P@3 <WITH> Turkish <HAS> 99.51 <C> [BOLD] P@5 <WITH> Turkish <HAS> 99.78 <C> [BOLD] P@10 <WITH> Turkish <HAS> 99.92 <C> [BOLD] MRR <WITH> Turkish <HAS> 98.33 <C> <CAP> TABLE II: Synthetic Data Performance results
 <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Bengali <HAS> 7.20 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Bengali <HAS> 0.48 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Bengali <HAS> 14.85 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Bengali <HAS> 1.14 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Czech <HAS> 7.81 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Czech <HAS> 0.75 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Czech <HAS> 26.67 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Czech <HAS> 2.34 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Danish <HAS> 7.28 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Danish <HAS> 0.67 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Danish <HAS> 23.70 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Danish <HAS> 1.96 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Dutch <HAS> 10.80 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Dutch <HAS> 0.81 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Dutch <HAS> 30.44 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Dutch <HAS> 2.40 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> English <HAS> 7.27 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> English <HAS> 0.79 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> English <HAS> 39.36 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> English <HAS> 2.35 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Finnish <HAS> 8.53 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Finnish <HAS> 0.46 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Finnish <HAS> 15.55 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Finnish <HAS> 1.05 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> French <HAS> 7.19 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> French <HAS> 0.82 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> French <HAS> 32.02 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> French <HAS> 2.69 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> German <HAS> 8.65 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> German <HAS> 0.85 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> German <HAS> 41.18 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> German <HAS> 2.63 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Greek <HAS> 7.63 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Greek <HAS> 0.86 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Greek <HAS> 25.40 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Greek <HAS> 1.87 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Hebrew <HAS> 22.35 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Hebrew <HAS> 1.01 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Hebrew <HAS> 49.91 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Hebrew <HAS> 2.18 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Hindi <HAS> 8.50 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Hindi <HAS> 0.60 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Hindi <HAS> 18.51 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Hindi <HAS> 1.72 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Indonesian <HAS> 12.00 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Indonesian <HAS> 0.49 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Indonesian <HAS> 20.75 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Indonesian <HAS> 1.22 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Italian <HAS> 6.92 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Italian <HAS> 0.72 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Italian <HAS> 29.02 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Italian <HAS> 2.17 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Marathi <HAS> 7.16 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Marathi <HAS> 0.43 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Marathi <HAS> 10.68 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Marathi <HAS> 0.97 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Polish <HAS> 6.44 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Polish <HAS> 0.64 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Polish <HAS> 24.15 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Polish <HAS> 1.74 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Portuguese <HAS> 7.14 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Portuguese <HAS> 0.66 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Portuguese <HAS> 28.92 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Portuguese <HAS> 2.20 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Romanian <HAS> 10.26 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Romanian <HAS> 0.63 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Romanian <HAS> 18.83 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Romanian <HAS> 1.79 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Russian <HAS> 6.79 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Russian <HAS> 0.68 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Russian <HAS> 22.56 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Russian <HAS> 1.72 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Spanish <HAS> 7.19 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Spanish <HAS> 0.75 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Spanish <HAS> 31.00 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Spanish <HAS> 2.41 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Swedish <HAS> 7.76 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Swedish <HAS> 0.83 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Swedish <HAS> 32.17 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Swedish <HAS> 2.57 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Tamil <HAS> 11.34 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Tamil <HAS> 0.23 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Tamil <HAS> 4.83 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Tamil <HAS> 0.31 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Telugu <HAS> 6.31 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Telugu <HAS> 0.29 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Telugu <HAS> 7.50 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Telugu <HAS> 0.54 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Thai <HAS> 11.60 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Thai <HAS> 0.66 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Thai <HAS> 18.75 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Thai <HAS> 1.33 <C> <R> <C> [BOLD] Detection  [BOLD] Time ( [ITALIC] μs) <WITH> Turkish <HAS> 7.40 <C> [BOLD] Suggestion Time  [BOLD] ED=1 (ms) <WITH> Turkish <HAS> 0.49 <C> [BOLD] Suggestion Time  [BOLD] ED=2 (ms) <WITH> Turkish <HAS> 17.42 <C> [BOLD] Ranking  [BOLD] Time (ms) <WITH> Turkish <HAS> 1.23 <C> <CAP> TABLE III: Synthetic Data Time Performance results
 <R> <C> [BOLD] P@1 <WITH> Aspell <HAS> 60.82 <C> [BOLD] P@3 <WITH> Aspell <HAS> 80.81 <C> [BOLD] P@5 <WITH> Aspell <HAS> 87.26 <C> [BOLD] P@10 <WITH> Aspell <HAS> 91.35 <C> <R> <C> [BOLD] P@1 <WITH> Hunspell <HAS> 61.34 <C> [BOLD] P@3 <WITH> Hunspell <HAS> 77.86 <C> [BOLD] P@5 <WITH> Hunspell <HAS> 83.47 <C> [BOLD] P@10 <WITH> Hunspell <HAS> 87.04 <C> <R> <C> [BOLD] P@1 <WITH> [ITALIC] Ours <HAS> 68.99 <C> [BOLD] P@3 <WITH> [ITALIC] Ours <HAS> 83.43 <C> [BOLD] P@5 <WITH> [ITALIC] Ours <HAS> 87.03 <C> [BOLD] P@10 <WITH> [ITALIC] Ours <HAS> 90.16 <C> <CAP> TABLE VI: Public dataset comparison results
 <R> <C> [BOLD] # Sentences <WITH> Bengali <HAS> 663748 <C> [BOLD] # Total Words <WITH> Bengali <HAS> 457140 <C> [BOLD] # Detected <WITH> Bengali <HAS> 443650 <C> [BOLD] % <WITH> Bengali <HAS> 97.05 <C> <R> <C> [BOLD] # Sentences <WITH> Czech <HAS> 6128 <C> [BOLD] # Total Words <WITH> Czech <HAS> 36846 <C> [BOLD] # Detected <WITH> Czech <HAS> 36072 <C> [BOLD] % <WITH> Czech <HAS> 97.90 <C> <R> <C> [BOLD] # Sentences <WITH> Danish <HAS> 16198 <C> [BOLD] # Total Words <WITH> Danish <HAS> 102883 <C> [BOLD] # Detected <WITH> Danish <HAS> 101798 <C> [BOLD] % <WITH> Danish <HAS> 98.95 <C> <R> <C> [BOLD] # Sentences <WITH> Dutch <HAS> 55125 <C> [BOLD] # Total Words <WITH> Dutch <HAS> 1048256 <C> [BOLD] # Detected <WITH> Dutch <HAS> 1004274 <C> [BOLD] % <WITH> Dutch <HAS> 95.80 <C> <R> <C> [BOLD] # Sentences <WITH> English <HAS> 239555 <C> [BOLD] # Total Words <WITH> English <HAS> 4981604 <C> [BOLD] # Detected <WITH> English <HAS> 4907733 <C> [BOLD] % <WITH> English <HAS> 98.52 <C> <R> <C> [BOLD] # Sentences <WITH> Finnish <HAS> 3757 <C> [BOLD] # Total Words <WITH> Finnish <HAS> 43457 <C> [BOLD] # Detected <WITH> Finnish <HAS> 39989 <C> [BOLD] % <WITH> Finnish <HAS> 92.02 <C> <R> <C> [BOLD] # Sentences <WITH> French <HAS> 164916 <C> [BOLD] # Total Words <WITH> French <HAS> 3244367 <C> [BOLD] # Detected <WITH> French <HAS> 3187587 <C> [BOLD] % <WITH> French <HAS> 98.25 <C> <R> <C> [BOLD] # Sentences <WITH> German <HAS> 71025 <C> [BOLD] # Total Words <WITH> German <HAS> 1283239 <C> [BOLD] # Detected <WITH> German <HAS> 1250232 <C> [BOLD] % <WITH> German <HAS> 97.43 <C> <R> <C> [BOLD] # Sentences <WITH> Greek <HAS> 1586 <C> [BOLD] # Total Words <WITH> Greek <HAS> 43035 <C> [BOLD] # Detected <WITH> Greek <HAS> 42086 <C> [BOLD] % <WITH> Greek <HAS> 97.79 <C> <R> <C> [BOLD] # Sentences <WITH> Hebrew <HAS> 95813 <C> [BOLD] # Total Words <WITH> Hebrew <HAS> 505335 <C> [BOLD] # Detected <WITH> Hebrew <HAS> 494481 <C> [BOLD] % <WITH> Hebrew <HAS> 97.85 <C> <R> <C> [BOLD] # Sentences <WITH> Hindi <HAS> 5089 <C> [BOLD] # Total Words <WITH> Hindi <HAS> 37617 <C> [BOLD] # Detected <WITH> Hindi <HAS> 37183 <C> [BOLD] % <WITH> Hindi <HAS> 98.85 <C> <R> <C> [BOLD] # Sentences <WITH> Indonesian <HAS> 100248 <C> [BOLD] # Total Words <WITH> Indonesian <HAS> 84347 <C> [BOLD] # Detected <WITH> Indonesian <HAS> 82809 <C> [BOLD] % <WITH> Indonesian <HAS> 98.18 <C> <R> <C> [BOLD] # Sentences <WITH> Italian <HAS> 36026 <C> [BOLD] # Total Words <WITH> Italian <HAS> 718774 <C> [BOLD] # Detected <WITH> Italian <HAS> 703514 <C> [BOLD] % <WITH> Italian <HAS> 97.88 <C> <R> <C> [BOLD] # Sentences <WITH> Marathi <HAS> 17007 <C> [BOLD] # Total Words <WITH> Marathi <HAS> 84286 <C> [BOLD] # Detected <WITH> Marathi <HAS> 79866 <C> [BOLD] % <WITH> Marathi <HAS> 94.76 <C> <R> <C> [BOLD] # Sentences <WITH> Polish <HAS> 3283 <C> [BOLD] # Total Words <WITH> Polish <HAS> 34226 <C> [BOLD] # Detected <WITH> Polish <HAS> 32780 <C> [BOLD] % <WITH> Polish <HAS> 95.78 <C> <R> <C> [BOLD] # Sentences <WITH> Portuguese <HAS> 1453 <C> [BOLD] # Total Words <WITH> Portuguese <HAS> 25568 <C> [BOLD] # Detected <WITH> Portuguese <HAS> 25455 <C> [BOLD] % <WITH> Portuguese <HAS> 99.56 <C> <R> <C> [BOLD] # Sentences <WITH> Romanian <HAS> 4786 <C> [BOLD] # Total Words <WITH> Romanian <HAS> 34862 <C> [BOLD] # Detected <WITH> Romanian <HAS> 34091 <C> [BOLD] % <WITH> Romanian <HAS> 97.79 <C> <R> <C> [BOLD] # Sentences <WITH> Russian <HAS> 27252 <C> [BOLD] # Total Words <WITH> Russian <HAS> 384262 <C> [BOLD] # Detected <WITH> Russian <HAS> 372979 <C> [BOLD] % <WITH> Russian <HAS> 97.06 <C> <R> <C> [BOLD] # Sentences <WITH> Spanish <HAS> 108017 <C> [BOLD] # Total Words <WITH> Spanish <HAS> 2057481 <C> [BOLD] # Detected <WITH> Spanish <HAS> 2028951 <C> [BOLD] % <WITH> Spanish <HAS> 98.61 <C> <R> <C> [BOLD] # Sentences <WITH> Swedish <HAS> 3209 <C> [BOLD] # Total Words <WITH> Swedish <HAS> 66191 <C> [BOLD] # Detected <WITH> Swedish <HAS> 64649 <C> [BOLD] % <WITH> Swedish <HAS> 97.67 <C> <R> <C> [BOLD] # Sentences <WITH> Tamil <HAS> 40165 <C> [BOLD] # Total Words <WITH> Tamil <HAS> 21044 <C> [BOLD] # Detected <WITH> Tamil <HAS> 19526 <C> [BOLD] % <WITH> Tamil <HAS> 92.79 <C> <R> <C> [BOLD] # Sentences <WITH> Telugu <HAS> 30466 <C> [BOLD] # Total Words <WITH> Telugu <HAS> 17710 <C> [BOLD] # Detected <WITH> Telugu <HAS> 17108 <C> [BOLD] % <WITH> Telugu <HAS> 96.60 <C> <R> <C> [BOLD] # Sentences <WITH> Thai <HAS> 16032 <C> [BOLD] # Total Words <WITH> Thai <HAS> 67507 <C> [BOLD] # Detected <WITH> Thai <HAS> 49744 <C> [BOLD] % <WITH> Thai <HAS> 73.69 <C> <R> <C> [BOLD] # Sentences <WITH> Turkish <HAS> 163910 <C> [BOLD] # Total Words <WITH> Turkish <HAS> 794098 <C> [BOLD] # Detected <WITH> Turkish <HAS> 775776 <C> [BOLD] % <WITH> Turkish <HAS> 97.69 <C> <CAP> TABLE VII: False Positive Experiment Results
 <R> <C> F&B <WITH> [BOLD] Train <HAS> [EMPTY] <C> A <WITH> [BOLD] Train <HAS> [EMPTY] <C> R <WITH> [BOLD] Train <HAS> [EMPTY] <C> Ca <WITH> [BOLD] Train <HAS> [EMPTY] <C> Se <WITH> [BOLD] Train <HAS> [EMPTY] <C> So <WITH> [BOLD] Train <HAS> [EMPTY] <C> T <WITH> [BOLD] Train <HAS> [EMPTY] <C> E <WITH> [BOLD] Train <HAS> [EMPTY] <C> O <WITH> [BOLD] Train <HAS> [EMPTY] <C> <R> <C> F&B <WITH> Food & Bev. <HAS> – <C> A <WITH> Food & Bev. <HAS> 58.1 <C> R <WITH> Food & Bev. <HAS> 52.5 <C> Ca <WITH> Food & Bev. <HAS> 66.4 <C> Se <WITH> Food & Bev. <HAS> 59.7 <C> So <WITH> Food & Bev. <HAS> 58.9 <C> T <WITH> Food & Bev. <HAS> 54.1 <C> E <WITH> Food & Bev. <HAS> 61.4 <C> O <WITH> Food & Bev. <HAS> 53.7 <C> <R> <C> F&B <WITH> Apparel <HAS> 63.9 <C> A <WITH> Apparel <HAS> – <C> R <WITH> Apparel <HAS> 74.4 <C> Ca <WITH> Apparel <HAS> 65.1 <C> Se <WITH> Apparel <HAS> 70.8 <C> So <WITH> Apparel <HAS> 71.2 <C> T <WITH> Apparel <HAS> 68.5 <C> E <WITH> Apparel <HAS> 76.9 <C> O <WITH> Apparel <HAS> 85.6 <C> <R> <C> F&B <WITH> Retail <HAS> 58.8 <C> A <WITH> Retail <HAS> 74.4 <C> R <WITH> Retail <HAS> – <C> Ca <WITH> Retail <HAS> 70.1 <C> Se <WITH> Retail <HAS> 72.6 <C> So <WITH> Retail <HAS> 69.9 <C> T <WITH> Retail <HAS> 68.7 <C> E <WITH> Retail <HAS> 69.6 <C> O <WITH> Retail <HAS> 82.7 <C> <R> <C> F&B <WITH> Cars <HAS> 68.7 <C> A <WITH> Cars <HAS> 61.1 <C> R <WITH> Cars <HAS> 65.1 <C> Ca <WITH> Cars <HAS> – <C> Se <WITH> Cars <HAS> 58.8 <C> So <WITH> Cars <HAS> 67. <C> T <WITH> Cars <HAS> 59.3 <C> E <WITH> Cars <HAS> 62.9 <C> O <WITH> Cars <HAS> 68.2 <C> <R> <C> F&B <WITH> Services <HAS> 65. <C> A <WITH> Services <HAS> 74.2 <C> R <WITH> Services <HAS> 75.8 <C> Ca <WITH> Services <HAS> 74. <C> Se <WITH> Services <HAS> – <C> So <WITH> Services <HAS> 68.8 <C> T <WITH> Services <HAS> 74.2 <C> E <WITH> Services <HAS> 77.9 <C> O <WITH> Services <HAS> 77.9 <C> <R> <C> F&B <WITH> Software <HAS> 62. <C> A <WITH> Software <HAS> 74.2 <C> R <WITH> Software <HAS> 68. <C> Ca <WITH> Software <HAS> 67.9 <C> Se <WITH> Software <HAS> 72.8 <C> So <WITH> Software <HAS> – <C> T <WITH> Software <HAS> 72.8 <C> E <WITH> Software <HAS> 72.1 <C> O <WITH> Software <HAS> 80.6 <C> <R> <C> F&B <WITH> Transport <HAS> 59.3 <C> A <WITH> Transport <HAS> 71.7 <C> R <WITH> Transport <HAS> 72.4 <C> Ca <WITH> Transport <HAS> 67. <C> Se <WITH> Transport <HAS> 74.6 <C> So <WITH> Transport <HAS> 75. <C> T <WITH> Transport <HAS> – <C> E <WITH> Transport <HAS> 72.6 <C> O <WITH> Transport <HAS> 81.7 <C> <R> <C> F&B <WITH> Electronics <HAS> 61.6 <C> A <WITH> Electronics <HAS> 75.2 <C> R <WITH> Electronics <HAS> 71. <C> Ca <WITH> Electronics <HAS> 68. <C> Se <WITH> Electronics <HAS> 75. <C> So <WITH> Electronics <HAS> 69.9 <C> T <WITH> Electronics <HAS> 68.2 <C> E <WITH> Electronics <HAS> – <C> O <WITH> Electronics <HAS> 78.7 <C> <R> <C> F&B <WITH> Other <HAS> 56.1 <C> A <WITH> Other <HAS> 71.3 <C> R <WITH> Other <HAS> 72.4 <C> Ca <WITH> Other <HAS> 70.2 <C> Se <WITH> Other <HAS> 73.5 <C> So <WITH> Other <HAS> 67.2 <C> T <WITH> Other <HAS> 68.5 <C> E <WITH> Other <HAS> 71. <C> O <WITH> Other <HAS> – <C> <R> <C> F&B <WITH> All <HAS> 70.3 <C> A <WITH> All <HAS> 77.7 <C> R <WITH> All <HAS> 79.5 <C> Ca <WITH> All <HAS> 82.0 <C> Se <WITH> All <HAS> 79.6 <C> So <WITH> All <HAS> 80.1 <C> T <WITH> All <HAS> 76.8 <C> E <WITH> All <HAS> 81.7 <C> O <WITH> All <HAS> 88.2 <C> <CAP> Table 9: Performance of models trained with tweets from one domain and tested on other domains. All results are reported in ROC AUC. The All line displays results on training on all categories except the category in testing.
 <R> <C> [BOLD] Complaints <WITH> Food & Beverage <HAS> 95 <C> [BOLD] Not Complaints <WITH> Food & Beverage <HAS> 35 <C> <R> <C> [BOLD] Complaints <WITH> Apparel <HAS> 141 <C> [BOLD] Not Complaints <WITH> Apparel <HAS> 117 <C> <R> <C> [BOLD] Complaints <WITH> Retail <HAS> 124 <C> [BOLD] Not Complaints <WITH> Retail <HAS> 75 <C> <R> <C> [BOLD] Complaints <WITH> Cars <HAS> 67 <C> [BOLD] Not Complaints <WITH> Cars <HAS> 25 <C> <R> <C> [BOLD] Complaints <WITH> Services <HAS> 207 <C> [BOLD] Not Complaints <WITH> Services <HAS> 130 <C> <R> <C> [BOLD] Complaints <WITH> Software & Online Services <HAS> 189 <C> [BOLD] Not Complaints <WITH> Software & Online Services <HAS> 103 <C> <R> <C> [BOLD] Complaints <WITH> Transport <HAS> 139 <C> [BOLD] Not Complaints <WITH> Transport <HAS> 109 <C> <R> <C> [BOLD] Complaints <WITH> Electronics <HAS> 174 <C> [BOLD] Not Complaints <WITH> Electronics <HAS> 112 <C> <R> <C> [BOLD] Complaints <WITH> Other <HAS> 96 <C> [BOLD] Not Complaints <WITH> Other <HAS> 33 <C> <R> <C> [BOLD] Complaints <WITH> Total <HAS> 1232 <C> [BOLD] Not Complaints <WITH> Total <HAS> 739 <C> <CAP> Table 3: Number of tweets annotated as complaints across the nine domains.
 <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> [BOLD] Unigrams <HAS> [BOLD] Unigrams <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> [BOLD] Unigrams <HAS> [BOLD] Unigrams <C> [BOLD] Not Complaints  [ITALIC] r <WITH> [BOLD] Unigrams <HAS> [BOLD] Unigrams <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> not <HAS> .154 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> not <HAS> [URL] <C> [BOLD] Not Complaints  [ITALIC] r <WITH> not <HAS> .150 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> my <HAS> .131 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> my <HAS> ! <C> [BOLD] Not Complaints  [ITALIC] r <WITH> my <HAS> .082 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> working <HAS> .124 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> working <HAS> he <C> [BOLD] Not Complaints  [ITALIC] r <WITH> working <HAS> .069 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> still <HAS> .123 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> still <HAS> thank <C> [BOLD] Not Complaints  [ITALIC] r <WITH> still <HAS> .067 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> on <HAS> .119 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> on <HAS> , <C> [BOLD] Not Complaints  [ITALIC] r <WITH> on <HAS> .064 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> can’t <HAS> .113 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> can’t <HAS> love <C> [BOLD] Not Complaints  [ITALIC] r <WITH> can’t <HAS> .064 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> service <HAS> .112 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> service <HAS> lol <C> [BOLD] Not Complaints  [ITALIC] r <WITH> service <HAS> .061 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> customer <HAS> .109 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> customer <HAS> you <C> [BOLD] Not Complaints  [ITALIC] r <WITH> customer <HAS> .060 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> why <HAS> .108 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> why <HAS> great <C> [BOLD] Not Complaints  [ITALIC] r <WITH> why <HAS> .058 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> website <HAS> .107 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> website <HAS> win <C> [BOLD] Not Complaints  [ITALIC] r <WITH> website <HAS> .058 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> no <HAS> .104 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> no <HAS> ’ <C> [BOLD] Not Complaints  [ITALIC] r <WITH> no <HAS> .058 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> ? <HAS> .098 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> ? <HAS> she <C> [BOLD] Not Complaints  [ITALIC] r <WITH> ? <HAS> .054 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> fix <HAS> .093 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> fix <HAS> : <C> [BOLD] Not Complaints  [ITALIC] r <WITH> fix <HAS> .053 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> won’t <HAS> .092 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> won’t <HAS> that <C> [BOLD] Not Complaints  [ITALIC] r <WITH> won’t <HAS> .053 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> been <HAS> .090 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> been <HAS> more <C> [BOLD] Not Complaints  [ITALIC] r <WITH> been <HAS> .052 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> issue <HAS> .089 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> issue <HAS> it <C> [BOLD] Not Complaints  [ITALIC] r <WITH> issue <HAS> .052 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> days <HAS> .088 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> days <HAS> would <C> [BOLD] Not Complaints  [ITALIC] r <WITH> days <HAS> .051 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> error <HAS> .087 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> error <HAS> him <C> [BOLD] Not Complaints  [ITALIC] r <WITH> error <HAS> .047 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> is <HAS> .084 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> is <HAS> life <C> [BOLD] Not Complaints  [ITALIC] r <WITH> is <HAS> .046 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> charged <HAS> .083 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> charged <HAS> good <C> [BOLD] Not Complaints  [ITALIC] r <WITH> charged <HAS> .046 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> [BOLD] POS (Unigrams and Bigrams) <HAS> [BOLD] POS (Unigrams and Bigrams) <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> [BOLD] POS (Unigrams and Bigrams) <HAS> [BOLD] POS (Unigrams and Bigrams) <C> [BOLD] Not Complaints  [ITALIC] r <WITH> [BOLD] POS (Unigrams and Bigrams) <HAS> [BOLD] POS (Unigrams and Bigrams) <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> VBN <HAS> .141 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> VBN <HAS> UH <C> [BOLD] Not Complaints  [ITALIC] r <WITH> VBN <HAS> .104 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> $ <HAS> .118 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> $ <HAS> NNP <C> [BOLD] Not Complaints  [ITALIC] r <WITH> $ <HAS> .098 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> VBZ <HAS> .114 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> VBZ <HAS> PRP <C> [BOLD] Not Complaints  [ITALIC] r <WITH> VBZ <HAS> .076 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> NN_VBZ <HAS> .114 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> NN_VBZ <HAS> HT <C> [BOLD] Not Complaints  [ITALIC] r <WITH> NN_VBZ <HAS> .076 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> PRP$ <HAS> .107 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> PRP$ <HAS> PRP_. <C> [BOLD] Not Complaints  [ITALIC] r <WITH> PRP$ <HAS> .076 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> PRP$_NN <HAS> .105 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> PRP$_NN <HAS> PRP_RB <C> [BOLD] Not Complaints  [ITALIC] r <WITH> PRP$_NN <HAS> .067 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> VBG <HAS> .093 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> VBG <HAS> NNP_NNP <C> [BOLD] Not Complaints  [ITALIC] r <WITH> VBG <HAS> .062 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> CD <HAS> .092 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> CD <HAS> VBP_PRP <C> [BOLD] Not Complaints  [ITALIC] r <WITH> CD <HAS> .054 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> WRB_VBZ <HAS> .084 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> WRB_VBZ <HAS> JJ <C> [BOLD] Not Complaints  [ITALIC] r <WITH> WRB_VBZ <HAS> .053 <C> <R> <C> [BOLD] Complaints  [ITALIC] r <WITH> VBZ_VBN <HAS> .084 <C> [BOLD] Not Complaints  [BOLD] Feature <WITH> VBZ_VBN <HAS> DT_JJ <C> [BOLD] Not Complaints  [ITALIC] r <WITH> VBZ_VBN <HAS> .051 <C> <CAP> Table 4: Features associated with complaint and non-complaint tweets, sorted by Pearson correlation (r) computed between the normalized frequency of each feature and the complaint label across all tweets. All correlations are significant at p
 <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> [BOLD] LIWC Features <HAS> [BOLD] LIWC Features <C> [BOLD] Complaints  [ITALIC] r <WITH> [BOLD] LIWC Features <HAS> [BOLD] LIWC Features <C> [BOLD] Not Complaints  [BOLD] Label <WITH> [BOLD] LIWC Features <HAS> [BOLD] LIWC Features <C> [BOLD] Not Complaints  [BOLD] Words <WITH> [BOLD] LIWC Features <HAS> [BOLD] LIWC Features <C> [BOLD] Not Complaints  [ITALIC] r <WITH> [BOLD] LIWC Features <HAS> [BOLD] LIWC Features <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> NEGATE <HAS> not, no, can’t, don’t, never, nothing, doesn’t, won’t <C> [BOLD] Complaints  [ITALIC] r <WITH> NEGATE <HAS> .271 <C> [BOLD] Not Complaints  [BOLD] Label <WITH> NEGATE <HAS> POSEMO <C> [BOLD] Not Complaints  [BOLD] Words <WITH> NEGATE <HAS> thanks, love, thank, good, great, support, lol, win <C> [BOLD] Not Complaints  [ITALIC] r <WITH> NEGATE <HAS> .185 <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> RELATIV <HAS> in, on, when, at, out, still, now, up, back, new <C> [BOLD] Complaints  [ITALIC] r <WITH> RELATIV <HAS> .225 <C> [BOLD] Not Complaints  [BOLD] Label <WITH> RELATIV <HAS> AFFECT <C> [BOLD] Not Complaints  [BOLD] Words <WITH> RELATIV <HAS> thanks, love, thank, good, great, support, lol <C> [BOLD] Not Complaints  [ITALIC] r <WITH> RELATIV <HAS> .111 <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> FUNCTION <HAS> the, i, to, a, my, and, you, for, is, in <C> [BOLD] Complaints  [ITALIC] r <WITH> FUNCTION <HAS> .204 <C> [BOLD] Not Complaints  [BOLD] Label <WITH> FUNCTION <HAS> SHEHE <C> [BOLD] Not Complaints  [BOLD] Words <WITH> FUNCTION <HAS> he, his, she, her, him, he’s, himself <C> [BOLD] Not Complaints  [ITALIC] r <WITH> FUNCTION <HAS> .105 <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> TIME <HAS> when, still, now, back, new, never, after, then, waiting <C> [BOLD] Complaints  [ITALIC] r <WITH> TIME <HAS> .186 <C> [BOLD] Not Complaints  [BOLD] Label <WITH> TIME <HAS> MALE <C> [BOLD] Not Complaints  [BOLD] Words <WITH> TIME <HAS> he, his, man, him, sir, he’s, son <C> [BOLD] Not Complaints  [ITALIC] r <WITH> TIME <HAS> .086 <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> DIFFER <HAS> not, but, if, or, can’t, really, than, other, haven’t <C> [BOLD] Complaints  [ITALIC] r <WITH> DIFFER <HAS> .169 <C> [BOLD] Not Complaints  [BOLD] Label <WITH> DIFFER <HAS> FEMALE <C> [BOLD] Not Complaints  [BOLD] Words <WITH> DIFFER <HAS> she, her, girl, mom, ma, lady, mother, female, mrs <C> [BOLD] Not Complaints  [ITALIC] r <WITH> DIFFER <HAS> .084 <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> COGPROC <HAS> not, but, how, if, all, why, or, any, need <C> [BOLD] Complaints  [ITALIC] r <WITH> COGPROC <HAS> .132 <C> [BOLD] Not Complaints  [BOLD] Label <WITH> COGPROC <HAS> ASSENT <C> [BOLD] Not Complaints  [BOLD] Words <WITH> COGPROC <HAS> yes, ok, awesome, okay, yeah, cool, absolutely, agree <C> [BOLD] Not Complaints  [ITALIC] r <WITH> COGPROC <HAS> .080 <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> [BOLD] Word2Vec Clusters <HAS> [BOLD] Word2Vec Clusters <C> [BOLD] Complaints  [ITALIC] r <WITH> [BOLD] Word2Vec Clusters <HAS> [BOLD] Word2Vec Clusters <C> [BOLD] Not Complaints  [BOLD] Label <WITH> [BOLD] Word2Vec Clusters <HAS> [BOLD] Word2Vec Clusters <C> [BOLD] Not Complaints  [BOLD] Words <WITH> [BOLD] Word2Vec Clusters <HAS> [BOLD] Word2Vec Clusters <C> [BOLD] Not Complaints  [ITALIC] r <WITH> [BOLD] Word2Vec Clusters <HAS> [BOLD] Word2Vec Clusters <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> Cust. Service <HAS> service, customer, contact, job, staff, assist, agent <C> [BOLD] Complaints  [ITALIC] r <WITH> Cust. Service <HAS> .136 <C> [BOLD] Not Complaints  [BOLD] Label <WITH> Cust. Service <HAS> Gratitude <C> [BOLD] Not Complaints  [BOLD] Words <WITH> Cust. Service <HAS> thanks, thank, good, great, support, everyone, huge, proud <C> [BOLD] Not Complaints  [ITALIC] r <WITH> Cust. Service <HAS> .089 <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> Order <HAS> order, store, buy, free, delivery, available, package <C> [BOLD] Complaints  [ITALIC] r <WITH> Order <HAS> .128 <C> [BOLD] Not Complaints  [BOLD] Label <WITH> Order <HAS> Family <C> [BOLD] Not Complaints  [BOLD] Words <WITH> Order <HAS> old, friend, family, mom, wife, husband, younger <C> [BOLD] Not Complaints  [ITALIC] r <WITH> Order <HAS> .063 <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> Issues <HAS> delayed, closed, between, outage, delay, road, accident <C> [BOLD] Complaints  [ITALIC] r <WITH> Issues <HAS> .122 <C> [BOLD] Not Complaints  [BOLD] Label <WITH> Issues <HAS> Voting <C> [BOLD] Not Complaints  [BOLD] Words <WITH> Issues <HAS> favorite, part, stars, model, vote, models, represent <C> [BOLD] Not Complaints  [ITALIC] r <WITH> Issues <HAS> .060 <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> Time Ref. <HAS> been, yet, haven’t, long, happened, yesterday, took <C> [BOLD] Complaints  [ITALIC] r <WITH> Time Ref. <HAS> .122 <C> [BOLD] Not Complaints  [BOLD] Label <WITH> Time Ref. <HAS> Contests <C> [BOLD] Not Complaints  [BOLD] Words <WITH> Time Ref. <HAS> Christmas, gift, receive, entered, giveaway, enter, cards <C> [BOLD] Not Complaints  [ITALIC] r <WITH> Time Ref. <HAS> .058 <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> Tech Parts <HAS> battery, laptop, screen, warranty, desktop, printer <C> [BOLD] Complaints  [ITALIC] r <WITH> Tech Parts <HAS> .100 <C> [BOLD] Not Complaints  [BOLD] Label <WITH> Tech Parts <HAS> Pets <C> [BOLD] Not Complaints  [BOLD] Words <WITH> Tech Parts <HAS> dogs, cat, dog, pet, shepherd, fluffy, treats <C> [BOLD] Not Complaints  [ITALIC] r <WITH> Tech Parts <HAS> .054 <C> <R> <C> [BOLD] Complaints  [BOLD] Words <WITH> Access <HAS> use, using, error, password, access, automatically, reset <C> [BOLD] Complaints  [ITALIC] r <WITH> Access <HAS> .098 <C> [BOLD] Not Complaints  [BOLD] Label <WITH> Access <HAS> Christian <C> [BOLD] Not Complaints  [BOLD] Words <WITH> Access <HAS> god, shall, heaven, spirit, lord, belongs, soul, believers <C> [BOLD] Not Complaints  [ITALIC] r <WITH> Access <HAS> .053 <C> <CAP> Table 5: Group text features associated with tweets that are complaints and not complaints. Features are sorted by Pearson correlation (r) between their each feature’s normalized frequency and the outcome. We restrict to only the top six categories for each feature type. All correlations are significant at p
 <R> <C> [BOLD] Acc <WITH> Most Frequent Class <HAS> 64.2 <C> [BOLD] F1 <WITH> Most Frequent Class <HAS> 39.1 <C> [BOLD] AUC <WITH> Most Frequent Class <HAS> 0.500 <C> <R> <C> [BOLD] Acc <WITH> Logistic Regression <HAS> [EMPTY] <C> [BOLD] F1 <WITH> Logistic Regression <HAS> [EMPTY] <C> [BOLD] AUC <WITH> Logistic Regression <HAS> [EMPTY] <C> <R> <C> [BOLD] Acc <WITH> Sentiment – MPQA <HAS> 64.2 <C> [BOLD] F1 <WITH> Sentiment – MPQA <HAS> 39.1 <C> [BOLD] AUC <WITH> Sentiment – MPQA <HAS> 0.499 <C> <R> <C> [BOLD] Acc <WITH> Sentiment – NRC <HAS> 63.9 <C> [BOLD] F1 <WITH> Sentiment – NRC <HAS> 42.2 <C> [BOLD] AUC <WITH> Sentiment – NRC <HAS> 0.599 <C> <R> <C> [BOLD] Acc <WITH> Sentiment – V&B <HAS> 68.9 <C> [BOLD] F1 <WITH> Sentiment – V&B <HAS> 60.0 <C> [BOLD] AUC <WITH> Sentiment – V&B <HAS> 0.696 <C> <R> <C> [BOLD] Acc <WITH> Sentiment – VADER <HAS> 66.0 <C> [BOLD] F1 <WITH> Sentiment – VADER <HAS> 54.2 <C> [BOLD] AUC <WITH> Sentiment – VADER <HAS> 0.654 <C> <R> <C> [BOLD] Acc <WITH> Sentiment – Stanford <HAS> 68.0 <C> [BOLD] F1 <WITH> Sentiment – Stanford <HAS> 55.6 <C> [BOLD] AUC <WITH> Sentiment – Stanford <HAS> 0.696 <C> <R> <C> [BOLD] Acc <WITH> Complaint Specific (all) <HAS> 65.7 <C> [BOLD] F1 <WITH> Complaint Specific (all) <HAS> 55.2 <C> [BOLD] AUC <WITH> Complaint Specific (all) <HAS> 0.634 <C> <R> <C> [BOLD] Acc <WITH> Request <HAS> 64.2 <C> [BOLD] F1 <WITH> Request <HAS> 39.1 <C> [BOLD] AUC <WITH> Request <HAS> 0.583 <C> <R> <C> [BOLD] Acc <WITH> Intensifiers <HAS> 64.5 <C> [BOLD] F1 <WITH> Intensifiers <HAS> 47.3 <C> [BOLD] AUC <WITH> Intensifiers <HAS> 0.639 <C> <R> <C> [BOLD] Acc <WITH> Downgraders <HAS> 65.4 <C> [BOLD] F1 <WITH> Downgraders <HAS> 49.8 <C> [BOLD] AUC <WITH> Downgraders <HAS> 0.615 <C> <R> <C> [BOLD] Acc <WITH> Temporal References <HAS> 64.2 <C> [BOLD] F1 <WITH> Temporal References <HAS> 43.7 <C> [BOLD] AUC <WITH> Temporal References <HAS> 0.535 <C> <R> <C> [BOLD] Acc <WITH> Pronoun Types <HAS> 64.1 <C> [BOLD] F1 <WITH> Pronoun Types <HAS> 39.1 <C> [BOLD] AUC <WITH> Pronoun Types <HAS> 0.545 <C> <R> <C> [BOLD] Acc <WITH> POS Bigrams <HAS> 72.2 <C> [BOLD] F1 <WITH> POS Bigrams <HAS> 66.8 <C> [BOLD] AUC <WITH> POS Bigrams <HAS> 0.756 <C> <R> <C> [BOLD] Acc <WITH> LIWC <HAS> 71.6 <C> [BOLD] F1 <WITH> LIWC <HAS> 65.8 <C> [BOLD] AUC <WITH> LIWC <HAS> 0.784 <C> <R> <C> [BOLD] Acc <WITH> Word2Vec Clusters <HAS> 67.7 <C> [BOLD] F1 <WITH> Word2Vec Clusters <HAS> 58.3 <C> [BOLD] AUC <WITH> Word2Vec Clusters <HAS> 0.738 <C> <R> <C> [BOLD] Acc <WITH> Bag-of-Words <HAS> 79.8 <C> [BOLD] F1 <WITH> Bag-of-Words <HAS> 77.5 <C> [BOLD] AUC <WITH> Bag-of-Words <HAS> 0.866 <C> <R> <C> [BOLD] Acc <WITH> All Features <HAS> [BOLD] 80.5 <C> [BOLD] F1 <WITH> All Features <HAS> [BOLD] 78.0 <C> [BOLD] AUC <WITH> All Features <HAS> [BOLD] 0.873 <C> <R> <C> [BOLD] Acc <WITH> Neural Networks <HAS> [EMPTY] <C> [BOLD] F1 <WITH> Neural Networks <HAS> [EMPTY] <C> [BOLD] AUC <WITH> Neural Networks <HAS> [EMPTY] <C> <R> <C> [BOLD] Acc <WITH> MLP <HAS> 78.3 <C> [BOLD] F1 <WITH> MLP <HAS> 76.2 <C> [BOLD] AUC <WITH> MLP <HAS> 0.845 <C> <R> <C> [BOLD] Acc <WITH> LSTM <HAS> 80.2 <C> [BOLD] F1 <WITH> LSTM <HAS> 77.0 <C> [BOLD] AUC <WITH> LSTM <HAS> 0.864 <C> <CAP> Table 6: Complaint prediction results using logistic regression (with different types of linguistic features), neural network approaches and the most frequent class baseline. Best results are in bold.
 <R> <C> [BOLD] Acc <WITH> Most Frequent Class <HAS> 64.2 <C> [BOLD] F1 <WITH> Most Frequent Class <HAS> 39.1 <C> [BOLD] AUC <WITH> Most Frequent Class <HAS> 0.500 <C> <R> <C> [BOLD] Acc <WITH> LR-All Features – Original Data <HAS> 80.5 <C> [BOLD] F1 <WITH> LR-All Features – Original Data <HAS> 78.0 <C> [BOLD] AUC <WITH> LR-All Features – Original Data <HAS> 0.873 <C> <R> <C> [BOLD] Acc <WITH> Dist. Supervision + Pooling <HAS> 77.2 <C> [BOLD] F1 <WITH> Dist. Supervision + Pooling <HAS> 75.7 <C> [BOLD] AUC <WITH> Dist. Supervision + Pooling <HAS> 0.853 <C> <R> <C> [BOLD] Acc <WITH> Dist. Supervision + EasyAdapt <HAS> [BOLD] 81.2 <C> [BOLD] F1 <WITH> Dist. Supervision + EasyAdapt <HAS> [BOLD] 79.0 <C> [BOLD] AUC <WITH> Dist. Supervision + EasyAdapt <HAS> [BOLD] 0.885 <C> <CAP> Table 7: Complaint prediction results using the original data set and distantly supervised data. All models are based on logistic regression with bag-of-word and Part-of-Speech tag features.
 <R> <C> [BOLD] In-Domain <WITH> Food & Beverage <HAS> 63.9 <C> [BOLD] Pooling <WITH> Food & Beverage <HAS> 60.9 <C> [BOLD] EasyAdapt <WITH> Food & Beverage <HAS> [BOLD] 83.1 <C> <R> <C> [BOLD] In-Domain <WITH> Apparel <HAS> [BOLD] 76.2 <C> [BOLD] Pooling <WITH> Apparel <HAS> 71.1 <C> [BOLD] EasyAdapt <WITH> Apparel <HAS> 72.5 <C> <R> <C> [BOLD] In-Domain <WITH> Retail <HAS> 58.8 <C> [BOLD] Pooling <WITH> Retail <HAS> [BOLD] 79.7 <C> [BOLD] EasyAdapt <WITH> Retail <HAS> [BOLD] 79.7 <C> <R> <C> [BOLD] In-Domain <WITH> Cars <HAS> 41.5 <C> [BOLD] Pooling <WITH> Cars <HAS> 77.8 <C> [BOLD] EasyAdapt <WITH> Cars <HAS> [BOLD] 80.9 <C> <R> <C> [BOLD] In-Domain <WITH> Services <HAS> 65.2 <C> [BOLD] Pooling <WITH> Services <HAS> 75.9 <C> [BOLD] EasyAdapt <WITH> Services <HAS> [BOLD] 76.7 <C> <R> <C> [BOLD] In-Domain <WITH> Software <HAS> 61.3 <C> [BOLD] Pooling <WITH> Software <HAS> 73.4 <C> [BOLD] EasyAdapt <WITH> Software <HAS> [BOLD] 78.7 <C> <R> <C> [BOLD] In-Domain <WITH> Transport <HAS> 56.4 <C> [BOLD] Pooling <WITH> Transport <HAS> [BOLD] 73.4 <C> [BOLD] EasyAdapt <WITH> Transport <HAS> 69.8 <C> <R> <C> [BOLD] In-Domain <WITH> Electronics <HAS> 66.2 <C> [BOLD] Pooling <WITH> Electronics <HAS> 73.0 <C> [BOLD] EasyAdapt <WITH> Electronics <HAS> [BOLD] 76.2 <C> <R> <C> [BOLD] In-Domain <WITH> Other <HAS> 42.4 <C> [BOLD] Pooling <WITH> Other <HAS> [BOLD] 82.8 <C> [BOLD] EasyAdapt <WITH> Other <HAS> [BOLD] 82.8 <C> <CAP> Table 8: Performance of models in Macro F1 on tweets from each domain.
 <R> <C> Val. Accuracy <WITH> Siamese Networks <HAS> 77.42% <C> Loss <WITH> Siamese Networks <HAS> 0.5601 <C> Val. Loss <WITH> Siamese Networks <HAS> 0.5329 <C> Pretraining Time <WITH> Siamese Networks <HAS> [EMPTY] <C> Finetuning Time <WITH> Siamese Networks <HAS> 4m per epoch <C> <R> <C> Val. Accuracy <WITH> BERT <HAS> 87.47% <C> Loss <WITH> BERT <HAS> 0.4655 <C> Val. Loss <WITH> BERT <HAS> 0.4419 <C> Pretraining Time <WITH> BERT <HAS> 66 hours <C> Finetuning Time <WITH> BERT <HAS> 2m per epoch <C> <R> <C> Val. Accuracy <WITH> GPT-2 <HAS> 90.99% <C> Loss <WITH> GPT-2 <HAS> 0.2172 <C> Val. Loss <WITH> GPT-2 <HAS> 0.1826 <C> Pretraining Time <WITH> GPT-2 <HAS> 78 hours <C> Finetuning Time <WITH> GPT-2 <HAS> 4m per epoch <C> <R> <C> Val. Accuracy <WITH> ULMFiT <HAS> 91.59% <C> Loss <WITH> ULMFiT <HAS> 0.3750 <C> Val. Loss <WITH> ULMFiT <HAS> 0.1972 <C> Pretraining Time <WITH> ULMFiT <HAS> 11 hours <C> Finetuning Time <WITH> ULMFiT <HAS> 2m per epoch <C> <R> <C> Val. Accuracy <WITH> ULMFiT (no LM Finetuning) <HAS> 78.11% <C> Loss <WITH> ULMFiT (no LM Finetuning) <HAS> 0.5512 <C> Val. Loss <WITH> ULMFiT (no LM Finetuning) <HAS> 0.5409 <C> Pretraining Time <WITH> ULMFiT (no LM Finetuning) <HAS> 11 hours <C> Finetuning Time <WITH> ULMFiT (no LM Finetuning) <HAS> 2m per epoch <C> <R> <C> Val. Accuracy <WITH> BERT + Multitasking <HAS> 91.20% <C> Loss <WITH> BERT + Multitasking <HAS> 0.3155 <C> Val. Loss <WITH> BERT + Multitasking <HAS> 0.3023 <C> Pretraining Time <WITH> BERT + Multitasking <HAS> 66 hours <C> Finetuning Time <WITH> BERT + Multitasking <HAS> 4m per epoch <C> <R> <C> Val. Accuracy <WITH> GPT-2 + Multitasking <HAS> 96.28% <C> Loss <WITH> GPT-2 + Multitasking <HAS> 0.2609 <C> Val. Loss <WITH> GPT-2 + Multitasking <HAS> 0.2197 <C> Pretraining Time <WITH> GPT-2 + Multitasking <HAS> 78 hours <C> Finetuning Time <WITH> GPT-2 + Multitasking <HAS> 5m per epoch <C> <CAP> Table 4: Consolidated experiment results. The first section shows finetuning results for base transfer learning methods and the baseline siamese network. The second section shows results for ULMFiT without Language Model Finetuning. The last section shows finetuning results for transformer methods augmented with multitasking heads. BERT and GPT-2 were finetuned for three epochs in all cases and ULMFiT was finetuned for 5 during classifier finetuning.
 <R> <C> Pretrained? <WITH> Multitasking <HAS> No <C> Accuracy <WITH> Multitasking <HAS> 53.61% <C> Val. Loss <WITH> Multitasking <HAS> 0.7217 <C> Acc. Inc. <WITH> Multitasking <HAS> - <C> % of Perf. <WITH> Multitasking <HAS> - <C> <R> <C> Pretrained? <WITH> [EMPTY] <HAS> Yes <C> Accuracy <WITH> [EMPTY] <HAS> 96.28% <C> Val. Loss <WITH> [EMPTY] <HAS> 0.2197 <C> Acc. Inc. <WITH> [EMPTY] <HAS> +42.67% <C> % of Perf. <WITH> [EMPTY] <HAS> 44.32% <C> <R> <C> Pretrained? <WITH> Standard <HAS> No <C> Accuracy <WITH> Standard <HAS> 51.02% <C> Val. Loss <WITH> Standard <HAS> 0.7024 <C> Acc. Inc. <WITH> Standard <HAS> - <C> % of Perf. <WITH> Standard <HAS> - <C> <R> <C> Pretrained? <WITH> [EMPTY] <HAS> Yes <C> Accuracy <WITH> [EMPTY] <HAS> 90.99% <C> Val. Loss <WITH> [EMPTY] <HAS> 0.1826 <C> Acc. Inc. <WITH> [EMPTY] <HAS> +39.97% <C> % of Perf. <WITH> [EMPTY] <HAS> 43.93% <C> <CAP> Table 5: An ablation study on the effects of pretraining for multitasking-based and standard GPT-2 finetuning. Results show that pretraining greatly accounts for almost half of performance on both finetuning techniques. “Acc. Inc.” refers to the boost in performance contributed by the pretraining step. “% of Perf.” refers to the percentage of the total performance that the pretraining step contributes.
 <R> <C> Accuracy <WITH> 1 <HAS> 89.44% <C> Val. Loss <WITH> 1 <HAS> 0.2811 <C> Effect <WITH> 1 <HAS> -6.84% <C> <R> <C> Accuracy <WITH> 2 <HAS> 91.20% <C> Val. Loss <WITH> 2 <HAS> 0.2692 <C> Effect <WITH> 2 <HAS> -5.08% <C> <R> <C> Accuracy <WITH> 4 <HAS> 93.85% <C> Val. Loss <WITH> 4 <HAS> 0.2481 <C> Effect <WITH> 4 <HAS> -2.43% <C> <R> <C> Accuracy <WITH> 8 <HAS> 96.02% <C> Val. Loss <WITH> 8 <HAS> 0.2257 <C> Effect <WITH> 8 <HAS> -0.26% <C> <R> <C> Accuracy <WITH> 10 <HAS> 96.28% <C> Val. Loss <WITH> 10 <HAS> 0.2197 <C> Effect <WITH> 10 <HAS> [EMPTY] <C> <R> <C> Accuracy <WITH> 16 <HAS> 96.32% <C> Val. Loss <WITH> 16 <HAS> 0.2190 <C> Effect <WITH> 16 <HAS> +0.04 <C> <CAP> Table 6: An ablation study on the effect of multiple heads in the attention mechanisms. The results show that increasing the number of heads improves performance, though this plateaus at 10 attention heads. All ablations use the multitask-based finetuning method. “Effect” refers to the increase or decrease of accuracy as the heads are removed. Note that 10 heads is the default used throughout the study.
 <R> <C> Question <WITH> Annotation <HAS> Were the films Tonka and 101 Dalmatians released in the same decade? <C> Answer <WITH> Annotation <HAS> 1958 Walt Disney Western adventure film <C> Prediction <WITH> Annotation <HAS> No <C> Pct (%) <WITH> Annotation <HAS> 9 <C> <R> <C> Question <WITH> Multiple Answers <HAS> Michael J. Hunter replaced the lawyer who became the administrator of which agency? <C> Answer <WITH> Multiple Answers <HAS> EPA <C> Prediction <WITH> Multiple Answers <HAS> Environmental Protection Agency <C> Pct (%) <WITH> Multiple Answers <HAS> 24 <C> <R> <C> Question <WITH> Discrete Reasoning <HAS> Between two bands, Mastodon and Hole, which one has more members? <C> Answer <WITH> Discrete Reasoning <HAS> Mastodon <C> Prediction <WITH> Discrete Reasoning <HAS> Hole <C> Pct (%) <WITH> Discrete Reasoning <HAS> 15 <C> <R> <C> Question <WITH> Commonsense & External Knowledge <HAS> What is the name of second extended play by the artists of the mini-abum Code#01? <C> Answer <WITH> Commonsense & External Knowledge <HAS> Code#02 Pretty Pretty <C> Prediction <WITH> Commonsense & External Knowledge <HAS> Code#01 Bad Girl <C> Pct (%) <WITH> Commonsense & External Knowledge <HAS> 16 <C> <R> <C> Question <WITH> Multi-hop <HAS> Who directed the film based on the rock opera 5:15 appeared in? <C> Answer <WITH> Multi-hop <HAS> Franc Roddam <C> Prediction <WITH> Multi-hop <HAS> Ken Russell <C> Pct (%) <WITH> Multi-hop <HAS> 16 <C> <R> <C> Question <WITH> MRC <HAS> How was Ada Lovelace, the first computer programmer, related to Lord Byron in Childe Byron? <C> Answer <WITH> MRC <HAS> his daughter <C> Prediction <WITH> MRC <HAS> strained relationship <C> Pct (%) <WITH> MRC <HAS> 20 <C> <CAP> Table 6: Error analysis of HGN model. For ‘Multi-hop’ errors, the model jumps to the wrong film (“Tommy (1975 film)”) instead of the correct one (“Quadrophenia (film)”) from the starting entity “rock opera 5:15”. The supporting fact for the ‘MRC’ example is “Childe Byron is a 1977 play by Romulus Linney about the strained relationship between the poet, Lord Byron, and his daughter, Ada Lovelace”.
 <R> <C> Ans EM <WITH> DecompRC Min et al. ( 2019b ) <HAS> 55.20 <C> Ans F1 <WITH> DecompRC Min et al. ( 2019b ) <HAS> 69.63 <C> Sup EM <WITH> DecompRC Min et al. ( 2019b ) <HAS> - <C> Sup F1 <WITH> DecompRC Min et al. ( 2019b ) <HAS> - <C> Joint EM <WITH> DecompRC Min et al. ( 2019b ) <HAS> - <C> Joint F1 <WITH> DecompRC Min et al. ( 2019b ) <HAS> - <C> <R> <C> Ans EM <WITH> ChainEx Chen et al. ( 2019 ) <HAS> 61.20 <C> Ans F1 <WITH> ChainEx Chen et al. ( 2019 ) <HAS> 74.11 <C> Sup EM <WITH> ChainEx Chen et al. ( 2019 ) <HAS> - <C> Sup F1 <WITH> ChainEx Chen et al. ( 2019 ) <HAS> - <C> Joint EM <WITH> ChainEx Chen et al. ( 2019 ) <HAS> - <C> Joint F1 <WITH> ChainEx Chen et al. ( 2019 ) <HAS> - <C> <R> <C> Ans EM <WITH> Baseline Model Yang et al. ( 2018 ) <HAS> 45.60 <C> Ans F1 <WITH> Baseline Model Yang et al. ( 2018 ) <HAS> 59.02 <C> Sup EM <WITH> Baseline Model Yang et al. ( 2018 ) <HAS> 20.32 <C> Sup F1 <WITH> Baseline Model Yang et al. ( 2018 ) <HAS> 64.49 <C> Joint EM <WITH> Baseline Model Yang et al. ( 2018 ) <HAS> 10.83 <C> Joint F1 <WITH> Baseline Model Yang et al. ( 2018 ) <HAS> 40.16 <C> <R> <C> Ans EM <WITH> QFE Nishida et al. ( 2019 ) <HAS> 53.86 <C> Ans F1 <WITH> QFE Nishida et al. ( 2019 ) <HAS> 68.06 <C> Sup EM <WITH> QFE Nishida et al. ( 2019 ) <HAS> 57.75 <C> Sup F1 <WITH> QFE Nishida et al. ( 2019 ) <HAS> 84.49 <C> Joint EM <WITH> QFE Nishida et al. ( 2019 ) <HAS> 34.63 <C> Joint F1 <WITH> QFE Nishida et al. ( 2019 ) <HAS> 59.61 <C> <R> <C> Ans EM <WITH> DFGN Xiao et al. ( 2019 ) <HAS> 56.31 <C> Ans F1 <WITH> DFGN Xiao et al. ( 2019 ) <HAS> 69.69 <C> Sup EM <WITH> DFGN Xiao et al. ( 2019 ) <HAS> 51.50 <C> Sup F1 <WITH> DFGN Xiao et al. ( 2019 ) <HAS> 81.62 <C> Joint EM <WITH> DFGN Xiao et al. ( 2019 ) <HAS> 33.62 <C> Joint F1 <WITH> DFGN Xiao et al. ( 2019 ) <HAS> 59.82 <C> <R> <C> Ans EM <WITH> LQR-Net Grail et al. ( 2020 ) <HAS> 60.20 <C> Ans F1 <WITH> LQR-Net Grail et al. ( 2020 ) <HAS> 73.78 <C> Sup EM <WITH> LQR-Net Grail et al. ( 2020 ) <HAS> 56.21 <C> Sup F1 <WITH> LQR-Net Grail et al. ( 2020 ) <HAS> 84.09 <C> Joint EM <WITH> LQR-Net Grail et al. ( 2020 ) <HAS> 36.56 <C> Joint F1 <WITH> LQR-Net Grail et al. ( 2020 ) <HAS> 63.68 <C> <R> <C> Ans EM <WITH> P-BERT† <HAS> 61.18 <C> Ans F1 <WITH> P-BERT† <HAS> 74.16 <C> Sup EM <WITH> P-BERT† <HAS> 51.38 <C> Sup F1 <WITH> P-BERT† <HAS> 82.76 <C> Joint EM <WITH> P-BERT† <HAS> 35.42 <C> Joint F1 <WITH> P-BERT† <HAS> 63.79 <C> <R> <C> Ans EM <WITH> TAP2† <HAS> 64.99 <C> Ans F1 <WITH> TAP2† <HAS> 78.59 <C> Sup EM <WITH> TAP2† <HAS> 55.47 <C> Sup F1 <WITH> TAP2† <HAS> 85.57 <C> Joint EM <WITH> TAP2† <HAS> 39.77 <C> Joint F1 <WITH> TAP2† <HAS> 69.12 <C> <R> <C> Ans EM <WITH> EPS+BERT† <HAS> 65.79 <C> Ans F1 <WITH> EPS+BERT† <HAS> 79.05 <C> Sup EM <WITH> EPS+BERT† <HAS> 58.50 <C> Sup F1 <WITH> EPS+BERT† <HAS> 86.26 <C> Joint EM <WITH> EPS+BERT† <HAS> 42.47 <C> Joint F1 <WITH> EPS+BERT† <HAS> 70.48 <C> <R> <C> Ans EM <WITH> SAE-large Tu et al. ( 2020 ) <HAS> 66.92 <C> Ans F1 <WITH> SAE-large Tu et al. ( 2020 ) <HAS> 79.62 <C> Sup EM <WITH> SAE-large Tu et al. ( 2020 ) <HAS> 61.53 <C> Sup F1 <WITH> SAE-large Tu et al. ( 2020 ) <HAS> 86.86 <C> Joint EM <WITH> SAE-large Tu et al. ( 2020 ) <HAS> 45.36 <C> Joint F1 <WITH> SAE-large Tu et al. ( 2020 ) <HAS> 71.45 <C> <R> <C> Ans EM <WITH> C2F ReaderShao et al. ( 2020 ) <HAS> 67.98 <C> Ans F1 <WITH> C2F ReaderShao et al. ( 2020 ) <HAS> 81.24 <C> Sup EM <WITH> C2F ReaderShao et al. ( 2020 ) <HAS> 60.81 <C> Sup F1 <WITH> C2F ReaderShao et al. ( 2020 ) <HAS> 87.63 <C> Joint EM <WITH> C2F ReaderShao et al. ( 2020 ) <HAS> 44.67 <C> Joint F1 <WITH> C2F ReaderShao et al. ( 2020 ) <HAS> 72.73 <C> <R> <C> Ans EM <WITH> HGN (ours) <HAS> [BOLD] 69.22 <C> Ans F1 <WITH> HGN (ours) <HAS> [BOLD] 82.19 <C> Sup EM <WITH> HGN (ours) <HAS> [BOLD] 62.76 <C> Sup F1 <WITH> HGN (ours) <HAS> [BOLD] 88.47 <C> Joint EM <WITH> HGN (ours) <HAS> [BOLD] 47.11 <C> Joint F1 <WITH> HGN (ours) <HAS> [BOLD] 74.21 <C> <CAP> Table 1: Results on the test set of HotpotQA in the Distractor setting. HGN achieves state-of-the-art results at the time of submission (Dec. 1, 2019). (†) indicates unpublished work. RoBERTa-large is used for context encoding.
 <R> <C> Ans EM <WITH> TPReasoner Xiong et al. ( 2019 ) <HAS> 36.04 <C> Ans F1 <WITH> TPReasoner Xiong et al. ( 2019 ) <HAS> 47.43 <C> Sup EM <WITH> TPReasoner Xiong et al. ( 2019 ) <HAS> - <C> Sup F1 <WITH> TPReasoner Xiong et al. ( 2019 ) <HAS> - <C> Joint EM <WITH> TPReasoner Xiong et al. ( 2019 ) <HAS> - <C> Joint F1 <WITH> TPReasoner Xiong et al. ( 2019 ) <HAS> - <C> <R> <C> Ans EM <WITH> Baseline Model Yang et al. ( 2018 ) <HAS> 23.95 <C> Ans F1 <WITH> Baseline Model Yang et al. ( 2018 ) <HAS> 32.89 <C> Sup EM <WITH> Baseline Model Yang et al. ( 2018 ) <HAS> 3.86 <C> Sup F1 <WITH> Baseline Model Yang et al. ( 2018 ) <HAS> 37.71 <C> Joint EM <WITH> Baseline Model Yang et al. ( 2018 ) <HAS> 1.85 <C> Joint F1 <WITH> Baseline Model Yang et al. ( 2018 ) <HAS> 16.15 <C> <R> <C> Ans EM <WITH> QFE Nishida et al. ( 2019 ) <HAS> 28.66 <C> Ans F1 <WITH> QFE Nishida et al. ( 2019 ) <HAS> 38.06 <C> Sup EM <WITH> QFE Nishida et al. ( 2019 ) <HAS> 14.20 <C> Sup F1 <WITH> QFE Nishida et al. ( 2019 ) <HAS> 44.35 <C> Joint EM <WITH> QFE Nishida et al. ( 2019 ) <HAS> 8.69 <C> Joint F1 <WITH> QFE Nishida et al. ( 2019 ) <HAS> 23.10 <C> <R> <C> Ans EM <WITH> MUPPET Feldman and El-Yaniv ( 2019 ) <HAS> 30.61 <C> Ans F1 <WITH> MUPPET Feldman and El-Yaniv ( 2019 ) <HAS> 40.26 <C> Sup EM <WITH> MUPPET Feldman and El-Yaniv ( 2019 ) <HAS> 16.65 <C> Sup F1 <WITH> MUPPET Feldman and El-Yaniv ( 2019 ) <HAS> 47.33 <C> Joint EM <WITH> MUPPET Feldman and El-Yaniv ( 2019 ) <HAS> 10.85 <C> Joint F1 <WITH> MUPPET Feldman and El-Yaniv ( 2019 ) <HAS> 27.01 <C> <R> <C> Ans EM <WITH> Cognitive Graph Ding et al. ( 2019 ) <HAS> 37.12 <C> Ans F1 <WITH> Cognitive Graph Ding et al. ( 2019 ) <HAS> 48.87 <C> Sup EM <WITH> Cognitive Graph Ding et al. ( 2019 ) <HAS> 22.82 <C> Sup F1 <WITH> Cognitive Graph Ding et al. ( 2019 ) <HAS> 57.69 <C> Joint EM <WITH> Cognitive Graph Ding et al. ( 2019 ) <HAS> 12.42 <C> Joint F1 <WITH> Cognitive Graph Ding et al. ( 2019 ) <HAS> 34.92 <C> <R> <C> Ans EM <WITH> PR-BERT† <HAS> 43.33 <C> Ans F1 <WITH> PR-BERT† <HAS> 53.79 <C> Sup EM <WITH> PR-BERT† <HAS> 21.90 <C> Sup F1 <WITH> PR-BERT† <HAS> 59.63 <C> Joint EM <WITH> PR-BERT† <HAS> 14.50 <C> Joint F1 <WITH> PR-BERT† <HAS> 39.11 <C> <R> <C> Ans EM <WITH> Golden Retriever Qi et al. ( 2019 ) <HAS> 37.92 <C> Ans F1 <WITH> Golden Retriever Qi et al. ( 2019 ) <HAS> 48.58 <C> Sup EM <WITH> Golden Retriever Qi et al. ( 2019 ) <HAS> 30.69 <C> Sup F1 <WITH> Golden Retriever Qi et al. ( 2019 ) <HAS> 64.24 <C> Joint EM <WITH> Golden Retriever Qi et al. ( 2019 ) <HAS> 18.04 <C> Joint F1 <WITH> Golden Retriever Qi et al. ( 2019 ) <HAS> 39.13 <C> <R> <C> Ans EM <WITH> Entity-centric BERT Godbole et al. ( 2019 ) <HAS> 41.82 <C> Ans F1 <WITH> Entity-centric BERT Godbole et al. ( 2019 ) <HAS> 53.09 <C> Sup EM <WITH> Entity-centric BERT Godbole et al. ( 2019 ) <HAS> 26.26 <C> Sup F1 <WITH> Entity-centric BERT Godbole et al. ( 2019 ) <HAS> 57.29 <C> Joint EM <WITH> Entity-centric BERT Godbole et al. ( 2019 ) <HAS> 17.01 <C> Joint F1 <WITH> Entity-centric BERT Godbole et al. ( 2019 ) <HAS> 39.18 <C> <R> <C> Ans EM <WITH> SemanticRetrievalMRS Yixin Nie ( 2019 ) <HAS> 45.32 <C> Ans F1 <WITH> SemanticRetrievalMRS Yixin Nie ( 2019 ) <HAS> 57.34 <C> Sup EM <WITH> SemanticRetrievalMRS Yixin Nie ( 2019 ) <HAS> 38.67 <C> Sup F1 <WITH> SemanticRetrievalMRS Yixin Nie ( 2019 ) <HAS> 70.83 <C> Joint EM <WITH> SemanticRetrievalMRS Yixin Nie ( 2019 ) <HAS> 25.14 <C> Joint F1 <WITH> SemanticRetrievalMRS Yixin Nie ( 2019 ) <HAS> 47.60 <C> <R> <C> Ans EM <WITH> Transformer-XH Zhao et al. ( 2020 ) <HAS> 48.95 <C> Ans F1 <WITH> Transformer-XH Zhao et al. ( 2020 ) <HAS> 60.75 <C> Sup EM <WITH> Transformer-XH Zhao et al. ( 2020 ) <HAS> 41.66 <C> Sup F1 <WITH> Transformer-XH Zhao et al. ( 2020 ) <HAS> 70.01 <C> Joint EM <WITH> Transformer-XH Zhao et al. ( 2020 ) <HAS> 27.13 <C> Joint F1 <WITH> Transformer-XH Zhao et al. ( 2020 ) <HAS> 49.57 <C> <R> <C> Ans EM <WITH> MIR+EPS+BERT† <HAS> 52.86 <C> Ans F1 <WITH> MIR+EPS+BERT† <HAS> 64.79 <C> Sup EM <WITH> MIR+EPS+BERT† <HAS> 42.75 <C> Sup F1 <WITH> MIR+EPS+BERT† <HAS> 72.00 <C> Joint EM <WITH> MIR+EPS+BERT† <HAS> 31.19 <C> Joint F1 <WITH> MIR+EPS+BERT† <HAS> 54.75 <C> <R> <C> Ans EM <WITH> Graph Recur. Retriever Asai et al. ( 2020 ) <HAS> [BOLD] 60.04 <C> Ans F1 <WITH> Graph Recur. Retriever Asai et al. ( 2020 ) <HAS> [BOLD] 72.96 <C> Sup EM <WITH> Graph Recur. Retriever Asai et al. ( 2020 ) <HAS> 49.08 <C> Sup F1 <WITH> Graph Recur. Retriever Asai et al. ( 2020 ) <HAS> 76.41 <C> Joint EM <WITH> Graph Recur. Retriever Asai et al. ( 2020 ) <HAS> 35.35 <C> Joint F1 <WITH> Graph Recur. Retriever Asai et al. ( 2020 ) <HAS> [BOLD] 61.18 <C> <R> <C> Ans EM <WITH> HGN (ours) <HAS> 57.85 <C> Ans F1 <WITH> HGN (ours) <HAS> 69.93 <C> Sup EM <WITH> HGN (ours) <HAS> [BOLD] 51.01 <C> Sup F1 <WITH> HGN (ours) <HAS> [BOLD] 76.82 <C> Joint EM <WITH> HGN (ours) <HAS> [BOLD] 37.17 <C> Joint F1 <WITH> HGN (ours) <HAS> 60.74 <C> <CAP> Table 2: Results on the test set of HotpotQA in the Fullwiki setting. HGN achieves close to state-of-the-art results at the time of submission (Dec. 1, 2019). (†) indicates unpublished work. RoBERTa-large is used for context encoding, and SemanticRetrievalMRS is used for retrieval. Leaderboard: https://hotpotqa.github.io/.
 <R> <C> Ans F1 <WITH> w/o Graph <HAS> 80.58 <C> Sup F1 <WITH> w/o Graph <HAS> 85.83 <C> Joint F1 <WITH> w/o Graph <HAS> 71.02 <C> <R> <C> Ans F1 <WITH> PS Graph <HAS> 81.68 <C> Sup F1 <WITH> PS Graph <HAS> 88.44 <C> Joint F1 <WITH> PS Graph <HAS> 73.83 <C> <R> <C> Ans F1 <WITH> PSE Graph <HAS> 82.10 <C> Sup F1 <WITH> PSE Graph <HAS> 88.40 <C> Joint F1 <WITH> PSE Graph <HAS> 74.13 <C> <R> <C> Ans F1 <WITH> Hier. Graph <HAS> [BOLD] 82.22 <C> Sup F1 <WITH> Hier. Graph <HAS> [BOLD] 88.58 <C> Joint F1 <WITH> Hier. Graph <HAS> [BOLD] 74.37 <C> <CAP> Table 3: Ablation study on the effectiveness of the hierarchical graph on the dev set in the Distractor setting. RoBERTa-large is used for context encoding.
 <R> <C> Ans F1 <WITH> DFGN (BERT-base) <HAS> 69.38 <C> Sup F1 <WITH> DFGN (BERT-base) <HAS> 82.23 <C> Joint F1 <WITH> DFGN (BERT-base) <HAS> 59.89 <C> <R> <C> Ans F1 <WITH> EPS (BERT-wwm)† <HAS> 79.05 <C> Sup F1 <WITH> EPS (BERT-wwm)† <HAS> 86.26 <C> Joint F1 <WITH> EPS (BERT-wwm)† <HAS> 70.48 <C> <R> <C> Ans F1 <WITH> SAE (RoBERTa) <HAS> 80.75 <C> Sup F1 <WITH> SAE (RoBERTa) <HAS> 87.38 <C> Joint F1 <WITH> SAE (RoBERTa) <HAS> 72.75 <C> <R> <C> Ans F1 <WITH> HGN (BERT-base) <HAS> 74.76 <C> Sup F1 <WITH> HGN (BERT-base) <HAS> 86.61 <C> Joint F1 <WITH> HGN (BERT-base) <HAS> 66.90 <C> <R> <C> Ans F1 <WITH> HGN (BERT-wwm) <HAS> 80.51 <C> Sup F1 <WITH> HGN (BERT-wwm) <HAS> 88.14 <C> Joint F1 <WITH> HGN (BERT-wwm) <HAS> 72.77 <C> <R> <C> Ans F1 <WITH> HGN (RoBERTa) <HAS> [BOLD] 82.22 <C> Sup F1 <WITH> HGN (RoBERTa) <HAS> [BOLD] 88.58 <C> Joint F1 <WITH> HGN (RoBERTa) <HAS> [BOLD] 74.37 <C> <CAP> Table 5: Results with different pre-trained language models on the dev set in the Distractor setting. (†) is unpublished work with results on the test set, using BERT whole word masking (wwm).
 <R> <C> Ans F1 <WITH> comp-yn <HAS> 93.45 <C> Sup F1 <WITH> comp-yn <HAS> 94.22 <C> Joint F1 <WITH> comp-yn <HAS> 88.50 <C> Pct (%) <WITH> comp-yn <HAS> 6.19 <C> <R> <C> Ans F1 <WITH> comp-span <HAS> 79.06 <C> Sup F1 <WITH> comp-span <HAS> 91.72 <C> Joint F1 <WITH> comp-span <HAS> 74.17 <C> Pct (%) <WITH> comp-span <HAS> 13.90 <C> <R> <C> Ans F1 <WITH> bridge <HAS> 81.90 <C> Sup F1 <WITH> bridge <HAS> 87.60 <C> Joint F1 <WITH> bridge <HAS> 73.31 <C> Pct (%) <WITH> bridge <HAS> 79.91 <C> <CAP> Table 7: Results of HGN for different reasoning types.
 <R> <C> BLEU <WITH> Automatic <HAS> 16.8 <C> <R> <C> BLEU <WITH> Gold <HAS> [BOLD] *17.5* <C> <CAP> Table 4: BLEU scores of Dual2seq on the little prince data, when gold or automatic AMRs are available.
 <R> <C> NC-v11 BLEU <WITH> OpenNMT-tf <HAS> 15.1 <C> NC-v11 TER↓ <WITH> OpenNMT-tf <HAS> 0.6902 <C> NC-v11 Meteor <WITH> OpenNMT-tf <HAS> 0.3040 <C> Full BLEU <WITH> OpenNMT-tf <HAS> 24.3 <C> Full TER↓ <WITH> OpenNMT-tf <HAS> 0.5567 <C> Full Meteor <WITH> OpenNMT-tf <HAS> 0.4225 <C> <R> <C> NC-v11 BLEU <WITH> Transformer-tf <HAS> 17.1 <C> NC-v11 TER↓ <WITH> Transformer-tf <HAS> 0.6647 <C> NC-v11 Meteor <WITH> Transformer-tf <HAS> 0.3578 <C> Full BLEU <WITH> Transformer-tf <HAS> 25.1 <C> Full TER↓ <WITH> Transformer-tf <HAS> 0.5537 <C> Full Meteor <WITH> Transformer-tf <HAS> 0.4344 <C> <R> <C> NC-v11 BLEU <WITH> Seq2seq <HAS> 16.0 <C> NC-v11 TER↓ <WITH> Seq2seq <HAS> 0.6695 <C> NC-v11 Meteor <WITH> Seq2seq <HAS> 0.3379 <C> Full BLEU <WITH> Seq2seq <HAS> 23.7 <C> Full TER↓ <WITH> Seq2seq <HAS> 0.5590 <C> Full Meteor <WITH> Seq2seq <HAS> 0.4258 <C> <R> <C> NC-v11 BLEU <WITH> Dual2seq-LinAMR <HAS> 17.3 <C> NC-v11 TER↓ <WITH> Dual2seq-LinAMR <HAS> 0.6530 <C> NC-v11 Meteor <WITH> Dual2seq-LinAMR <HAS> 0.3612 <C> Full BLEU <WITH> Dual2seq-LinAMR <HAS> 24.0 <C> Full TER↓ <WITH> Dual2seq-LinAMR <HAS> 0.5643 <C> Full Meteor <WITH> Dual2seq-LinAMR <HAS> 0.4246 <C> <R> <C> NC-v11 BLEU <WITH> Duel2seq-SRL <HAS> 17.2 <C> NC-v11 TER↓ <WITH> Duel2seq-SRL <HAS> 0.6591 <C> NC-v11 Meteor <WITH> Duel2seq-SRL <HAS> 0.3644 <C> Full BLEU <WITH> Duel2seq-SRL <HAS> 23.8 <C> Full TER↓ <WITH> Duel2seq-SRL <HAS> 0.5626 <C> Full Meteor <WITH> Duel2seq-SRL <HAS> 0.4223 <C> <R> <C> NC-v11 BLEU <WITH> Dual2seq-Dep <HAS> 17.8 <C> NC-v11 TER↓ <WITH> Dual2seq-Dep <HAS> 0.6516 <C> NC-v11 Meteor <WITH> Dual2seq-Dep <HAS> 0.3673 <C> Full BLEU <WITH> Dual2seq-Dep <HAS> 25.0 <C> Full TER↓ <WITH> Dual2seq-Dep <HAS> 0.5538 <C> Full Meteor <WITH> Dual2seq-Dep <HAS> 0.4328 <C> <R> <C> NC-v11 BLEU <WITH> Dual2seq <HAS> [BOLD] *19.2* <C> NC-v11 TER↓ <WITH> Dual2seq <HAS> [BOLD] 0.6305 <C> NC-v11 Meteor <WITH> Dual2seq <HAS> [BOLD] 0.3840 <C> Full BLEU <WITH> Dual2seq <HAS> [BOLD] *25.5* <C> Full TER↓ <WITH> Dual2seq <HAS> [BOLD] 0.5480 <C> Full Meteor <WITH> Dual2seq <HAS> [BOLD] 0.4376 <C> <CAP> Table 3: Test performance. NC-v11 represents training only with the NC-v11 data, while Full means using the full training data. * represents significant Koehn (2004) result (p<0.01) over Seq2seq. ↓ indicates the lower the better.
 <R> <C> [BOLD]  Simple Baseline  <WITH> [BOLD] CLOTH <HAS> 25.0 <C> [BOLD] ELMo <WITH> [BOLD] CLOTH <HAS> 70.7 <C> [BOLD] GPT <WITH> [BOLD] CLOTH <HAS> – <C> [BOLD] BERT <WITH> [BOLD] CLOTH <HAS> [BOLD] 86.0 <C> [BOLD] MT-DNN <WITH> [BOLD] CLOTH <HAS> – <C> [BOLD] XLNet <WITH> [BOLD] CLOTH <HAS> – <C> [BOLD] RoBERTa <WITH> [BOLD] CLOTH <HAS> – <C> [BOLD] ALBERT <WITH> [BOLD] CLOTH <HAS> – <C> [BOLD] Human <WITH> [BOLD] CLOTH <HAS> 85.9 <C> <R> <C> [BOLD]  Simple Baseline  <WITH> [BOLD] Cosmos QA <HAS> – <C> [BOLD] ELMo <WITH> [BOLD] Cosmos QA <HAS> – <C> [BOLD] GPT <WITH> [BOLD] Cosmos QA <HAS> 54.5 <C> [BOLD] BERT <WITH> [BOLD] Cosmos QA <HAS> 67.1 <C> [BOLD] MT-DNN <WITH> [BOLD] Cosmos QA <HAS> – <C> [BOLD] XLNet <WITH> [BOLD] Cosmos QA <HAS> – <C> [BOLD] RoBERTa <WITH> [BOLD] Cosmos QA <HAS> – <C> [BOLD] ALBERT <WITH> [BOLD] Cosmos QA <HAS> – <C> [BOLD] Human <WITH> [BOLD] Cosmos QA <HAS> 94.0 <C> <R> <C> [BOLD]  Simple Baseline  <WITH> [BOLD] DREAM <HAS> 33.4 <C> [BOLD] ELMo <WITH> [BOLD] DREAM <HAS> 59.5 <C> [BOLD] GPT <WITH> [BOLD] DREAM <HAS> 55.5 <C> [BOLD] BERT <WITH> [BOLD] DREAM <HAS> 66.8 <C> [BOLD] MT-DNN <WITH> [BOLD] DREAM <HAS> – <C> [BOLD] XLNet <WITH> [BOLD] DREAM <HAS> [BOLD] 72.0 <C> [BOLD] RoBERTa <WITH> [BOLD] DREAM <HAS> – <C> [BOLD] ALBERT <WITH> [BOLD] DREAM <HAS> – <C> [BOLD] Human <WITH> [BOLD] DREAM <HAS> 95.5 <C> <R> <C> [BOLD]  Simple Baseline  <WITH> [BOLD] GLUE <HAS> – <C> [BOLD] ELMo <WITH> [BOLD] GLUE <HAS> 70.0 <C> [BOLD] GPT <WITH> [BOLD] GLUE <HAS> – <C> [BOLD] BERT <WITH> [BOLD] GLUE <HAS> 80.5 <C> [BOLD] MT-DNN <WITH> [BOLD] GLUE <HAS> 87.6 <C> [BOLD] XLNet <WITH> [BOLD] GLUE <HAS> 88.4 <C> [BOLD] RoBERTa <WITH> [BOLD] GLUE <HAS> 88.5 <C> [BOLD] ALBERT <WITH> [BOLD] GLUE <HAS> [BOLD] 89.4 <C> [BOLD] Human <WITH> [BOLD] GLUE <HAS> 87.1 <C> <R> <C> [BOLD]  Simple Baseline  <WITH> [BOLD] HellaSWAG <HAS> 25.0 <C> [BOLD] ELMo <WITH> [BOLD] HellaSWAG <HAS> 33.3 <C> [BOLD] GPT <WITH> [BOLD] HellaSWAG <HAS> 41.7 <C> [BOLD] BERT <WITH> [BOLD] HellaSWAG <HAS> 47.3 <C> [BOLD] MT-DNN <WITH> [BOLD] HellaSWAG <HAS> – <C> [BOLD] XLNet <WITH> [BOLD] HellaSWAG <HAS> – <C> [BOLD] RoBERTa <WITH> [BOLD] HellaSWAG <HAS> [BOLD] 85.2 <C> [BOLD] ALBERT <WITH> [BOLD] HellaSWAG <HAS> [EMPTY] <C> [BOLD] Human <WITH> [BOLD] HellaSWAG <HAS> 95.6 <C> <R> <C> [BOLD]  Simple Baseline  <WITH> [BOLD] MC-TACO <HAS> 17.4 <C> [BOLD] ELMo <WITH> [BOLD] MC-TACO <HAS> 26.4 <C> [BOLD] GPT <WITH> [BOLD] MC-TACO <HAS> – <C> [BOLD] BERT <WITH> [BOLD] MC-TACO <HAS> 42.7 <C> [BOLD] MT-DNN <WITH> [BOLD] MC-TACO <HAS> – <C> [BOLD] XLNet <WITH> [BOLD] MC-TACO <HAS> – <C> [BOLD] RoBERTa <WITH> [BOLD] MC-TACO <HAS> [BOLD] 43.6 <C> [BOLD] ALBERT <WITH> [BOLD] MC-TACO <HAS> – <C> [BOLD] Human <WITH> [BOLD] MC-TACO <HAS> 75.8 <C> <R> <C> [BOLD]  Simple Baseline  <WITH> [BOLD] RACE <HAS> 24.9 <C> [BOLD] ELMo <WITH> [BOLD] RACE <HAS> – <C> [BOLD] GPT <WITH> [BOLD] RACE <HAS> 59.0 <C> [BOLD] BERT <WITH> [BOLD] RACE <HAS> 72.0 <C> [BOLD] MT-DNN <WITH> [BOLD] RACE <HAS> – <C> [BOLD] XLNet <WITH> [BOLD] RACE <HAS> 81.8 <C> [BOLD] RoBERTa <WITH> [BOLD] RACE <HAS> 83.2 <C> [BOLD] ALBERT <WITH> [BOLD] RACE <HAS> [BOLD] 89.4 <C> [BOLD] Human <WITH> [BOLD] RACE <HAS> 94.5 <C> <R> <C> [BOLD]  Simple Baseline  <WITH> [BOLD] SciTail <HAS> 60.3 <C> [BOLD] ELMo <WITH> [BOLD] SciTail <HAS> – <C> [BOLD] GPT <WITH> [BOLD] SciTail <HAS> 88.3 <C> [BOLD] BERT <WITH> [BOLD] SciTail <HAS> – <C> [BOLD] MT-DNN <WITH> [BOLD] SciTail <HAS> 94.1 <C> [BOLD] XLNet <WITH> [BOLD] SciTail <HAS> – <C> [BOLD] RoBERTa <WITH> [BOLD] SciTail <HAS> – <C> [BOLD] ALBERT <WITH> [BOLD] SciTail <HAS> – <C> [BOLD] Human <WITH> [BOLD] SciTail <HAS> – <C> <R> <C> [BOLD]  Simple Baseline  <WITH> [BOLD] SQuAD 1.1 <HAS> 1.3 <C> [BOLD] ELMo <WITH> [BOLD] SQuAD 1.1 <HAS> 81.0 <C> [BOLD] GPT <WITH> [BOLD] SQuAD 1.1 <HAS> – <C> [BOLD] BERT <WITH> [BOLD] SQuAD 1.1 <HAS> 87.4 <C> [BOLD] MT-DNN <WITH> [BOLD] SQuAD 1.1 <HAS> – <C> [BOLD] XLNet <WITH> [BOLD] SQuAD 1.1 <HAS> [BOLD] 89.9 <C> [BOLD] RoBERTa <WITH> [BOLD] SQuAD 1.1 <HAS> – <C> [BOLD] ALBERT <WITH> [BOLD] SQuAD 1.1 <HAS> – <C> [BOLD] Human <WITH> [BOLD] SQuAD 1.1 <HAS> 82.3 <C> <R> <C> [BOLD]  Simple Baseline  <WITH> [BOLD] SQuAD 2.0 <HAS> 48.9 <C> [BOLD] ELMo <WITH> [BOLD] SQuAD 2.0 <HAS> 63.4 <C> [BOLD] GPT <WITH> [BOLD] SQuAD 2.0 <HAS> – <C> [BOLD] BERT <WITH> [BOLD] SQuAD 2.0 <HAS> 80.8 <C> [BOLD] MT-DNN <WITH> [BOLD] SQuAD 2.0 <HAS> – <C> [BOLD] XLNet <WITH> [BOLD] SQuAD 2.0 <HAS> 86.3 <C> [BOLD] RoBERTa <WITH> [BOLD] SQuAD 2.0 <HAS> 86.8 <C> [BOLD] ALBERT <WITH> [BOLD] SQuAD 2.0 <HAS> [BOLD] 89.7 <C> [BOLD] Human <WITH> [BOLD] SQuAD 2.0 <HAS> 86.9 <C> <R> <C> [BOLD]  Simple Baseline  <WITH> [BOLD] SuperGLUE <HAS> 47.1 <C> [BOLD] ELMo <WITH> [BOLD] SuperGLUE <HAS> – <C> [BOLD] GPT <WITH> [BOLD] SuperGLUE <HAS> – <C> [BOLD] BERT <WITH> [BOLD] SuperGLUE <HAS> 69.0 <C> [BOLD] MT-DNN <WITH> [BOLD] SuperGLUE <HAS> – <C> [BOLD] XLNet <WITH> [BOLD] SuperGLUE <HAS> – <C> [BOLD] RoBERTa <WITH> [BOLD] SuperGLUE <HAS> [BOLD] 84.6 <C> [BOLD] ALBERT <WITH> [BOLD] SuperGLUE <HAS> – <C> [BOLD] Human <WITH> [BOLD] SuperGLUE <HAS> 89.8 <C> <R> <C> [BOLD]  Simple Baseline  <WITH> [BOLD] SWAG <HAS> 25.0 <C> [BOLD] ELMo <WITH> [BOLD] SWAG <HAS> 59.1 <C> [BOLD] GPT <WITH> [BOLD] SWAG <HAS> 78.0 <C> [BOLD] BERT <WITH> [BOLD] SWAG <HAS> 86.3 <C> [BOLD] MT-DNN <WITH> [BOLD] SWAG <HAS> 87.1 <C> [BOLD] XLNet <WITH> [BOLD] SWAG <HAS> – <C> [BOLD] RoBERTa <WITH> [BOLD] SWAG <HAS> [BOLD] 89.9 <C> [BOLD] ALBERT <WITH> [BOLD] SWAG <HAS> – <C> [BOLD] Human <WITH> [BOLD] SWAG <HAS> 88.0 <C> <CAP> Table 2: Comparison of exact-match accuracy achieved on selected benchmarks by a random or majority-choice baseline, various neural contextual embedding models, and humans. ELMo refers to the highest-performing listed approach using ELMo embeddings. Best system performance on each benchmark in bold. Information extracted from leaderboards (linked to in the first column) at time of writing (October 2019), and original papers for benchmarks introduced in Section 2.
 <R> <C> ACE05 <WITH> BERT + LSTM <HAS> 85.8 <C> SciERC <WITH> BERT + LSTM <HAS> 69.9 <C> GENIA <WITH> BERT + LSTM <HAS> 78.4 <C> WLPC <WITH> BERT + LSTM <HAS> [BOLD] 78.9 <C> <R> <C> ACE05 <WITH> +RelProp <HAS> 85.7 <C> SciERC <WITH> +RelProp <HAS> 70.5 <C> GENIA <WITH> +RelProp <HAS> - <C> WLPC <WITH> +RelProp <HAS> 78.7 <C> <R> <C> ACE05 <WITH> +CorefProp <HAS> 86.3 <C> SciERC <WITH> +CorefProp <HAS> [BOLD] 72.0 <C> GENIA <WITH> +CorefProp <HAS> 78.3 <C> WLPC <WITH> +CorefProp <HAS> - <C> <R> <C> ACE05 <WITH> BERT Finetune <HAS> 87.3 <C> SciERC <WITH> BERT Finetune <HAS> 70.5 <C> GENIA <WITH> BERT Finetune <HAS> 78.3 <C> WLPC <WITH> BERT Finetune <HAS> 78.5 <C> <R> <C> ACE05 <WITH> +RelProp <HAS> 86.7 <C> SciERC <WITH> +RelProp <HAS> 71.1 <C> GENIA <WITH> +RelProp <HAS> - <C> WLPC <WITH> +RelProp <HAS> 78.8 <C> <R> <C> ACE05 <WITH> +CorefProp <HAS> [BOLD] 87.5 <C> SciERC <WITH> +CorefProp <HAS> 71.1 <C> GENIA <WITH> +CorefProp <HAS> [BOLD] 79.5 <C> WLPC <WITH> +CorefProp <HAS> - <C> <CAP> Table 2: F1 scores on NER.
 <R> <C> Task <WITH> ACE05 <HAS> Entity <C> SOTA <WITH> ACE05 <HAS> 88.4 <C> Ours <WITH> ACE05 <HAS> [BOLD] 88.6 <C> Δ% <WITH> ACE05 <HAS> 1.7 <C> <R> <C> Task <WITH> ACE05 <HAS> Relation <C> SOTA <WITH> ACE05 <HAS> 63.2 <C> Ours <WITH> ACE05 <HAS> [BOLD] 63.4 <C> Δ% <WITH> ACE05 <HAS> 0.5 <C> <R> <C> Task <WITH> ACE05-Event* <HAS> Entity <C> SOTA <WITH> ACE05-Event* <HAS> 87.1 <C> Ours <WITH> ACE05-Event* <HAS> [BOLD] 90.7 <C> Δ% <WITH> ACE05-Event* <HAS> 27.9 <C> <R> <C> Task <WITH> ACE05-Event* <HAS> Trig-ID <C> SOTA <WITH> ACE05-Event* <HAS> 73.9 <C> Ours <WITH> ACE05-Event* <HAS> [BOLD] 76.5 <C> Δ% <WITH> ACE05-Event* <HAS> 9.6 <C> <R> <C> Task <WITH> ACE05-Event* <HAS> Trig-C <C> SOTA <WITH> ACE05-Event* <HAS> 72.0 <C> Ours <WITH> ACE05-Event* <HAS> [BOLD] 73.6 <C> Δ% <WITH> ACE05-Event* <HAS> 5.7 <C> <R> <C> Task <WITH> ACE05-Event* <HAS> Arg-ID <C> SOTA <WITH> ACE05-Event* <HAS> [BOLD] 57.2 <C> Ours <WITH> ACE05-Event* <HAS> 55.4 <C> Δ% <WITH> ACE05-Event* <HAS> -4.2 <C> <R> <C> Task <WITH> ACE05-Event* <HAS> Arg-C <C> SOTA <WITH> ACE05-Event* <HAS> 52.4 <C> Ours <WITH> ACE05-Event* <HAS> [BOLD] 52.5 <C> Δ% <WITH> ACE05-Event* <HAS> 0.2 <C> <R> <C> Task <WITH> SciERC <HAS> Entity <C> SOTA <WITH> SciERC <HAS> 65.2 <C> Ours <WITH> SciERC <HAS> [BOLD] 67.5 <C> Δ% <WITH> SciERC <HAS> 6.6 <C> <R> <C> Task <WITH> SciERC <HAS> Relation <C> SOTA <WITH> SciERC <HAS> 41.6 <C> Ours <WITH> SciERC <HAS> [BOLD] 48.4 <C> Δ% <WITH> SciERC <HAS> 11.6 <C> <R> <C> Task <WITH> GENIA <HAS> Entity <C> SOTA <WITH> GENIA <HAS> 76.2 <C> Ours <WITH> GENIA <HAS> [BOLD] 77.9 <C> Δ% <WITH> GENIA <HAS> 7.1 <C> <R> <C> Task <WITH> WLPC <HAS> Entity <C> SOTA <WITH> WLPC <HAS> 79.5 <C> Ours <WITH> WLPC <HAS> [BOLD] 79.7 <C> Δ% <WITH> WLPC <HAS> 1.0 <C> <R> <C> Task <WITH> WLPC <HAS> Relation <C> SOTA <WITH> WLPC <HAS> 64.1 <C> Ours <WITH> WLPC <HAS> [BOLD] 65.9 <C> Δ% <WITH> WLPC <HAS> 5.0 <C> <CAP> Table 1: DyGIE++ achieves state-of-the-art results. Test set F1 scores of best model, on all tasks and datasets. We define the following notations for events: Trig: Trigger, Arg: argument, ID: Identification, C: Classification. * indicates the use of a 4-model ensemble for trigger detection. See Appendix E for details. The results of the single model are reported in Table 2 (c). We ran significance tests on a subset of results in Appendix D. All were statistically significant except Arg-C and Arg-ID on ACE05-Event.
 <R> <C> ACE05 <WITH> BERT + LSTM <HAS> 60.6 <C> SciERC <WITH> BERT + LSTM <HAS> 40.3 <C> WLPC <WITH> BERT + LSTM <HAS> 65.1 <C> <R> <C> ACE05 <WITH> +RelProp <HAS> 61.9 <C> SciERC <WITH> +RelProp <HAS> 41.1 <C> WLPC <WITH> +RelProp <HAS> 65.3 <C> <R> <C> ACE05 <WITH> +CorefProp <HAS> 59.7 <C> SciERC <WITH> +CorefProp <HAS> 42.6 <C> WLPC <WITH> +CorefProp <HAS> - <C> <R> <C> ACE05 <WITH> BERT FineTune <HAS> [BOLD] 62.1 <C> SciERC <WITH> BERT FineTune <HAS> 44.3 <C> WLPC <WITH> BERT FineTune <HAS> 65.4 <C> <R> <C> ACE05 <WITH> +RelProp <HAS> 62.0 <C> SciERC <WITH> +RelProp <HAS> 43.0 <C> WLPC <WITH> +RelProp <HAS> [BOLD] 65.5 <C> <R> <C> ACE05 <WITH> +CorefProp <HAS> 60.0 <C> SciERC <WITH> +CorefProp <HAS> [BOLD] 45.3 <C> WLPC <WITH> +CorefProp <HAS> - <C> <CAP> Table 3: F1 scores on Relation.
 <R> <C> SciERC Entity <WITH> Best BERT <HAS> 69.8 <C> SciERC Relation <WITH> Best BERT <HAS> 41.9 <C> GENIA Entity <WITH> Best BERT <HAS> 78.4 <C> <R> <C> SciERC Entity <WITH> Best SciBERT <HAS> [BOLD] 72.0 <C> SciERC Relation <WITH> Best SciBERT <HAS> [BOLD] 45.3 <C> GENIA Entity <WITH> Best SciBERT <HAS> [BOLD] 79.5 <C> <CAP> Table 7: In-domain pre-training: SciBERT vs. BERT
 <R> <C> Variation <WITH> Relation <HAS> BERT+LSTM <C> 1 <WITH> Relation <HAS> 59.3 <C> 3 <WITH> Relation <HAS> [BOLD] 60.6 <C> <R> <C> Variation <WITH> Relation <HAS> BERT Finetune <C> 1 <WITH> Relation <HAS> 62.0 <C> 3 <WITH> Relation <HAS> [BOLD] 62.1 <C> <R> <C> Variation <WITH> Entity <HAS> BERT+LSTM <C> 1 <WITH> Entity <HAS> 90.0 <C> 3 <WITH> Entity <HAS> [BOLD] 90.5 <C> <R> <C> Variation <WITH> Entity <HAS> BERT Finetune <C> 1 <WITH> Entity <HAS> 88.8 <C> 3 <WITH> Entity <HAS> [BOLD] 89.7 <C> <R> <C> Variation <WITH> Trigger <HAS> BERT+LSTM <C> 1 <WITH> Trigger <HAS> [BOLD] 69.4 <C> 3 <WITH> Trigger <HAS> 68.9 <C> <R> <C> Variation <WITH> Trigger <HAS> BERT Finetune <C> 1 <WITH> Trigger <HAS> 68.3 <C> 3 <WITH> Trigger <HAS> [BOLD] 69.7 <C> <R> <C> Variation <WITH> Arg Class <HAS> BERT+LSTM <C> 1 <WITH> Arg Class <HAS> 48.6 <C> 3 <WITH> Arg Class <HAS> [BOLD] 51.4 <C> <R> <C> Variation <WITH> Arg Class <HAS> BERT Finetune <C> 1 <WITH> Arg Class <HAS> [BOLD] 50.0 <C> 3 <WITH> Arg Class <HAS> 48.8 <C> <CAP> Table 6: Effect of BERT cross-sentence context. F1 score of relation F1 on ACE05 dev set and entity, arg, trigger extraction F1 on ACE05-E test set, as a function of the BERT context window size.
 <R> <C> En→It best <WITH> Artetxe et al., 2018b <HAS> [BOLD] 48.53 <C> En→It avg <WITH> Artetxe et al., 2018b <HAS> 48.13 <C> En→It iters <WITH> Artetxe et al., 2018b <HAS> 573 <C> En→De best <WITH> Artetxe et al., 2018b <HAS> 48.47 <C> En→De avg <WITH> Artetxe et al., 2018b <HAS> 48.19 <C> En→De iters <WITH> Artetxe et al., 2018b <HAS> 773 <C> En→Fi best <WITH> Artetxe et al., 2018b <HAS> 33.50 <C> En→Fi avg <WITH> Artetxe et al., 2018b <HAS> 32.63 <C> En→Fi iters <WITH> Artetxe et al., 2018b <HAS> 988 <C> En→Es best <WITH> Artetxe et al., 2018b <HAS> 37.60 <C> En→Es avg <WITH> Artetxe et al., 2018b <HAS> 37.33 <C> En→Es iters <WITH> Artetxe et al., 2018b <HAS> 808 <C> <R> <C> En→It best <WITH> Noise-aware Alignment <HAS> [BOLD] 48.53 <C> En→It avg <WITH> Noise-aware Alignment <HAS> [BOLD] 48.20 <C> En→It iters <WITH> Noise-aware Alignment <HAS> 471 <C> En→De best <WITH> Noise-aware Alignment <HAS> [BOLD] 49.67 <C> En→De avg <WITH> Noise-aware Alignment <HAS> [BOLD] 48.89 <C> En→De iters <WITH> Noise-aware Alignment <HAS> 568 <C> En→Fi best <WITH> Noise-aware Alignment <HAS> [BOLD] 33.98 <C> En→Fi avg <WITH> Noise-aware Alignment <HAS> [BOLD] 33.68 <C> En→Fi iters <WITH> Noise-aware Alignment <HAS> 502 <C> En→Es best <WITH> Noise-aware Alignment <HAS> [BOLD] 38.40 <C> En→Es avg <WITH> Noise-aware Alignment <HAS> [BOLD] 37.79 <C> En→Es iters <WITH> Noise-aware Alignment <HAS> 551 <C> <CAP> Table 1: Bilingual Experiment P@1. Numbers are based on 10 runs of each method. The En→De, En→Fi and En→Es improvements are significant at p<0.05 according to ANOVA on the different runs.
 <R> <C> RST-DTtest <WITH> Right Branching <HAS> 54.64 <C> Instr-DTtest <WITH> Right Branching <HAS> 58.47 <C> <R> <C> RST-DTtest <WITH> Left Branching <HAS> 53.73 <C> Instr-DTtest <WITH> Left Branching <HAS> 48.15 <C> <R> <C> RST-DTtest <WITH> Hier. Right Branch. <HAS> [BOLD] 70.82 <C> Instr-DTtest <WITH> Hier. Right Branch. <HAS> [BOLD] 67.86 <C> <R> <C> RST-DTtest <WITH> Hier. Left Branch. <HAS> 70.58 <C> Instr-DTtest <WITH> Hier. Left Branch. <HAS> 63.49 <C> <R> <C> RST-DTtest <WITH> [BOLD] Intra-Domain Evaluation <HAS> [BOLD] Intra-Domain Evaluation <C> Instr-DTtest <WITH> [BOLD] Intra-Domain Evaluation <HAS> [BOLD] Intra-Domain Evaluation <C> <R> <C> RST-DTtest <WITH> HILDAHernault et al. ( 2010 ) <HAS> 83.00 <C> Instr-DTtest <WITH> HILDAHernault et al. ( 2010 ) <HAS> — <C> <R> <C> RST-DTtest <WITH> DPLPJi and Eisenstein ( 2014 ) <HAS> 82.08 <C> Instr-DTtest <WITH> DPLPJi and Eisenstein ( 2014 ) <HAS> — <C> <R> <C> RST-DTtest <WITH> CODRAJoty et al. ( 2015 ) <HAS> 83.84 <C> Instr-DTtest <WITH> CODRAJoty et al. ( 2015 ) <HAS> [BOLD] 82.88 <C> <R> <C> RST-DTtest <WITH> Two-StageWang et al. ( 2017 ) <HAS> [BOLD] 86.00 <C> Instr-DTtest <WITH> Two-StageWang et al. ( 2017 ) <HAS> 77.28 <C> <R> <C> RST-DTtest <WITH> [BOLD] Inter-Domain Evaluation <HAS> [BOLD] Inter-Domain Evaluation <C> Instr-DTtest <WITH> [BOLD] Inter-Domain Evaluation <HAS> [BOLD] Inter-Domain Evaluation <C> <R> <C> RST-DTtest <WITH> Two-StageRST-DT <HAS> × <C> Instr-DTtest <WITH> Two-StageRST-DT <HAS> 73.65 <C> <R> <C> RST-DTtest <WITH> Two-StageInstr-DT <HAS> 74.48 <C> Instr-DTtest <WITH> Two-StageInstr-DT <HAS> × <C> <R> <C> RST-DTtest <WITH> Two-StageOurs(avg) <HAS> 76.42 <C> Instr-DTtest <WITH> Two-StageOurs(avg) <HAS> [BOLD] 74.22 <C> <R> <C> RST-DTtest <WITH> Two-StageOurs(max) <HAS> [BOLD] 77.24 <C> Instr-DTtest <WITH> Two-StageOurs(max) <HAS> 73.12 <C> <R> <C> RST-DTtest <WITH> Human Morey et al. ( 2017 ) <HAS> 88.30 <C> Instr-DTtest <WITH> Human Morey et al. ( 2017 ) <HAS> — <C> <CAP> Table 3: Discourse structure prediction results; tested on RST-DTtest and Instr-DTtest. Subscripts in inter-domain evaluation sub-table indicate the training set. Best performance in the category is bold. Consistently best model for inter-domain discourse structure prediction is underlined
 <R> <C> TGPC Succ. (%) <WITH> Retrieval  <HAS> 7.16 <C> TGPC #Turns <WITH> Retrieval  <HAS> 4.17 <C> CWC Succ. (%) <WITH> Retrieval  <HAS> 0 <C> CWC #Turns <WITH> Retrieval  <HAS> - <C> <R> <C> TGPC Succ. (%) <WITH> Retrieval-Stgy  <HAS> 47.80 <C> TGPC #Turns <WITH> Retrieval-Stgy  <HAS> 6.7 <C> CWC Succ. (%) <WITH> Retrieval-Stgy  <HAS> 44.6 <C> CWC #Turns <WITH> Retrieval-Stgy  <HAS> 7.42 <C> <R> <C> TGPC Succ. (%) <WITH> PMI  <HAS> 35.36 <C> TGPC #Turns <WITH> PMI  <HAS> 6.38 <C> CWC Succ. (%) <WITH> PMI  <HAS> 47.4 <C> CWC #Turns <WITH> PMI  <HAS> 5.29 <C> <R> <C> TGPC Succ. (%) <WITH> Neural  <HAS> 54.76 <C> TGPC #Turns <WITH> Neural  <HAS> 4.73 <C> CWC Succ. (%) <WITH> Neural  <HAS> 47.6 <C> CWC #Turns <WITH> Neural  <HAS> 5.16 <C> <R> <C> TGPC Succ. (%) <WITH> Kernel  <HAS> 62.56 <C> TGPC #Turns <WITH> Kernel  <HAS> 4.65 <C> CWC Succ. (%) <WITH> Kernel  <HAS> 53.2 <C> CWC #Turns <WITH> Kernel  <HAS> 4.08 <C> <R> <C> TGPC Succ. (%) <WITH> DKRN (ours) <HAS> [BOLD] 89.0 <C> TGPC #Turns <WITH> DKRN (ours) <HAS> 5.02 <C> CWC Succ. (%) <WITH> DKRN (ours) <HAS> [BOLD] 84.4 <C> CWC #Turns <WITH> DKRN (ours) <HAS> 4.20 <C> <CAP> Table 4: Results of Self-Play Evaluation.
 <R> <C> System <WITH> TGPC <HAS> Retrieval  <C> Keyword Prediction  [ITALIC] Rw@1 <WITH> TGPC <HAS> - <C> Keyword Prediction  [ITALIC] Rw@3 <WITH> TGPC <HAS> - <C> Keyword Prediction  [ITALIC] Rw@5 <WITH> TGPC <HAS> - <C> Keyword Prediction P@1 <WITH> TGPC <HAS> - <C> Response Retrieval  [ITALIC] R20@1 <WITH> TGPC <HAS> 0.5063 <C> Response Retrieval  [ITALIC] R20@3 <WITH> TGPC <HAS> 0.7615 <C> Response Retrieval  [ITALIC] R20@5 <WITH> TGPC <HAS> 0.8676 <C> Response Retrieval MRR <WITH> TGPC <HAS> 0.6589 <C> <R> <C> System <WITH> TGPC <HAS> PMI  <C> Keyword Prediction  [ITALIC] Rw@1 <WITH> TGPC <HAS> 0.0585 <C> Keyword Prediction  [ITALIC] Rw@3 <WITH> TGPC <HAS> 0.1351 <C> Keyword Prediction  [ITALIC] Rw@5 <WITH> TGPC <HAS> 0.1872 <C> Keyword Prediction P@1 <WITH> TGPC <HAS> 0.0871 <C> Response Retrieval  [ITALIC] R20@1 <WITH> TGPC <HAS> 0.5441 <C> Response Retrieval  [ITALIC] R20@3 <WITH> TGPC <HAS> 0.7839 <C> Response Retrieval  [ITALIC] R20@5 <WITH> TGPC <HAS> 0.8716 <C> Response Retrieval MRR <WITH> TGPC <HAS> 0.6847 <C> <R> <C> System <WITH> TGPC <HAS> Neural  <C> Keyword Prediction  [ITALIC] Rw@1 <WITH> TGPC <HAS> 0.0708 <C> Keyword Prediction  [ITALIC] Rw@3 <WITH> TGPC <HAS> 0.1438 <C> Keyword Prediction  [ITALIC] Rw@5 <WITH> TGPC <HAS> 0.1820 <C> Keyword Prediction P@1 <WITH> TGPC <HAS> 0.1321 <C> Response Retrieval  [ITALIC] R20@1 <WITH> TGPC <HAS> 0.5311 <C> Response Retrieval  [ITALIC] R20@3 <WITH> TGPC <HAS> 0.7905 <C> Response Retrieval  [ITALIC] R20@5 <WITH> TGPC <HAS> 0.8800 <C> Response Retrieval MRR <WITH> TGPC <HAS> 0.6822 <C> <R> <C> System <WITH> TGPC <HAS> Kernel  <C> Keyword Prediction  [ITALIC] Rw@1 <WITH> TGPC <HAS> 0.0632 <C> Keyword Prediction  [ITALIC] Rw@3 <WITH> TGPC <HAS> 0.1377 <C> Keyword Prediction  [ITALIC] Rw@5 <WITH> TGPC <HAS> 0.1798 <C> Keyword Prediction P@1 <WITH> TGPC <HAS> 0.1172 <C> Response Retrieval  [ITALIC] R20@1 <WITH> TGPC <HAS> 0.5386 <C> Response Retrieval  [ITALIC] R20@3 <WITH> TGPC <HAS> 0.8012 <C> Response Retrieval  [ITALIC] R20@5 <WITH> TGPC <HAS> 0.8924 <C> Response Retrieval MRR <WITH> TGPC <HAS> 0.6877 <C> <R> <C> System <WITH> TGPC <HAS> DKRN (ours) <C> Keyword Prediction  [ITALIC] Rw@1 <WITH> TGPC <HAS> [BOLD] 0.0909 <C> Keyword Prediction  [ITALIC] Rw@3 <WITH> TGPC <HAS> [BOLD] 0.1903 <C> Keyword Prediction  [ITALIC] Rw@5 <WITH> TGPC <HAS> [BOLD] 0.2477 <C> Keyword Prediction P@1 <WITH> TGPC <HAS> [BOLD] 0.1685 <C> Response Retrieval  [ITALIC] R20@1 <WITH> TGPC <HAS> [BOLD] 0.5729 <C> Response Retrieval  [ITALIC] R20@3 <WITH> TGPC <HAS> [BOLD] 0.8132 <C> Response Retrieval  [ITALIC] R20@5 <WITH> TGPC <HAS> [BOLD] 0.8966 <C> Response Retrieval MRR <WITH> TGPC <HAS> [BOLD] 0.7110 <C> <R> <C> System <WITH> CWC <HAS> Retrieval  <C> Keyword Prediction  [ITALIC] Rw@1 <WITH> CWC <HAS> - <C> Keyword Prediction  [ITALIC] Rw@3 <WITH> CWC <HAS> - <C> Keyword Prediction  [ITALIC] Rw@5 <WITH> CWC <HAS> - <C> Keyword Prediction P@1 <WITH> CWC <HAS> - <C> Response Retrieval  [ITALIC] R20@1 <WITH> CWC <HAS> 0.5785 <C> Response Retrieval  [ITALIC] R20@3 <WITH> CWC <HAS> 0.8101 <C> Response Retrieval  [ITALIC] R20@5 <WITH> CWC <HAS> 0.8999 <C> Response Retrieval MRR <WITH> CWC <HAS> 0.7141 <C> <R> <C> System <WITH> CWC <HAS> PMI  <C> Keyword Prediction  [ITALIC] Rw@1 <WITH> CWC <HAS> 0.0555 <C> Keyword Prediction  [ITALIC] Rw@3 <WITH> CWC <HAS> 0.1001 <C> Keyword Prediction  [ITALIC] Rw@5 <WITH> CWC <HAS> 0.1212 <C> Keyword Prediction P@1 <WITH> CWC <HAS> 0.0969 <C> Response Retrieval  [ITALIC] R20@1 <WITH> CWC <HAS> 0.5945 <C> Response Retrieval  [ITALIC] R20@3 <WITH> CWC <HAS> 0.8185 <C> Response Retrieval  [ITALIC] R20@5 <WITH> CWC <HAS> 0.9054 <C> Response Retrieval MRR <WITH> CWC <HAS> 0.7257 <C> <R> <C> System <WITH> CWC <HAS> Neural  <C> Keyword Prediction  [ITALIC] Rw@1 <WITH> CWC <HAS> 0.0654 <C> Keyword Prediction  [ITALIC] Rw@3 <WITH> CWC <HAS> 0.1194 <C> Keyword Prediction  [ITALIC] Rw@5 <WITH> CWC <HAS> 0.1450 <C> Keyword Prediction P@1 <WITH> CWC <HAS> 0.1141 <C> Response Retrieval  [ITALIC] R20@1 <WITH> CWC <HAS> 0.6044 <C> Response Retrieval  [ITALIC] R20@3 <WITH> CWC <HAS> 0.8233 <C> Response Retrieval  [ITALIC] R20@5 <WITH> CWC <HAS> 0.9085 <C> Response Retrieval MRR <WITH> CWC <HAS> 0.7326 <C> <R> <C> System <WITH> CWC <HAS> Kernel  <C> Keyword Prediction  [ITALIC] Rw@1 <WITH> CWC <HAS> 0.0592 <C> Keyword Prediction  [ITALIC] Rw@3 <WITH> CWC <HAS> 0.1113 <C> Keyword Prediction  [ITALIC] Rw@5 <WITH> CWC <HAS> 0.1337 <C> Keyword Prediction P@1 <WITH> CWC <HAS> 0.1011 <C> Response Retrieval  [ITALIC] R20@1 <WITH> CWC <HAS> 0.6017 <C> Response Retrieval  [ITALIC] R20@3 <WITH> CWC <HAS> 0.8234 <C> Response Retrieval  [ITALIC] R20@5 <WITH> CWC <HAS> 0.9087 <C> Response Retrieval MRR <WITH> CWC <HAS> 0.7320 <C> <R> <C> System <WITH> CWC <HAS> DKRN (ours) <C> Keyword Prediction  [ITALIC] Rw@1 <WITH> CWC <HAS> [BOLD] 0.0680 <C> Keyword Prediction  [ITALIC] Rw@3 <WITH> CWC <HAS> [BOLD] 0.1254 <C> Keyword Prediction  [ITALIC] Rw@5 <WITH> CWC <HAS> [BOLD] 0.1548 <C> Keyword Prediction P@1 <WITH> CWC <HAS> [BOLD] 0.1185 <C> Response Retrieval  [ITALIC] R20@1 <WITH> CWC <HAS> [BOLD] 0.6324 <C> Response Retrieval  [ITALIC] R20@3 <WITH> CWC <HAS> [BOLD] 0.8416 <C> Response Retrieval  [ITALIC] R20@5 <WITH> CWC <HAS> [BOLD] 0.9183 <C> Response Retrieval MRR <WITH> CWC <HAS> [BOLD] 0.7533 <C> <CAP> Table 3: Results of Turn-level Evaluation.
 <R> <C> Succ. (%) <WITH> Retrieval-Stgy  <HAS> 54.0 <C> Smoothness <WITH> Retrieval-Stgy  <HAS> 2.48 <C> <R> <C> Succ. (%) <WITH> PMI  <HAS> 46.0 <C> Smoothness <WITH> PMI  <HAS> 2.56 <C> <R> <C> Succ. (%) <WITH> Neural  <HAS> 36.0 <C> Smoothness <WITH> Neural  <HAS> 2.50 <C> <R> <C> Succ. (%) <WITH> Kernel  <HAS> 58.0 <C> Smoothness <WITH> Kernel  <HAS> 2.48 <C> <R> <C> Succ. (%) <WITH> DKRN (ours) <HAS> [BOLD] 88.0 <C> Smoothness <WITH> DKRN (ours) <HAS> [BOLD] 3.22 <C> <CAP> Table 5: Results of the Human Rating on CWC.
 <R> <C> Ours Better(%) <WITH> Retrieval-Stgy  <HAS> [BOLD] 62 <C> No Prefer(%) <WITH> Retrieval-Stgy  <HAS> 22 <C> Ours Worse(%) <WITH> Retrieval-Stgy  <HAS> 16 <C> <R> <C> Ours Better(%) <WITH> PMI  <HAS> [BOLD] 54 <C> No Prefer(%) <WITH> PMI  <HAS> 32 <C> Ours Worse(%) <WITH> PMI  <HAS> 14 <C> <R> <C> Ours Better(%) <WITH> Neural  <HAS> [BOLD] 60 <C> No Prefer(%) <WITH> Neural  <HAS> 22 <C> Ours Worse(%) <WITH> Neural  <HAS> 18 <C> <R> <C> Ours Better(%) <WITH> Kernel  <HAS> [BOLD] 62 <C> No Prefer(%) <WITH> Kernel  <HAS> 26 <C> Ours Worse(%) <WITH> Kernel  <HAS> 12 <C> <CAP> Table 6: Results of the Human Rating on CWC.
 <R> <C> [BOLD] Eval set % <WITH> Baseline (No SA)Anderson et al. ( 2018 ) <HAS> 55.00 <C> [BOLD] #param <WITH> Baseline (No SA)Anderson et al. ( 2018 ) <HAS> 0M <C> <R> <C> [BOLD] Eval set % <WITH> SA (S: 1,2,3 - B: 1) <HAS> 55.11 <C> [BOLD] #param <WITH> SA (S: 1,2,3 - B: 1) <HAS> } 0.107M <C> <R> <C> [BOLD] Eval set % <WITH> SA (S: 1,2,3 - B: 2) <HAS> 55.17 <C> [BOLD] #param <WITH> SA (S: 1,2,3 - B: 2) <HAS> } 0.107M <C> <R> <C> [BOLD] Eval set % <WITH> [BOLD] SA (S: 1,2,3 - B: 3) <HAS> [BOLD] 55.27 <C> [BOLD] #param <WITH> [BOLD] SA (S: 1,2,3 - B: 3) <HAS> } 0.107M <C> <CAP> Table 1: Experiments run on a ResNet-34. Numbers following S (stages) and B (blocks) indicate where SA (self-attention) modules are put. Parameters count concerns only SA and are in millions (M).
 <R> <C> [BOLD] Eval set % <WITH> SA (S: 3 - M: 1) <HAS> 55.25 <C> [BOLD] #param <WITH> SA (S: 3 - M: 1) <HAS> } 0.082M <C> <R> <C> [BOLD] Eval set % <WITH> [BOLD] SA (S: 3 - B: 3) <HAS> [BOLD] 55.42 <C> [BOLD] #param <WITH> [BOLD] SA (S: 3 - B: 3) <HAS> } 0.082M <C> <R> <C> [BOLD] Eval set % <WITH> SA (S: 3 - B: 4) <HAS> 55.33 <C> [BOLD] #param <WITH> SA (S: 3 - B: 4) <HAS> } 0.082M <C> <R> <C> [BOLD] Eval set % <WITH> SA (S: 3 - B: 6) <HAS> 55.31 <C> [BOLD] #param <WITH> SA (S: 3 - B: 6) <HAS> } 0.082M <C> <R> <C> [BOLD] Eval set % <WITH> SA (S: 3 - B: 1,3,5) <HAS> 55.45 <C> [BOLD] #param <WITH> SA (S: 3 - B: 1,3,5) <HAS> } 0.245M <C> <R> <C> [BOLD] Eval set % <WITH> [BOLD] SA (S: 3 - B: 2,4,6) <HAS> [BOLD] 55.56 <C> [BOLD] #param <WITH> [BOLD] SA (S: 3 - B: 2,4,6) <HAS> } 0.245M <C> <CAP> Table 1: Experiments run on a ResNet-34. Numbers following S (stages) and B (blocks) indicate where SA (self-attention) modules are put. Parameters count concerns only SA and are in millions (M).
 <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] ILP <HAS> 24.5 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] ILP <HAS> 41.1 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] ILP <HAS> 29.3±0.5 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] ILP <HAS> 7.9 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] ILP <HAS> 15.0 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] ILP <HAS> 9.9±0.5 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] ILP <HAS> 13.6 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] ILP <HAS> 22.6 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] ILP <HAS> 15.6±0.4 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] Sum-Basic <HAS> 28.4 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] Sum-Basic <HAS> 44.4 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] Sum-Basic <HAS> 33.1±0.5 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] Sum-Basic <HAS> 8.5 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] Sum-Basic <HAS> 15.6 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] Sum-Basic <HAS> 10.4±0.4 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] Sum-Basic <HAS> 14.7 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] Sum-Basic <HAS> 22.9 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] Sum-Basic <HAS> 16.7±0.5 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] KL-Sum <HAS> 39.5 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] KL-Sum <HAS> 34.6 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] KL-Sum <HAS> 35.5±0.5 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] KL-Sum <HAS> 13.0 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] KL-Sum <HAS> 12.7 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] KL-Sum <HAS> 12.3±0.5 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] KL-Sum <HAS> 15.2 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] KL-Sum <HAS> 21.1 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] KL-Sum <HAS> 16.3±0.5 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] LexRank <HAS> 42.1 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] LexRank <HAS> 39.5 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] LexRank <HAS> 38.7±0.5 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] LexRank <HAS> 14.7 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] LexRank <HAS> 15.3 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] LexRank <HAS> 14.2±0.5 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] LexRank <HAS> 14.3 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] LexRank <HAS> 21.5 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] LexRank <HAS> 16.0±0.5 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] MEAD <HAS> 45.5 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] MEAD <HAS> 36.5 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] MEAD <HAS> 38.5± 0.5 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] MEAD <HAS> 17.9 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] MEAD <HAS> 14.9 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] MEAD <HAS> 15.4±0.5 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] MEAD <HAS> 27.8 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] MEAD <HAS> 29.2 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] MEAD <HAS> 26.8±0.5 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] SVM <HAS> 19.0 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] SVM <HAS> 48.8 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] SVM <HAS> 24.7±0.8 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] SVM <HAS> 7.5 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] SVM <HAS> 21.1 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] SVM <HAS> 10.0±0.5 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] SVM <HAS> 32.7 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] SVM <HAS> 34.3 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] SVM <HAS> 31.4±0.4 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] LogReg <HAS> 26.9 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] LogReg <HAS> 34.5 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] LogReg <HAS> 28.7±0.6 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] LogReg <HAS> 6.4 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] LogReg <HAS> 9.9 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] LogReg <HAS> 7.3±0.4 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] LogReg <HAS> 12.2 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] LogReg <HAS> 14.9 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] LogReg <HAS> 12.7±0.5 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] LogReg [ITALIC] r <HAS> 28.0 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] LogReg [ITALIC] r <HAS> 34.8 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] LogReg [ITALIC] r <HAS> 29.4±0.6 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] LogReg [ITALIC] r <HAS> 6.9 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] LogReg [ITALIC] r <HAS> 10.4 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] LogReg [ITALIC] r <HAS> 7.8±0.4 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] LogReg [ITALIC] r <HAS> 12.1 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] LogReg [ITALIC] r <HAS> 14.5 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] LogReg [ITALIC] r <HAS> 12.5±0.5 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] HAN <HAS> 31.0 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] HAN <HAS> 42.8 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] HAN <HAS> 33.7±0.7 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] HAN <HAS> 11.2 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] HAN <HAS> 17.8 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] HAN <HAS> 12.7±0.5 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] HAN <HAS> 26.9 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] HAN <HAS> 34.1 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] HAN <HAS> 32.4±0.5 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] HAN+pretrainT <HAS> 32.2 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] HAN+pretrainT <HAS> 42.4 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] HAN+pretrainT <HAS> 34.4±0.7 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] HAN+pretrainT <HAS> 11.5 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] HAN+pretrainT <HAS> 17.5 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] HAN+pretrainT <HAS> 12.9±0.5 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] HAN+pretrainT <HAS> 29.6 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] HAN+pretrainT <HAS> 35.8 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] HAN+pretrainT <HAS> 32.2±0.5 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] HAN+pretrainU <HAS> 32.1 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] HAN+pretrainU <HAS> 42.1 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] HAN+pretrainU <HAS> 33.8±0.7 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] HAN+pretrainU <HAS> 11.6 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] HAN+pretrainU <HAS> 17.6 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] HAN+pretrainU <HAS> 12.9±0.5 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] HAN+pretrainU <HAS> 30.1 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] HAN+pretrainU <HAS> 35.6 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] HAN+pretrainU <HAS> 32.3±0.5 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] HAN [ITALIC] r <HAS> 38.1 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] HAN [ITALIC] r <HAS> 40.5 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] HAN [ITALIC] r <HAS> [BOLD] 37.8±0.5 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] HAN [ITALIC] r <HAS> 14.0 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] HAN [ITALIC] r <HAS> 17.1 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] HAN [ITALIC] r <HAS> [BOLD] 14.7±0.5 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] HAN [ITALIC] r <HAS> 32.5 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] HAN [ITALIC] r <HAS> 34.4 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] HAN [ITALIC] r <HAS> [BOLD] 33.4±0.5 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] HAN+pretrainT [ITALIC] r <HAS> 37.9 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] HAN+pretrainT [ITALIC] r <HAS> 40.4 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] HAN+pretrainT [ITALIC] r <HAS> [BOLD] 37.6±0.5 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] HAN+pretrainT [ITALIC] r <HAS> 13.5 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] HAN+pretrainT [ITALIC] r <HAS> 16.8 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] HAN+pretrainT [ITALIC] r <HAS> [BOLD] 14.4±0.5 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] HAN+pretrainT [ITALIC] r <HAS> 32.5 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] HAN+pretrainT [ITALIC] r <HAS> 34.4 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] HAN+pretrainT [ITALIC] r <HAS> [BOLD] 33.4±0.5 <C> <R> <C> [BOLD] ROUGE-1  [BOLD] R (%) <WITH> [BOLD] HAN+pretrainU [ITALIC] r <HAS> 37.9 <C> [BOLD] ROUGE-1  [BOLD] P (%) <WITH> [BOLD] HAN+pretrainU [ITALIC] r <HAS> 40.4 <C> [BOLD] ROUGE-1  [BOLD] F (%) <WITH> [BOLD] HAN+pretrainU [ITALIC] r <HAS> [BOLD] 37.6±0.5 <C> [BOLD] ROUGE-2  [BOLD] R (%) <WITH> [BOLD] HAN+pretrainU [ITALIC] r <HAS> 13.6 <C> [BOLD] ROUGE-2  [BOLD] P (%) <WITH> [BOLD] HAN+pretrainU [ITALIC] r <HAS> 16.9 <C> [BOLD] ROUGE-2  [BOLD] F (%) <WITH> [BOLD] HAN+pretrainU [ITALIC] r <HAS> [BOLD] 14.4±0.5 <C> [BOLD] Sentence-Level  [BOLD] R (%) <WITH> [BOLD] HAN+pretrainU [ITALIC] r <HAS> 33.9 <C> [BOLD] Sentence-Level  [BOLD] P (%) <WITH> [BOLD] HAN+pretrainU [ITALIC] r <HAS> 33.8 <C> [BOLD] Sentence-Level  [BOLD] F (%) <WITH> [BOLD] HAN+pretrainU [ITALIC] r <HAS> [BOLD] 33.8±0.5 <C> <CAP> Table 1: Results of thread summarization. ‘HAN’ models are our proposed approaches adapted from the hierarchical attention networks [Yang et al.2016]. The models can be pretrained using unlabeled threads from TripAdvisor (‘T’) and Ubuntuforum (‘U’). r indicates a redundancy removal step is applied. We report the variance of F-scores across all threads (‘±’). A redundancy removal step improves recall scores (shown in gray) of the HAN models and boosts performance.
 <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> Delexicalisation-Based (DB) Model Mrkšić et al. ( 2017 ) <HAS> 69.1 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> Delexicalisation-Based (DB) Model Mrkšić et al. ( 2017 ) <HAS> 70.8 <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> DB Model + Semantic Dictionary Mrkšić et al. ( 2017 ) <HAS> 72.9 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> DB Model + Semantic Dictionary Mrkšić et al. ( 2017 ) <HAS> 83.7 <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> Scalable Multi-domain DST Rastogi et al. ( 2017 ) <HAS> 70.3 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> Scalable Multi-domain DST Rastogi et al. ( 2017 ) <HAS> - <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> MemN2N Perez and Liu ( 2017 ) <HAS> 74.0 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> MemN2N Perez and Liu ( 2017 ) <HAS> - <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> PtrNet Xu and Hu ( 2018 ) <HAS> 72.1 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> PtrNet Xu and Hu ( 2018 ) <HAS> - <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> Neural Belief Tracker: NBT-DNN Mrkšić et al. ( 2017 ) <HAS> 72.6 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> Neural Belief Tracker: NBT-DNN Mrkšić et al. ( 2017 ) <HAS> 84.4 <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> Neural Belief Tracker: NBT-CNN Mrkšić et al. ( 2017 ) <HAS> 73.4 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> Neural Belief Tracker: NBT-CNN Mrkšić et al. ( 2017 ) <HAS> 84.2 <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> Belief Tracking: Bi-LSTM Ramadan et al. ( 2018 ) <HAS> - <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> Belief Tracking: Bi-LSTM Ramadan et al. ( 2018 ) <HAS> 85.1 <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> Belief Tracking: CNN Ramadan et al. ( 2018 ) <HAS> - <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> Belief Tracking: CNN Ramadan et al. ( 2018 ) <HAS> 85.5 <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> GLAD Zhong et al. ( 2018 ) <HAS> 74.5 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> GLAD Zhong et al. ( 2018 ) <HAS> 88.1 <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> StateNet <HAS> 74.1 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> StateNet <HAS> 87.8 <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> StateNet_PS <HAS> 74.5 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> StateNet_PS <HAS> 88.2 <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> [BOLD] StateNet_PSI <HAS> [BOLD] 75.5 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> [BOLD] StateNet_PSI <HAS> [BOLD] 88.9 <C> <CAP> Table 1: Joint goal accuracy on DSTC2 and WOZ 2.0 test set vs. various approaches as reported in the literature.
 <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> [ITALIC] food <HAS> [BOLD] 75.5 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> [ITALIC] food <HAS> [BOLD] 88.9 <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> [ITALIC] pricerange <HAS> 73.6 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> [ITALIC] pricerange <HAS> 88.2 <C> <R> <C> [BOLD] Joint Acc. DSTC2 <WITH> [ITALIC] area <HAS> 73.5 <C> [BOLD] Joint Acc. WOZ 2.0 <WITH> [ITALIC] area <HAS> 87.8 <C> <CAP> Table 2: Joint goal accuracy on DSTC2 and WOZ 2.0 of StateNet_PSI using different pre-trained models based on different single slot.
 <R> <C> EN → DE R@1 <WITH> FME <HAS> 51.4 <C> EN → DE R@5 <WITH> FME <HAS> 76.4 <C> EN → DE R@10 <WITH> FME <HAS> 84.5 <C> DE → EN R@1 <WITH> FME <HAS> 46.9 <C> DE → EN R@5 <WITH> FME <HAS> 71.2 <C> DE → EN R@10 <WITH> FME <HAS> 79.1 <C> <R> <C> EN → DE R@1 <WITH> AME <HAS> [BOLD] 51.7 <C> EN → DE R@5 <WITH> AME <HAS> [BOLD] 76.7 <C> EN → DE R@10 <WITH> AME <HAS> [BOLD] 85.1 <C> DE → EN R@1 <WITH> AME <HAS> [BOLD] 49.1 <C> DE → EN R@5 <WITH> AME <HAS> [BOLD] 72.6 <C> DE → EN R@10 <WITH> AME <HAS> [BOLD] 80.5 <C> <CAP> Table 5: Textual similarity scores (asymmetric, Multi30k).
 <R> <C> Image to Text R@1 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Image to Text R@5 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Image to Text R@10 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Image to Text Mr <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image R@1 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image R@5 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image R@10 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image Mr <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Alignment <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> <R> <C> Image to Text R@1 <WITH> Parallel gella:17 <HAS> 31.7 <C> Image to Text R@5 <WITH> Parallel gella:17 <HAS> 62.4 <C> Image to Text R@10 <WITH> Parallel gella:17 <HAS> 74.1 <C> Image to Text Mr <WITH> Parallel gella:17 <HAS> 3 <C> Text to Image R@1 <WITH> Parallel gella:17 <HAS> 24.7 <C> Text to Image R@5 <WITH> Parallel gella:17 <HAS> 53.9 <C> Text to Image R@10 <WITH> Parallel gella:17 <HAS> 65.7 <C> Text to Image Mr <WITH> Parallel gella:17 <HAS> 5 <C> Alignment <WITH> Parallel gella:17 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> UVS kiros:15 <HAS> 23.0 <C> Image to Text R@5 <WITH> UVS kiros:15 <HAS> 50.7 <C> Image to Text R@10 <WITH> UVS kiros:15 <HAS> 62.9 <C> Image to Text Mr <WITH> UVS kiros:15 <HAS> 5 <C> Text to Image R@1 <WITH> UVS kiros:15 <HAS> 16.8 <C> Text to Image R@5 <WITH> UVS kiros:15 <HAS> 42.0 <C> Text to Image R@10 <WITH> UVS kiros:15 <HAS> 56.5 <C> Text to Image Mr <WITH> UVS kiros:15 <HAS> 8 <C> Alignment <WITH> UVS kiros:15 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> EmbeddingNet wang:18 <HAS> 40.7 <C> Image to Text R@5 <WITH> EmbeddingNet wang:18 <HAS> 69.7 <C> Image to Text R@10 <WITH> EmbeddingNet wang:18 <HAS> 79.2 <C> Image to Text Mr <WITH> EmbeddingNet wang:18 <HAS> - <C> Text to Image R@1 <WITH> EmbeddingNet wang:18 <HAS> 29.2 <C> Text to Image R@5 <WITH> EmbeddingNet wang:18 <HAS> 59.6 <C> Text to Image R@10 <WITH> EmbeddingNet wang:18 <HAS> 71.7 <C> Text to Image Mr <WITH> EmbeddingNet wang:18 <HAS> - <C> Alignment <WITH> EmbeddingNet wang:18 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> sm-LSTM huang:17 <HAS> 42.5 <C> Image to Text R@5 <WITH> sm-LSTM huang:17 <HAS> 71.9 <C> Image to Text R@10 <WITH> sm-LSTM huang:17 <HAS> 81.5 <C> Image to Text Mr <WITH> sm-LSTM huang:17 <HAS> 2 <C> Text to Image R@1 <WITH> sm-LSTM huang:17 <HAS> 30.2 <C> Text to Image R@5 <WITH> sm-LSTM huang:17 <HAS> 60.4 <C> Text to Image R@10 <WITH> sm-LSTM huang:17 <HAS> 72.3 <C> Text to Image Mr <WITH> sm-LSTM huang:17 <HAS> 3 <C> Alignment <WITH> sm-LSTM huang:17 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> VSE++ faghri:18 <HAS> [BOLD] 43.7 <C> Image to Text R@5 <WITH> VSE++ faghri:18 <HAS> 71.9 <C> Image to Text R@10 <WITH> VSE++ faghri:18 <HAS> 82.1 <C> Image to Text Mr <WITH> VSE++ faghri:18 <HAS> 2 <C> Text to Image R@1 <WITH> VSE++ faghri:18 <HAS> 32.3 <C> Text to Image R@5 <WITH> VSE++ faghri:18 <HAS> 60.9 <C> Text to Image R@10 <WITH> VSE++ faghri:18 <HAS> 72.1 <C> Text to Image Mr <WITH> VSE++ faghri:18 <HAS> 3 <C> Alignment <WITH> VSE++ faghri:18 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> Mono <HAS> 41.4 <C> Image to Text R@5 <WITH> Mono <HAS> 74.2 <C> Image to Text R@10 <WITH> Mono <HAS> 84.2 <C> Image to Text Mr <WITH> Mono <HAS> 2 <C> Text to Image R@1 <WITH> Mono <HAS> 32.1 <C> Text to Image R@5 <WITH> Mono <HAS> 63.0 <C> Text to Image R@10 <WITH> Mono <HAS> 73.9 <C> Text to Image Mr <WITH> Mono <HAS> 3 <C> Alignment <WITH> Mono <HAS> - <C> <R> <C> Image to Text R@1 <WITH> FME <HAS> 39.2 <C> Image to Text R@5 <WITH> FME <HAS> 71.1 <C> Image to Text R@10 <WITH> FME <HAS> 82.1 <C> Image to Text Mr <WITH> FME <HAS> 2 <C> Text to Image R@1 <WITH> FME <HAS> 29.7 <C> Text to Image R@5 <WITH> FME <HAS> 62.5 <C> Text to Image R@10 <WITH> FME <HAS> 74.1 <C> Text to Image Mr <WITH> FME <HAS> 3 <C> Alignment <WITH> FME <HAS> 76.81% <C> <R> <C> Image to Text R@1 <WITH> AME <HAS> 43.5 <C> Image to Text R@5 <WITH> AME <HAS> [BOLD] 77.2 <C> Image to Text R@10 <WITH> AME <HAS> [BOLD] 85.3 <C> Image to Text Mr <WITH> AME <HAS> [BOLD] 2 <C> Text to Image R@1 <WITH> AME <HAS> [BOLD] 34.0 <C> Text to Image R@5 <WITH> AME <HAS> [BOLD] 64.2 <C> Text to Image R@10 <WITH> AME <HAS> [BOLD] 75.4 <C> Text to Image Mr <WITH> AME <HAS> [BOLD] 3 <C> Alignment <WITH> AME <HAS> 66.91% <C> <R> <C> Image to Text R@1 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Image to Text R@5 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Image to Text R@10 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Image to Text Mr <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image R@1 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image R@5 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image R@10 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image Mr <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Alignment <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> <R> <C> Image to Text R@1 <WITH> Pivot gella:17 <HAS> 33.8 <C> Image to Text R@5 <WITH> Pivot gella:17 <HAS> 62.8 <C> Image to Text R@10 <WITH> Pivot gella:17 <HAS> 75.2 <C> Image to Text Mr <WITH> Pivot gella:17 <HAS> 3 <C> Text to Image R@1 <WITH> Pivot gella:17 <HAS> 26.2 <C> Text to Image R@5 <WITH> Pivot gella:17 <HAS> 56.4 <C> Text to Image R@10 <WITH> Pivot gella:17 <HAS> 68.4 <C> Text to Image Mr <WITH> Pivot gella:17 <HAS> 4 <C> Alignment <WITH> Pivot gella:17 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> Parallel gella:17 <HAS> 31.5 <C> Image to Text R@5 <WITH> Parallel gella:17 <HAS> 61.4 <C> Image to Text R@10 <WITH> Parallel gella:17 <HAS> 74.7 <C> Image to Text Mr <WITH> Parallel gella:17 <HAS> 3 <C> Text to Image R@1 <WITH> Parallel gella:17 <HAS> 27.1 <C> Text to Image R@5 <WITH> Parallel gella:17 <HAS> 56.2 <C> Text to Image R@10 <WITH> Parallel gella:17 <HAS> 66.9 <C> Text to Image Mr <WITH> Parallel gella:17 <HAS> 4 <C> Alignment <WITH> Parallel gella:17 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> Mono <HAS> 47.7 <C> Image to Text R@5 <WITH> Mono <HAS> 77.1 <C> Image to Text R@10 <WITH> Mono <HAS> 86.9 <C> Image to Text Mr <WITH> Mono <HAS> 2 <C> Text to Image R@1 <WITH> Mono <HAS> 35.8 <C> Text to Image R@5 <WITH> Mono <HAS> 66.6 <C> Text to Image R@10 <WITH> Mono <HAS> 76.8 <C> Text to Image Mr <WITH> Mono <HAS> 3 <C> Alignment <WITH> Mono <HAS> - <C> <R> <C> Image to Text R@1 <WITH> FME <HAS> 44.9 <C> Image to Text R@5 <WITH> FME <HAS> 76.9 <C> Image to Text R@10 <WITH> FME <HAS> 86.4 <C> Image to Text Mr <WITH> FME <HAS> 2 <C> Text to Image R@1 <WITH> FME <HAS> 34.2 <C> Text to Image R@5 <WITH> FME <HAS> 66.1 <C> Text to Image R@10 <WITH> FME <HAS> 77.1 <C> Text to Image Mr <WITH> FME <HAS> 3 <C> Alignment <WITH> FME <HAS> 76.81% <C> <R> <C> Image to Text R@1 <WITH> AME <HAS> [BOLD] 50.5 <C> Image to Text R@5 <WITH> AME <HAS> [BOLD] 79.7 <C> Image to Text R@10 <WITH> AME <HAS> [BOLD] 88.4 <C> Image to Text Mr <WITH> AME <HAS> [BOLD] 1 <C> Text to Image R@1 <WITH> AME <HAS> [BOLD] 38.0 <C> Text to Image R@5 <WITH> AME <HAS> [BOLD] 68.5 <C> Text to Image R@10 <WITH> AME <HAS> [BOLD] 78.4 <C> Text to Image Mr <WITH> AME <HAS> [BOLD] 2 <C> Alignment <WITH> AME <HAS> 73.10% <C> <CAP> Table 1: Image-caption ranking results for English (Multi30k)
 <R> <C> Image to Text R@1 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Image to Text R@5 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Image to Text R@10 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Image to Text Mr <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image R@1 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image R@5 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image R@10 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image Mr <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Alignment <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> <R> <C> Image to Text R@1 <WITH> Parallel gella:17 <HAS> 28.2 <C> Image to Text R@5 <WITH> Parallel gella:17 <HAS> 57.7 <C> Image to Text R@10 <WITH> Parallel gella:17 <HAS> 71.3 <C> Image to Text Mr <WITH> Parallel gella:17 <HAS> 4 <C> Text to Image R@1 <WITH> Parallel gella:17 <HAS> 20.9 <C> Text to Image R@5 <WITH> Parallel gella:17 <HAS> 46.9 <C> Text to Image R@10 <WITH> Parallel gella:17 <HAS> 59.3 <C> Text to Image Mr <WITH> Parallel gella:17 <HAS> 6 <C> Alignment <WITH> Parallel gella:17 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> Mono <HAS> 34.2 <C> Image to Text R@5 <WITH> Mono <HAS> 67.5 <C> Image to Text R@10 <WITH> Mono <HAS> 79.6 <C> Image to Text Mr <WITH> Mono <HAS> 3 <C> Text to Image R@1 <WITH> Mono <HAS> 26.5 <C> Text to Image R@5 <WITH> Mono <HAS> 54.7 <C> Text to Image R@10 <WITH> Mono <HAS> 66.2 <C> Text to Image Mr <WITH> Mono <HAS> 4 <C> Alignment <WITH> Mono <HAS> - <C> <R> <C> Image to Text R@1 <WITH> FME <HAS> 36.8 <C> Image to Text R@5 <WITH> FME <HAS> 69.4 <C> Image to Text R@10 <WITH> FME <HAS> 80.8 <C> Image to Text Mr <WITH> FME <HAS> 2 <C> Text to Image R@1 <WITH> FME <HAS> 26.6 <C> Text to Image R@5 <WITH> FME <HAS> 56.2 <C> Text to Image R@10 <WITH> FME <HAS> 68.5 <C> Text to Image Mr <WITH> FME <HAS> 4 <C> Alignment <WITH> FME <HAS> 76.81% <C> <R> <C> Image to Text R@1 <WITH> AME <HAS> [BOLD] 39.6 <C> Image to Text R@5 <WITH> AME <HAS> [BOLD] 72.7 <C> Image to Text R@10 <WITH> AME <HAS> [BOLD] 82.7 <C> Image to Text Mr <WITH> AME <HAS> [BOLD] 2 <C> Text to Image R@1 <WITH> AME <HAS> [BOLD] 28.9 <C> Text to Image R@5 <WITH> AME <HAS> [BOLD] 58.0 <C> Text to Image R@10 <WITH> AME <HAS> [BOLD] 68.7 <C> Text to Image Mr <WITH> AME <HAS> [BOLD] 4 <C> Alignment <WITH> AME <HAS> 66.91% <C> <R> <C> Image to Text R@1 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Image to Text R@5 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Image to Text R@10 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Image to Text Mr <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image R@1 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image R@5 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image R@10 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image Mr <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Alignment <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> <R> <C> Image to Text R@1 <WITH> Pivot gella:17 <HAS> 28.2 <C> Image to Text R@5 <WITH> Pivot gella:17 <HAS> 61.9 <C> Image to Text R@10 <WITH> Pivot gella:17 <HAS> 73.4 <C> Image to Text Mr <WITH> Pivot gella:17 <HAS> 3 <C> Text to Image R@1 <WITH> Pivot gella:17 <HAS> 22.5 <C> Text to Image R@5 <WITH> Pivot gella:17 <HAS> 49.3 <C> Text to Image R@10 <WITH> Pivot gella:17 <HAS> 61.7 <C> Text to Image Mr <WITH> Pivot gella:17 <HAS> 6 <C> Alignment <WITH> Pivot gella:17 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> Parallel gella:17 <HAS> 30.2 <C> Image to Text R@5 <WITH> Parallel gella:17 <HAS> 60.4 <C> Image to Text R@10 <WITH> Parallel gella:17 <HAS> 72.8 <C> Image to Text Mr <WITH> Parallel gella:17 <HAS> 3 <C> Text to Image R@1 <WITH> Parallel gella:17 <HAS> 21.8 <C> Text to Image R@5 <WITH> Parallel gella:17 <HAS> 50.5 <C> Text to Image R@10 <WITH> Parallel gella:17 <HAS> 62.3 <C> Text to Image Mr <WITH> Parallel gella:17 <HAS> 5 <C> Alignment <WITH> Parallel gella:17 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> Mono <HAS> [BOLD] 42.0 <C> Image to Text R@5 <WITH> Mono <HAS> 72.5 <C> Image to Text R@10 <WITH> Mono <HAS> 83.0 <C> Image to Text Mr <WITH> Mono <HAS> 2 <C> Text to Image R@1 <WITH> Mono <HAS> 29.6 <C> Text to Image R@5 <WITH> Mono <HAS> 58.4 <C> Text to Image R@10 <WITH> Mono <HAS> 69.6 <C> Text to Image Mr <WITH> Mono <HAS> 4 <C> Alignment <WITH> Mono <HAS> - <C> <R> <C> Image to Text R@1 <WITH> FME <HAS> 40.5 <C> Image to Text R@5 <WITH> FME <HAS> 73.3 <C> Image to Text R@10 <WITH> FME <HAS> 83.4 <C> Image to Text Mr <WITH> FME <HAS> 2 <C> Text to Image R@1 <WITH> FME <HAS> 29.6 <C> Text to Image R@5 <WITH> FME <HAS> 59.2 <C> Text to Image R@10 <WITH> FME <HAS> [BOLD] 72.1 <C> Text to Image Mr <WITH> FME <HAS> 3 <C> Alignment <WITH> FME <HAS> 76.81% <C> <R> <C> Image to Text R@1 <WITH> AME <HAS> 40.5 <C> Image to Text R@5 <WITH> AME <HAS> [BOLD] 74.3 <C> Image to Text R@10 <WITH> AME <HAS> [BOLD] 83.4 <C> Image to Text Mr <WITH> AME <HAS> [BOLD] 2 <C> Text to Image R@1 <WITH> AME <HAS> [BOLD] 31.0 <C> Text to Image R@5 <WITH> AME <HAS> [BOLD] 60.5 <C> Text to Image R@10 <WITH> AME <HAS> 70.6 <C> Text to Image Mr <WITH> AME <HAS> [BOLD] 3 <C> Alignment <WITH> AME <HAS> 73.10% <C> <CAP> Table 2: Image-caption ranking results for German (Multi30k)
 <R> <C> Image to Text R@1 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Image to Text R@5 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Image to Text R@10 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Image to Text Mr <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image R@1 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image R@5 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image R@10 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image Mr <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Alignment <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> <R> <C> Image to Text R@1 <WITH> UVS kiros:15 <HAS> 43.4 <C> Image to Text R@5 <WITH> UVS kiros:15 <HAS> 75.7 <C> Image to Text R@10 <WITH> UVS kiros:15 <HAS> 85.8 <C> Image to Text Mr <WITH> UVS kiros:15 <HAS> 2 <C> Text to Image R@1 <WITH> UVS kiros:15 <HAS> 31.0 <C> Text to Image R@5 <WITH> UVS kiros:15 <HAS> 66.7 <C> Text to Image R@10 <WITH> UVS kiros:15 <HAS> 79.9 <C> Text to Image Mr <WITH> UVS kiros:15 <HAS> 3 <C> Alignment <WITH> UVS kiros:15 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> EmbeddingNet wang:18 <HAS> 50.4 <C> Image to Text R@5 <WITH> EmbeddingNet wang:18 <HAS> 79.3 <C> Image to Text R@10 <WITH> EmbeddingNet wang:18 <HAS> 89.4 <C> Image to Text Mr <WITH> EmbeddingNet wang:18 <HAS> - <C> Text to Image R@1 <WITH> EmbeddingNet wang:18 <HAS> 39.8 <C> Text to Image R@5 <WITH> EmbeddingNet wang:18 <HAS> 75.3 <C> Text to Image R@10 <WITH> EmbeddingNet wang:18 <HAS> 86.6 <C> Text to Image Mr <WITH> EmbeddingNet wang:18 <HAS> - <C> Alignment <WITH> EmbeddingNet wang:18 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> sm-LSTM huang:17 <HAS> 53.2 <C> Image to Text R@5 <WITH> sm-LSTM huang:17 <HAS> 83.1 <C> Image to Text R@10 <WITH> sm-LSTM huang:17 <HAS> 91.5 <C> Image to Text Mr <WITH> sm-LSTM huang:17 <HAS> 1 <C> Text to Image R@1 <WITH> sm-LSTM huang:17 <HAS> 40.7 <C> Text to Image R@5 <WITH> sm-LSTM huang:17 <HAS> 75.8 <C> Text to Image R@10 <WITH> sm-LSTM huang:17 <HAS> 87.4 <C> Text to Image Mr <WITH> sm-LSTM huang:17 <HAS> 2 <C> Alignment <WITH> sm-LSTM huang:17 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> VSE++ faghri:18 <HAS> [BOLD] 58.3 <C> Image to Text R@5 <WITH> VSE++ faghri:18 <HAS> [BOLD] 86.1 <C> Image to Text R@10 <WITH> VSE++ faghri:18 <HAS> 93.3 <C> Image to Text Mr <WITH> VSE++ faghri:18 <HAS> 1 <C> Text to Image R@1 <WITH> VSE++ faghri:18 <HAS> [BOLD] 43.6 <C> Text to Image R@5 <WITH> VSE++ faghri:18 <HAS> 77.6 <C> Text to Image R@10 <WITH> VSE++ faghri:18 <HAS> 87.8 <C> Text to Image Mr <WITH> VSE++ faghri:18 <HAS> 2 <C> Alignment <WITH> VSE++ faghri:18 <HAS> - <C> <R> <C> Image to Text R@1 <WITH> Mono <HAS> 51.8 <C> Image to Text R@5 <WITH> Mono <HAS> 84.8 <C> Image to Text R@10 <WITH> Mono <HAS> 93.5 <C> Image to Text Mr <WITH> Mono <HAS> 1 <C> Text to Image R@1 <WITH> Mono <HAS> 40.0 <C> Text to Image R@5 <WITH> Mono <HAS> 77.3 <C> Text to Image R@10 <WITH> Mono <HAS> 89.4 <C> Text to Image Mr <WITH> Mono <HAS> 2 <C> Alignment <WITH> Mono <HAS> - <C> <R> <C> Image to Text R@1 <WITH> FME <HAS> 42.2 <C> Image to Text R@5 <WITH> FME <HAS> 76.6 <C> Image to Text R@10 <WITH> FME <HAS> 91.1 <C> Image to Text Mr <WITH> FME <HAS> 2 <C> Text to Image R@1 <WITH> FME <HAS> 31.2 <C> Text to Image R@5 <WITH> FME <HAS> 69.2 <C> Text to Image R@10 <WITH> FME <HAS> 83.7 <C> Text to Image Mr <WITH> FME <HAS> 3 <C> Alignment <WITH> FME <HAS> 92.70% <C> <R> <C> Image to Text R@1 <WITH> AME <HAS> 54.6 <C> Image to Text R@5 <WITH> AME <HAS> 85 <C> Image to Text R@10 <WITH> AME <HAS> [BOLD] 94.3 <C> Image to Text Mr <WITH> AME <HAS> [BOLD] 1 <C> Text to Image R@1 <WITH> AME <HAS> 42.1 <C> Text to Image R@5 <WITH> AME <HAS> [BOLD] 78.7 <C> Text to Image R@10 <WITH> AME <HAS> [BOLD] 90.3 <C> Text to Image Mr <WITH> AME <HAS> [BOLD] 2 <C> Alignment <WITH> AME <HAS> 82.54% <C> <R> <C> Image to Text R@1 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Image to Text R@5 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Image to Text R@10 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Image to Text Mr <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image R@1 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image R@5 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image R@10 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image Mr <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Alignment <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> <R> <C> Image to Text R@1 <WITH> Mono <HAS> 53.2 <C> Image to Text R@5 <WITH> Mono <HAS> 87.0 <C> Image to Text R@10 <WITH> Mono <HAS> 94.7 <C> Image to Text Mr <WITH> Mono <HAS> 1 <C> Text to Image R@1 <WITH> Mono <HAS> 42.3 <C> Text to Image R@5 <WITH> Mono <HAS> 78.9 <C> Text to Image R@10 <WITH> Mono <HAS> 90 <C> Text to Image Mr <WITH> Mono <HAS> 2 <C> Alignment <WITH> Mono <HAS> - <C> <R> <C> Image to Text R@1 <WITH> FME <HAS> 48.3 <C> Image to Text R@5 <WITH> FME <HAS> 83.6 <C> Image to Text R@10 <WITH> FME <HAS> 93.6 <C> Image to Text Mr <WITH> FME <HAS> 2 <C> Text to Image R@1 <WITH> FME <HAS> 37.2 <C> Text to Image R@5 <WITH> FME <HAS> 75.4 <C> Text to Image R@10 <WITH> FME <HAS> 88.4 <C> Text to Image Mr <WITH> FME <HAS> 2 <C> Alignment <WITH> FME <HAS> 92.70% <C> <R> <C> Image to Text R@1 <WITH> AME <HAS> [BOLD] 58.8 <C> Image to Text R@5 <WITH> AME <HAS> [BOLD] 88.6 <C> Image to Text R@10 <WITH> AME <HAS> [BOLD] 96.2 <C> Image to Text Mr <WITH> AME <HAS> [BOLD] 1 <C> Text to Image R@1 <WITH> AME <HAS> [BOLD] 46.2 <C> Text to Image R@5 <WITH> AME <HAS> [BOLD] 82.5 <C> Text to Image R@10 <WITH> AME <HAS> [BOLD] 91.9 <C> Text to Image Mr <WITH> AME <HAS> [BOLD] 2 <C> Alignment <WITH> AME <HAS> 84.99% <C> <CAP> Table 3: Image-caption ranking results for English (MS-COCO)
 <R> <C> Image to Text R@1 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Image to Text R@5 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Image to Text R@10 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Image to Text Mr <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image R@1 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image R@5 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image R@10 <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Text to Image Mr <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> Alignment <WITH> [BOLD] symmetric <HAS> [EMPTY] <C> <R> <C> Image to Text R@1 <WITH> Mono <HAS> 42.7 <C> Image to Text R@5 <WITH> Mono <HAS> 77.7 <C> Image to Text R@10 <WITH> Mono <HAS> 88.5 <C> Image to Text Mr <WITH> Mono <HAS> 2 <C> Text to Image R@1 <WITH> Mono <HAS> 33.1 <C> Text to Image R@5 <WITH> Mono <HAS> 69.8 <C> Text to Image R@10 <WITH> Mono <HAS> 84.3 <C> Text to Image Mr <WITH> Mono <HAS> 3 <C> Alignment <WITH> Mono <HAS> - <C> <R> <C> Image to Text R@1 <WITH> FME <HAS> 40.7 <C> Image to Text R@5 <WITH> FME <HAS> 77.7 <C> Image to Text R@10 <WITH> FME <HAS> 88.3 <C> Image to Text Mr <WITH> FME <HAS> 2 <C> Text to Image R@1 <WITH> FME <HAS> 30.0 <C> Text to Image R@5 <WITH> FME <HAS> 68.9 <C> Text to Image R@10 <WITH> FME <HAS> 83.1 <C> Text to Image Mr <WITH> FME <HAS> 3 <C> Alignment <WITH> FME <HAS> 92.70% <C> <R> <C> Image to Text R@1 <WITH> AME <HAS> [BOLD] 50.2 <C> Image to Text R@5 <WITH> AME <HAS> [BOLD] 85.6 <C> Image to Text R@10 <WITH> AME <HAS> [BOLD] 93.1 <C> Image to Text Mr <WITH> AME <HAS> [BOLD] 1 <C> Text to Image R@1 <WITH> AME <HAS> [BOLD] 40.2 <C> Text to Image R@5 <WITH> AME <HAS> [BOLD] 76.7 <C> Text to Image R@10 <WITH> AME <HAS> [BOLD] 87.8 <C> Text to Image Mr <WITH> AME <HAS> [BOLD] 2 <C> Alignment <WITH> AME <HAS> 82.54% <C> <R> <C> Image to Text R@1 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Image to Text R@5 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Image to Text R@10 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Image to Text Mr <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image R@1 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image R@5 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image R@10 <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Text to Image Mr <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> Alignment <WITH> [BOLD] asymmetric <HAS> [EMPTY] <C> <R> <C> Image to Text R@1 <WITH> Mono <HAS> 49.9 <C> Image to Text R@5 <WITH> Mono <HAS> 83.4 <C> Image to Text R@10 <WITH> Mono <HAS> 93.7 <C> Image to Text Mr <WITH> Mono <HAS> 2 <C> Text to Image R@1 <WITH> Mono <HAS> 39.7 <C> Text to Image R@5 <WITH> Mono <HAS> 76.5 <C> Text to Image R@10 <WITH> Mono <HAS> 88.3 <C> Text to Image Mr <WITH> Mono <HAS> [BOLD] 2 <C> Alignment <WITH> Mono <HAS> - <C> <R> <C> Image to Text R@1 <WITH> FME <HAS> 48.8 <C> Image to Text R@5 <WITH> FME <HAS> 81.9 <C> Image to Text R@10 <WITH> FME <HAS> 91.9 <C> Image to Text Mr <WITH> FME <HAS> 2 <C> Text to Image R@1 <WITH> FME <HAS> 37.0 <C> Text to Image R@5 <WITH> FME <HAS> 74.8 <C> Text to Image R@10 <WITH> FME <HAS> 87.0 <C> Text to Image Mr <WITH> FME <HAS> [BOLD] 2 <C> Alignment <WITH> FME <HAS> 92.70% <C> <R> <C> Image to Text R@1 <WITH> AME <HAS> [BOLD] 55.5 <C> Image to Text R@5 <WITH> AME <HAS> [BOLD] 87.9 <C> Image to Text R@10 <WITH> AME <HAS> [BOLD] 95.2 <C> Image to Text Mr <WITH> AME <HAS> [BOLD] 1 <C> Text to Image R@1 <WITH> AME <HAS> [BOLD] 44.9 <C> Text to Image R@5 <WITH> AME <HAS> [BOLD] 80.7 <C> Text to Image R@10 <WITH> AME <HAS> [BOLD] 89.3 <C> Text to Image Mr <WITH> AME <HAS> [BOLD] 2 <C> Alignment <WITH> AME <HAS> 84.99% <C> <CAP> Table 4: Image-caption ranking results for Japanese (MS-COCO)
 <R> <C> Italian Original <WITH> Same Gender <HAS> 0.442 <C> Italian Debiased <WITH> Same Gender <HAS> 0.434 <C> Italian English <WITH> Same Gender <HAS> 0.424 <C> Italian Reduction <WITH> Same Gender <HAS> – <C> German Original <WITH> Same Gender <HAS> 0.491 <C> German Debiased <WITH> Same Gender <HAS> 0.478 <C> German English <WITH> Same Gender <HAS> 0.446 <C> German Reduction <WITH> Same Gender <HAS> – <C> <R> <C> Italian Original <WITH> Different Gender <HAS> 0.385 <C> Italian Debiased <WITH> Different Gender <HAS> 0.421 <C> Italian English <WITH> Different Gender <HAS> 0.415 <C> Italian Reduction <WITH> Different Gender <HAS> – <C> German Original <WITH> Different Gender <HAS> 0.415 <C> German Debiased <WITH> Different Gender <HAS> 0.435 <C> German English <WITH> Different Gender <HAS> 0.403 <C> German Reduction <WITH> Different Gender <HAS> – <C> <R> <C> Italian Original <WITH> difference <HAS> 0.057 <C> Italian Debiased <WITH> difference <HAS> 0.013 <C> Italian English <WITH> difference <HAS> 0.009 <C> Italian Reduction <WITH> difference <HAS> [BOLD] 91.67% <C> German Original <WITH> difference <HAS> 0.076 <C> German Debiased <WITH> difference <HAS> 0.043 <C> German English <WITH> difference <HAS> 0.043 <C> German Reduction <WITH> difference <HAS> [BOLD] 100% <C> <CAP> Table 4: Averages of similarities of pairs with same vs. different gender in Italian and German compared to English. The last row is the difference between the averages of the two sets. “Reduction” stands for gap reduction when removing gender signals from the context.
 <R> <C> Italian Same-gender <WITH> 7–10 <HAS> Og: 4884 <C> Italian Diff-Gender <WITH> 7–10 <HAS> Og: 12947 <C> Italian difference <WITH> 7–10 <HAS> Og: 8063 <C> German Same-gender <WITH> 7–10 <HAS> Og: 5925 <C> German Diff-Gender <WITH> 7–10 <HAS> Og: 33604 <C> German difference <WITH> 7–10 <HAS> Og: 27679 <C> <R> <C> Italian Same-gender <WITH> 7–10 <HAS> Db: 5523 <C> Italian Diff-Gender <WITH> 7–10 <HAS> Db: 7312 <C> Italian difference <WITH> 7–10 <HAS> Db: 1789 <C> German Same-gender <WITH> 7–10 <HAS> Db: 7653 <C> German Diff-Gender <WITH> 7–10 <HAS> Db: 26071 <C> German difference <WITH> 7–10 <HAS> Db: 18418 <C> <R> <C> Italian Same-gender <WITH> 7–10 <HAS> En: 6978 <C> Italian Diff-Gender <WITH> 7–10 <HAS> En: 2467 <C> Italian difference <WITH> 7–10 <HAS> En: -4511 <C> German Same-gender <WITH> 7–10 <HAS> En: 4517 <C> German Diff-Gender <WITH> 7–10 <HAS> En: 8666 <C> German difference <WITH> 7–10 <HAS> En: 4149 <C> <R> <C> Italian Same-gender <WITH> 4–7 <HAS> Og: 10954 <C> Italian Diff-Gender <WITH> 4–7 <HAS> Og: 15838 <C> Italian difference <WITH> 4–7 <HAS> Og: 4884 <C> German Same-gender <WITH> 4–7 <HAS> Og: 19271 <C> German Diff-Gender <WITH> 4–7 <HAS> Og: 27256 <C> German difference <WITH> 4–7 <HAS> Og: 7985 <C> <R> <C> Italian Same-gender <WITH> 4–7 <HAS> Db: 12037 <C> Italian Diff-Gender <WITH> 4–7 <HAS> Db: 12564 <C> Italian difference <WITH> 4–7 <HAS> Db: 527 <C> German Same-gender <WITH> 4–7 <HAS> Db: 24845 <C> German Diff-Gender <WITH> 4–7 <HAS> Db: 22970 <C> German difference <WITH> 4–7 <HAS> Db: -1875 <C> <R> <C> Italian Same-gender <WITH> 4–7 <HAS> En: 15891 <C> Italian Diff-Gender <WITH> 4–7 <HAS> En: 17782 <C> Italian difference <WITH> 4–7 <HAS> En: 1891 <C> German Same-gender <WITH> 4–7 <HAS> En: 13282 <C> German Diff-Gender <WITH> 4–7 <HAS> En: 17649 <C> German difference <WITH> 4–7 <HAS> En: 4367 <C> <R> <C> Italian Same-gender <WITH> 0–4 <HAS> Og: 23314 <C> Italian Diff-Gender <WITH> 0–4 <HAS> Og: 35783 <C> Italian difference <WITH> 0–4 <HAS> Og: 12469 <C> German Same-gender <WITH> 0–4 <HAS> Og: 50983 <C> German Diff-Gender <WITH> 0–4 <HAS> Og: 85263 <C> German difference <WITH> 0–4 <HAS> Og: 34280 <C> <R> <C> Italian Same-gender <WITH> 0–4 <HAS> Db: 26386 <C> Italian Diff-Gender <WITH> 0–4 <HAS> Db: 28067 <C> Italian difference <WITH> 0–4 <HAS> Db: 1681 <C> German Same-gender <WITH> 0–4 <HAS> Db: 60603 <C> German Diff-Gender <WITH> 0–4 <HAS> Db: 79081 <C> German difference <WITH> 0–4 <HAS> Db: 18478 <C> <R> <C> Italian Same-gender <WITH> 0–4 <HAS> En: 57278 <C> Italian Diff-Gender <WITH> 0–4 <HAS> En: 53053 <C> Italian difference <WITH> 0–4 <HAS> En: -4225 <C> German Same-gender <WITH> 0–4 <HAS> En: 41509 <C> German Diff-Gender <WITH> 0–4 <HAS> En: 62929 <C> German difference <WITH> 0–4 <HAS> En: 21420 <C> <CAP> Table 2: Averages of rankings of the words in same-gender pairs vs. different-gender pairs for Italian and German, along with their differences. Og stands for the original embeddings, Db for the debiased embeddings, and En for English. Each row presents the averages of pairs with the respective scores in SimLex-999 (0–4, 4–7, 7–10).
 <R> <C> Italian Orig <WITH> SimLex <HAS> 0.280 <C> Italian Debias <WITH> SimLex <HAS> [BOLD] 0.288 <C> German Orig <WITH> SimLex <HAS> 0.343 <C> German Debias <WITH> SimLex <HAS> [BOLD] 0.356 <C> <R> <C> Italian Orig <WITH> WordSim <HAS> 0.548 <C> Italian Debias <WITH> WordSim <HAS> [BOLD] 0.577 <C> German Orig <WITH> WordSim <HAS> 0.547 <C> German Debias <WITH> WordSim <HAS> [BOLD] 0.553 <C> <CAP> Table 6: Results on SimLex-999 and WordSim-353, in Italian and German, before and after debiasing.
 <R> <C> Italian → En <WITH> Orig <HAS> 58.73 <C> Italian En → <WITH> Orig <HAS> 59.68 <C> German → En <WITH> Orig <HAS> 47.58 <C> German En → <WITH> Orig <HAS> 50.48 <C> <R> <C> Italian → En <WITH> Debias <HAS> [BOLD] 60.03 <C> Italian En → <WITH> Debias <HAS> [BOLD] 60.96 <C> German → En <WITH> Debias <HAS> [BOLD] 47.89 <C> German En → <WITH> Debias <HAS> [BOLD] 51.76 <C> <CAP> Table 7: Cross-lingual embedding alignment in Italian and in German, before and after debiasing.
 <R> <C> Size <WITH> Affirmative Action <HAS> 81 <C> TF-IDF ARI <WITH> Affirmative Action <HAS> -0.07 <C> WMD ARI <WITH> Affirmative Action <HAS> -0.02 <C> Sent2vec ARI <WITH> Affirmative Action <HAS> 0.03 <C> Doc2vec ARI <WITH> Affirmative Action <HAS> -0.01 <C> BERT ARI <WITH> Affirmative Action <HAS> -0.02 <C> [ITALIC] OD-w2v ARI <WITH> Affirmative Action <HAS> [BOLD] 0.14 <C> [ITALIC] OD-d2v ARI <WITH> Affirmative Action <HAS> [ITALIC] 0.02 <C> TF-IDF  [ITALIC] Sil. <WITH> Affirmative Action <HAS> 0.01 <C> WMD  [ITALIC] Sil. <WITH> Affirmative Action <HAS> 0.01 <C> Sent2vec  [ITALIC] Sil. <WITH> Affirmative Action <HAS> -0.01 <C> Doc2vec  [ITALIC] Sil. <WITH> Affirmative Action <HAS> -0.02 <C> BERT  [ITALIC] Sil. <WITH> Affirmative Action <HAS> -0.04 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Affirmative Action <HAS> [BOLD] 0.06 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Affirmative Action <HAS> [ITALIC] 0.01 <C> <R> <C> Size <WITH> Atheism <HAS> 116 <C> TF-IDF ARI <WITH> Atheism <HAS> [BOLD] 0.19 <C> WMD ARI <WITH> Atheism <HAS> 0.07 <C> Sent2vec ARI <WITH> Atheism <HAS> 0.00 <C> Doc2vec ARI <WITH> Atheism <HAS> 0.03 <C> BERT ARI <WITH> Atheism <HAS> -0.01 <C> [ITALIC] OD-w2v ARI <WITH> Atheism <HAS> 0.11 <C> [ITALIC] OD-d2v ARI <WITH> Atheism <HAS> [ITALIC] 0.16 <C> TF-IDF  [ITALIC] Sil. <WITH> Atheism <HAS> 0.02 <C> WMD  [ITALIC] Sil. <WITH> Atheism <HAS> 0.01 <C> Sent2vec  [ITALIC] Sil. <WITH> Atheism <HAS> 0.02 <C> Doc2vec  [ITALIC] Sil. <WITH> Atheism <HAS> 0.01 <C> BERT  [ITALIC] Sil. <WITH> Atheism <HAS> 0.01 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Atheism <HAS> [ITALIC] 0.05 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Atheism <HAS> [BOLD] 0.07 <C> <R> <C> Size <WITH> Austerity Measures <HAS> 20 <C> TF-IDF ARI <WITH> Austerity Measures <HAS> [ITALIC] 0.04 <C> WMD ARI <WITH> Austerity Measures <HAS> [ITALIC] 0.04 <C> Sent2vec ARI <WITH> Austerity Measures <HAS> -0.01 <C> Doc2vec ARI <WITH> Austerity Measures <HAS> -0.05 <C> BERT ARI <WITH> Austerity Measures <HAS> 0.04 <C> [ITALIC] OD-w2v ARI <WITH> Austerity Measures <HAS> [BOLD] 0.21 <C> [ITALIC] OD-d2v ARI <WITH> Austerity Measures <HAS> -0.01 <C> TF-IDF  [ITALIC] Sil. <WITH> Austerity Measures <HAS> 0.06 <C> WMD  [ITALIC] Sil. <WITH> Austerity Measures <HAS> 0.07 <C> Sent2vec  [ITALIC] Sil. <WITH> Austerity Measures <HAS> 0.05 <C> Doc2vec  [ITALIC] Sil. <WITH> Austerity Measures <HAS> -0.03 <C> BERT  [ITALIC] Sil. <WITH> Austerity Measures <HAS> 0.10 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Austerity Measures <HAS> [BOLD] 0.19 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Austerity Measures <HAS> 0.1 <C> <R> <C> Size <WITH> Democratization <HAS> 76 <C> TF-IDF ARI <WITH> Democratization <HAS> 0.02 <C> WMD ARI <WITH> Democratization <HAS> -0.01 <C> Sent2vec ARI <WITH> Democratization <HAS> 0.00 <C> Doc2vec ARI <WITH> Democratization <HAS> [ITALIC] 0.09 <C> BERT ARI <WITH> Democratization <HAS> -0.01 <C> [ITALIC] OD-w2v ARI <WITH> Democratization <HAS> [BOLD] 0.11 <C> [ITALIC] OD-d2v ARI <WITH> Democratization <HAS> 0.07 <C> TF-IDF  [ITALIC] Sil. <WITH> Democratization <HAS> 0.01 <C> WMD  [ITALIC] Sil. <WITH> Democratization <HAS> 0.01 <C> Sent2vec  [ITALIC] Sil. <WITH> Democratization <HAS> 0.02 <C> Doc2vec  [ITALIC] Sil. <WITH> Democratization <HAS> 0.02 <C> BERT  [ITALIC] Sil. <WITH> Democratization <HAS> 0.03 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Democratization <HAS> [BOLD] 0.16 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Democratization <HAS> [ITALIC] 0.11 <C> <R> <C> Size <WITH> Education Voucher Scheme <HAS> 30 <C> TF-IDF ARI <WITH> Education Voucher Scheme <HAS> [BOLD] 0.25 <C> WMD ARI <WITH> Education Voucher Scheme <HAS> 0.12 <C> Sent2vec ARI <WITH> Education Voucher Scheme <HAS> 0.08 <C> Doc2vec ARI <WITH> Education Voucher Scheme <HAS> -0.02 <C> BERT ARI <WITH> Education Voucher Scheme <HAS> 0.04 <C> [ITALIC] OD-w2v ARI <WITH> Education Voucher Scheme <HAS> 0.13 <C> [ITALIC] OD-d2v ARI <WITH> Education Voucher Scheme <HAS> [ITALIC] 0.19 <C> TF-IDF  [ITALIC] Sil. <WITH> Education Voucher Scheme <HAS> 0.01 <C> WMD  [ITALIC] Sil. <WITH> Education Voucher Scheme <HAS> 0.01 <C> Sent2vec  [ITALIC] Sil. <WITH> Education Voucher Scheme <HAS> 0.01 <C> Doc2vec  [ITALIC] Sil. <WITH> Education Voucher Scheme <HAS> -0.01 <C> BERT  [ITALIC] Sil. <WITH> Education Voucher Scheme <HAS> 0.02 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Education Voucher Scheme <HAS> [ITALIC] 0.38 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Education Voucher Scheme <HAS> [BOLD] 0.40 <C> <R> <C> Size <WITH> Gambling <HAS> 60 <C> TF-IDF ARI <WITH> Gambling <HAS> -0.06 <C> WMD ARI <WITH> Gambling <HAS> -0.01 <C> Sent2vec ARI <WITH> Gambling <HAS> -0.02 <C> Doc2vec ARI <WITH> Gambling <HAS> 0.04 <C> BERT ARI <WITH> Gambling <HAS> 0.09 <C> [ITALIC] OD-w2v ARI <WITH> Gambling <HAS> [ITALIC] 0.35 <C> [ITALIC] OD-d2v ARI <WITH> Gambling <HAS> [BOLD] 0.39 <C> TF-IDF  [ITALIC] Sil. <WITH> Gambling <HAS> 0.01 <C> WMD  [ITALIC] Sil. <WITH> Gambling <HAS> 0.02 <C> Sent2vec  [ITALIC] Sil. <WITH> Gambling <HAS> 0.03 <C> Doc2vec  [ITALIC] Sil. <WITH> Gambling <HAS> 0.01 <C> BERT  [ITALIC] Sil. <WITH> Gambling <HAS> 0.09 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Gambling <HAS> [BOLD] 0.30 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Gambling <HAS> [ITALIC] 0.22 <C> <R> <C> Size <WITH> Housing <HAS> 30 <C> TF-IDF ARI <WITH> Housing <HAS> 0.01 <C> WMD ARI <WITH> Housing <HAS> -0.01 <C> Sent2vec ARI <WITH> Housing <HAS> -0.01 <C> Doc2vec ARI <WITH> Housing <HAS> -0.02 <C> BERT ARI <WITH> Housing <HAS> 0.08 <C> [ITALIC] OD-w2v ARI <WITH> Housing <HAS> [BOLD] 0.27 <C> [ITALIC] OD-d2v ARI <WITH> Housing <HAS> 0.01 <C> TF-IDF  [ITALIC] Sil. <WITH> Housing <HAS> 0.02 <C> WMD  [ITALIC] Sil. <WITH> Housing <HAS> 0.03 <C> Sent2vec  [ITALIC] Sil. <WITH> Housing <HAS> 0.03 <C> Doc2vec  [ITALIC] Sil. <WITH> Housing <HAS> 0.01 <C> BERT  [ITALIC] Sil. <WITH> Housing <HAS> 0.11 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Housing <HAS> [BOLD] 0.13 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Housing <HAS> [ITALIC] 0.13 <C> <R> <C> Size <WITH> Hydroelectric Dams <HAS> 110 <C> TF-IDF ARI <WITH> Hydroelectric Dams <HAS> [BOLD] 0.47 <C> WMD ARI <WITH> Hydroelectric Dams <HAS> [ITALIC] 0.45 <C> Sent2vec ARI <WITH> Hydroelectric Dams <HAS> [ITALIC] 0.45 <C> Doc2vec ARI <WITH> Hydroelectric Dams <HAS> -0.01 <C> BERT ARI <WITH> Hydroelectric Dams <HAS> 0.38 <C> [ITALIC] OD-w2v ARI <WITH> Hydroelectric Dams <HAS> 0.35 <C> [ITALIC] OD-d2v ARI <WITH> Hydroelectric Dams <HAS> 0.14 <C> TF-IDF  [ITALIC] Sil. <WITH> Hydroelectric Dams <HAS> 0.04 <C> WMD  [ITALIC] Sil. <WITH> Hydroelectric Dams <HAS> 0.08 <C> Sent2vec  [ITALIC] Sil. <WITH> Hydroelectric Dams <HAS> 0.12 <C> Doc2vec  [ITALIC] Sil. <WITH> Hydroelectric Dams <HAS> 0.01 <C> BERT  [ITALIC] Sil. <WITH> Hydroelectric Dams <HAS> 0.19 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Hydroelectric Dams <HAS> [BOLD] 0.26 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Hydroelectric Dams <HAS> [ITALIC] 0.09 <C> <R> <C> Size <WITH> Intellectual Property <HAS> 66 <C> TF-IDF ARI <WITH> Intellectual Property <HAS> 0.01 <C> WMD ARI <WITH> Intellectual Property <HAS> 0.01 <C> Sent2vec ARI <WITH> Intellectual Property <HAS> 0.00 <C> Doc2vec ARI <WITH> Intellectual Property <HAS> 0.03 <C> BERT ARI <WITH> Intellectual Property <HAS> 0.03 <C> [ITALIC] OD-w2v ARI <WITH> Intellectual Property <HAS> [ITALIC] 0.05 <C> [ITALIC] OD-d2v ARI <WITH> Intellectual Property <HAS> [BOLD] 0.14 <C> TF-IDF  [ITALIC] Sil. <WITH> Intellectual Property <HAS> 0.01 <C> WMD  [ITALIC] Sil. <WITH> Intellectual Property <HAS> [ITALIC] 0.04 <C> Sent2vec  [ITALIC] Sil. <WITH> Intellectual Property <HAS> 0.03 <C> Doc2vec  [ITALIC] Sil. <WITH> Intellectual Property <HAS> 0.01 <C> BERT  [ITALIC] Sil. <WITH> Intellectual Property <HAS> 0.03 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Intellectual Property <HAS> [ITALIC] 0.04 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Intellectual Property <HAS> [BOLD] 0.12 <C> <R> <C> Size <WITH> Keystone pipeline <HAS> 18 <C> TF-IDF ARI <WITH> Keystone pipeline <HAS> 0.01 <C> WMD ARI <WITH> Keystone pipeline <HAS> 0.01 <C> Sent2vec ARI <WITH> Keystone pipeline <HAS> 0.00 <C> Doc2vec ARI <WITH> Keystone pipeline <HAS> -0.13 <C> BERT ARI <WITH> Keystone pipeline <HAS> [BOLD] 0.07 <C> [ITALIC] OD-w2v ARI <WITH> Keystone pipeline <HAS> -0.01 <C> [ITALIC] OD-d2v ARI <WITH> Keystone pipeline <HAS> [BOLD] 0.07 <C> TF-IDF  [ITALIC] Sil. <WITH> Keystone pipeline <HAS> -0.01 <C> WMD  [ITALIC] Sil. <WITH> Keystone pipeline <HAS> -0.03 <C> Sent2vec  [ITALIC] Sil. <WITH> Keystone pipeline <HAS> -0.03 <C> Doc2vec  [ITALIC] Sil. <WITH> Keystone pipeline <HAS> -0.07 <C> BERT  [ITALIC] Sil. <WITH> Keystone pipeline <HAS> 0.03 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Keystone pipeline <HAS> [BOLD] 0.05 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Keystone pipeline <HAS> [ITALIC] 0.02 <C> <R> <C> Size <WITH> Monarchy <HAS> 61 <C> TF-IDF ARI <WITH> Monarchy <HAS> -0.04 <C> WMD ARI <WITH> Monarchy <HAS> 0.01 <C> Sent2vec ARI <WITH> Monarchy <HAS> 0.00 <C> Doc2vec ARI <WITH> Monarchy <HAS> 0.03 <C> BERT ARI <WITH> Monarchy <HAS> -0.02 <C> [ITALIC] OD-w2v ARI <WITH> Monarchy <HAS> [BOLD] 0.15 <C> [ITALIC] OD-d2v ARI <WITH> Monarchy <HAS> [BOLD] 0.15 <C> TF-IDF  [ITALIC] Sil. <WITH> Monarchy <HAS> 0.01 <C> WMD  [ITALIC] Sil. <WITH> Monarchy <HAS> 0.02 <C> Sent2vec  [ITALIC] Sil. <WITH> Monarchy <HAS> 0.02 <C> Doc2vec  [ITALIC] Sil. <WITH> Monarchy <HAS> 0.01 <C> BERT  [ITALIC] Sil. <WITH> Monarchy <HAS> 0.01 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Monarchy <HAS> [BOLD] 0.11 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Monarchy <HAS> [ITALIC] 0.09 <C> <R> <C> Size <WITH> National Service <HAS> 33 <C> TF-IDF ARI <WITH> National Service <HAS> 0.14 <C> WMD ARI <WITH> National Service <HAS> -0.03 <C> Sent2vec ARI <WITH> National Service <HAS> -0.01 <C> Doc2vec ARI <WITH> National Service <HAS> 0.02 <C> BERT ARI <WITH> National Service <HAS> 0.01 <C> [ITALIC] OD-w2v ARI <WITH> National Service <HAS> [ITALIC] 0.31 <C> [ITALIC] OD-d2v ARI <WITH> National Service <HAS> [BOLD] 0.39 <C> TF-IDF  [ITALIC] Sil. <WITH> National Service <HAS> 0.02 <C> WMD  [ITALIC] Sil. <WITH> National Service <HAS> 0.04 <C> Sent2vec  [ITALIC] Sil. <WITH> National Service <HAS> 0.02 <C> Doc2vec  [ITALIC] Sil. <WITH> National Service <HAS> 0.01 <C> BERT  [ITALIC] Sil. <WITH> National Service <HAS> 0.02 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> National Service <HAS> [BOLD] 0.25 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> National Service <HAS> [BOLD] 0.25 <C> <R> <C> Size <WITH> One-child policy China <HAS> 67 <C> TF-IDF ARI <WITH> One-child policy China <HAS> -0.05 <C> WMD ARI <WITH> One-child policy China <HAS> 0.01 <C> Sent2vec ARI <WITH> One-child policy China <HAS> [BOLD] 0.11 <C> Doc2vec ARI <WITH> One-child policy China <HAS> -0.02 <C> BERT ARI <WITH> One-child policy China <HAS> 0.02 <C> [ITALIC] OD-w2v ARI <WITH> One-child policy China <HAS> [BOLD] 0.11 <C> [ITALIC] OD-d2v ARI <WITH> One-child policy China <HAS> 0.01 <C> TF-IDF  [ITALIC] Sil. <WITH> One-child policy China <HAS> 0.01 <C> WMD  [ITALIC] Sil. <WITH> One-child policy China <HAS> 0.02 <C> Sent2vec  [ITALIC] Sil. <WITH> One-child policy China <HAS> [ITALIC] 0.04 <C> Doc2vec  [ITALIC] Sil. <WITH> One-child policy China <HAS> -0.01 <C> BERT  [ITALIC] Sil. <WITH> One-child policy China <HAS> 0.03 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> One-child policy China <HAS> [BOLD] 0.07 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> One-child policy China <HAS> -0.02 <C> <R> <C> Size <WITH> Open-source Software <HAS> 48 <C> TF-IDF ARI <WITH> Open-source Software <HAS> -0.02 <C> WMD ARI <WITH> Open-source Software <HAS> -0.01 <C> Sent2vec ARI <WITH> Open-source Software <HAS> [ITALIC] 0.05 <C> Doc2vec ARI <WITH> Open-source Software <HAS> 0.01 <C> BERT ARI <WITH> Open-source Software <HAS> 0.12 <C> [ITALIC] OD-w2v ARI <WITH> Open-source Software <HAS> [BOLD] 0.09 <C> [ITALIC] OD-d2v ARI <WITH> Open-source Software <HAS> -0.02 <C> TF-IDF  [ITALIC] Sil. <WITH> Open-source Software <HAS> 0.01 <C> WMD  [ITALIC] Sil. <WITH> Open-source Software <HAS> -0.01 <C> Sent2vec  [ITALIC] Sil. <WITH> Open-source Software <HAS> 0.00 <C> Doc2vec  [ITALIC] Sil. <WITH> Open-source Software <HAS> -0.02 <C> BERT  [ITALIC] Sil. <WITH> Open-source Software <HAS> 0.03 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Open-source Software <HAS> [BOLD] 0.18 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Open-source Software <HAS> 0.01 <C> <R> <C> Size <WITH> Pornography <HAS> 52 <C> TF-IDF ARI <WITH> Pornography <HAS> -0.02 <C> WMD ARI <WITH> Pornography <HAS> 0.01 <C> Sent2vec ARI <WITH> Pornography <HAS> 0.01 <C> Doc2vec ARI <WITH> Pornography <HAS> -0.02 <C> BERT ARI <WITH> Pornography <HAS> -0.01 <C> [ITALIC] OD-w2v ARI <WITH> Pornography <HAS> [BOLD] 0.41 <C> [ITALIC] OD-d2v ARI <WITH> Pornography <HAS> [BOLD] 0.41 <C> TF-IDF  [ITALIC] Sil. <WITH> Pornography <HAS> 0.01 <C> WMD  [ITALIC] Sil. <WITH> Pornography <HAS> 0.01 <C> Sent2vec  [ITALIC] Sil. <WITH> Pornography <HAS> 0.02 <C> Doc2vec  [ITALIC] Sil. <WITH> Pornography <HAS> -0.01 <C> BERT  [ITALIC] Sil. <WITH> Pornography <HAS> 0.03 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Pornography <HAS> [BOLD] 0.47 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Pornography <HAS> [ITALIC] 0.41 <C> <R> <C> Size <WITH> Seanad Abolition <HAS> 25 <C> TF-IDF ARI <WITH> Seanad Abolition <HAS> 0.23 <C> WMD ARI <WITH> Seanad Abolition <HAS> 0.09 <C> Sent2vec ARI <WITH> Seanad Abolition <HAS> -0.01 <C> Doc2vec ARI <WITH> Seanad Abolition <HAS> -0.01 <C> BERT ARI <WITH> Seanad Abolition <HAS> 0.03 <C> [ITALIC] OD-w2v ARI <WITH> Seanad Abolition <HAS> [ITALIC] 0.32 <C> [ITALIC] OD-d2v ARI <WITH> Seanad Abolition <HAS> [BOLD] 0.54 <C> TF-IDF  [ITALIC] Sil. <WITH> Seanad Abolition <HAS> 0.02 <C> WMD  [ITALIC] Sil. <WITH> Seanad Abolition <HAS> 0.01 <C> Sent2vec  [ITALIC] Sil. <WITH> Seanad Abolition <HAS> -0.01 <C> Doc2vec  [ITALIC] Sil. <WITH> Seanad Abolition <HAS> -0.03 <C> BERT  [ITALIC] Sil. <WITH> Seanad Abolition <HAS> -0.04 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Seanad Abolition <HAS> [ITALIC] 0.15 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Seanad Abolition <HAS> [BOLD] 0.31 <C> <R> <C> Size <WITH> Trades Unions <HAS> 19 <C> TF-IDF ARI <WITH> Trades Unions <HAS> [ITALIC] 0.44 <C> WMD ARI <WITH> Trades Unions <HAS> [ITALIC] 0.44 <C> Sent2vec ARI <WITH> Trades Unions <HAS> [BOLD] 0.60 <C> Doc2vec ARI <WITH> Trades Unions <HAS> -0.05 <C> BERT ARI <WITH> Trades Unions <HAS> 0.44 <C> [ITALIC] OD-w2v ARI <WITH> Trades Unions <HAS> [ITALIC] 0.44 <C> [ITALIC] OD-d2v ARI <WITH> Trades Unions <HAS> 0.29 <C> TF-IDF  [ITALIC] Sil. <WITH> Trades Unions <HAS> 0.1 <C> WMD  [ITALIC] Sil. <WITH> Trades Unions <HAS> 0.17 <C> Sent2vec  [ITALIC] Sil. <WITH> Trades Unions <HAS> 0.21 <C> Doc2vec  [ITALIC] Sil. <WITH> Trades Unions <HAS> 0.01 <C> BERT  [ITALIC] Sil. <WITH> Trades Unions <HAS> 0.26 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Trades Unions <HAS> [BOLD] 0.48 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Trades Unions <HAS> [ITALIC] 0.32 <C> <R> <C> Size <WITH> Video Games <HAS> 72 <C> TF-IDF ARI <WITH> Video Games <HAS> -0.01 <C> WMD ARI <WITH> Video Games <HAS> 0.01 <C> Sent2vec ARI <WITH> Video Games <HAS> 0.12 <C> Doc2vec ARI <WITH> Video Games <HAS> 0.01 <C> BERT ARI <WITH> Video Games <HAS> 0.08 <C> [ITALIC] OD-w2v ARI <WITH> Video Games <HAS> [ITALIC] 0.40 <C> [ITALIC] OD-d2v ARI <WITH> Video Games <HAS> [BOLD] 0.56 <C> TF-IDF  [ITALIC] Sil. <WITH> Video Games <HAS> 0.01 <C> WMD  [ITALIC] Sil. <WITH> Video Games <HAS> 0.01 <C> Sent2vec  [ITALIC] Sil. <WITH> Video Games <HAS> 0.06 <C> Doc2vec  [ITALIC] Sil. <WITH> Video Games <HAS> 0.01 <C> BERT  [ITALIC] Sil. <WITH> Video Games <HAS> 0.05 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Video Games <HAS> [ITALIC] 0.32 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Video Games <HAS> [BOLD] 0.42 <C> <R> <C> Size <WITH> Average <HAS> 54.67 <C> TF-IDF ARI <WITH> Average <HAS> 0.09 <C> WMD ARI <WITH> Average <HAS> 0.07 <C> Sent2vec ARI <WITH> Average <HAS> 0.08 <C> Doc2vec ARI <WITH> Average <HAS> 0.01 <C> BERT ARI <WITH> Average <HAS> 0.08 <C> [ITALIC] OD-w2v ARI <WITH> Average <HAS> [BOLD] 0.22 <C> [ITALIC] OD-d2v ARI <WITH> Average <HAS> [ITALIC] 0.20 <C> TF-IDF  [ITALIC] Sil. <WITH> Average <HAS> 0.02 <C> WMD  [ITALIC] Sil. <WITH> Average <HAS> 0.03 <C> Sent2vec  [ITALIC] Sil. <WITH> Average <HAS> 0.04 <C> Doc2vec  [ITALIC] Sil. <WITH> Average <HAS> -0.01 <C> BERT  [ITALIC] Sil. <WITH> Average <HAS> 0.05 <C> [ITALIC] OD-w2v  [ITALIC] Sil. <WITH> Average <HAS> [BOLD] 0.20 <C> [ITALIC] OD-d2v  [ITALIC] Sil. <WITH> Average <HAS> [ITALIC] 0.17 <C> <CAP> Table 6: Performance comparison of the distance measures on all 18 datasets. The semantic distance in opinion distance (OD) measure is computed via cosine distance over either Word2vec (OD-w2v with semantic distance threshold 0.6) or Doc2vec (OD-d2v with distance threshold 0.3) embeddings. Sil. refers to Silhouette Coefficient. The second best result is italicized and underlined. The ARI and Silhouette coefficients scores of both OD methods (OD-d2v and OD-w2v) are statistically significant (paired t-test) with respect to baselines at significance level 0.005.
 <R> <C> Seanad Abolition ARI <WITH> TF-IDF <HAS> 0.23 <C> Seanad Abolition  [ITALIC] Sil <WITH> TF-IDF <HAS> 0.02 <C> Video Games ARI <WITH> TF-IDF <HAS> -0.01 <C> Video Games  [ITALIC] Sil <WITH> TF-IDF <HAS> 0.01 <C> Pornography ARI <WITH> TF-IDF <HAS> -0.02 <C> Pornography  [ITALIC] Sil <WITH> TF-IDF <HAS> 0.01 <C> <R> <C> Seanad Abolition ARI <WITH> WMD <HAS> 0.09 <C> Seanad Abolition  [ITALIC] Sil <WITH> WMD <HAS> 0.01 <C> Video Games ARI <WITH> WMD <HAS> 0.01 <C> Video Games  [ITALIC] Sil <WITH> WMD <HAS> 0.01 <C> Pornography ARI <WITH> WMD <HAS> -0.02 <C> Pornography  [ITALIC] Sil <WITH> WMD <HAS> 0.01 <C> <R> <C> Seanad Abolition ARI <WITH> Sent2vec <HAS> -0.01 <C> Seanad Abolition  [ITALIC] Sil <WITH> Sent2vec <HAS> -0.01 <C> Video Games ARI <WITH> Sent2vec <HAS> 0.11 <C> Video Games  [ITALIC] Sil <WITH> Sent2vec <HAS> 0.06 <C> Pornography ARI <WITH> Sent2vec <HAS> 0.01 <C> Pornography  [ITALIC] Sil <WITH> Sent2vec <HAS> 0.02 <C> <R> <C> Seanad Abolition ARI <WITH> Doc2vec <HAS> -0.01 <C> Seanad Abolition  [ITALIC] Sil <WITH> Doc2vec <HAS> -0.03 <C> Video Games ARI <WITH> Doc2vec <HAS> -0.01 <C> Video Games  [ITALIC] Sil <WITH> Doc2vec <HAS> 0.01 <C> Pornography ARI <WITH> Doc2vec <HAS> 0.02 <C> Pornography  [ITALIC] Sil <WITH> Doc2vec <HAS> -0.01 <C> <R> <C> Seanad Abolition ARI <WITH> BERT <HAS> 0.03 <C> Seanad Abolition  [ITALIC] Sil <WITH> BERT <HAS> -0.04 <C> Video Games ARI <WITH> BERT <HAS> 0.08 <C> Video Games  [ITALIC] Sil <WITH> BERT <HAS> 0.05 <C> Pornography ARI <WITH> BERT <HAS> -0.01 <C> Pornography  [ITALIC] Sil <WITH> BERT <HAS> 0.03 <C> <R> <C> Seanad Abolition ARI <WITH> OD-parse <HAS> 0.01 <C> Seanad Abolition  [ITALIC] Sil <WITH> OD-parse <HAS> -0.04 <C> Video Games ARI <WITH> OD-parse <HAS> -0.01 <C> Video Games  [ITALIC] Sil <WITH> OD-parse <HAS> 0.02 <C> Pornography ARI <WITH> OD-parse <HAS> 0.07 <C> Pornography  [ITALIC] Sil <WITH> OD-parse <HAS> 0.05 <C> <R> <C> Seanad Abolition ARI <WITH> OD <HAS> [BOLD] 0.54 <C> Seanad Abolition  [ITALIC] Sil <WITH> OD <HAS> [BOLD] 0.31 <C> Video Games ARI <WITH> OD <HAS> [BOLD] 0.56 <C> Video Games  [ITALIC] Sil <WITH> OD <HAS> [BOLD] 0.42 <C> Pornography ARI <WITH> OD <HAS> [BOLD] 0.41 <C> Pornography  [ITALIC] Sil <WITH> OD <HAS> [BOLD] 0.41 <C> <CAP> Table 3: ARI and Silhouette coefficient scores.
 <R> <C> Seanad Abolition <WITH> Unigrams <HAS> 0.54 <C> Video Games <WITH> Unigrams <HAS> 0.66 <C> Pornography <WITH> Unigrams <HAS> 0.63 <C> <R> <C> Seanad Abolition <WITH> Bigrams <HAS> 0.54 <C> Video Games <WITH> Bigrams <HAS> 0.64 <C> Pornography <WITH> Bigrams <HAS> 0.56 <C> <R> <C> Seanad Abolition <WITH> LSA <HAS> 0.68 <C> Video Games <WITH> LSA <HAS> 0.57 <C> Pornography <WITH> LSA <HAS> 0.57 <C> <R> <C> Seanad Abolition <WITH> Sentiment <HAS> 0.35 <C> Video Games <WITH> Sentiment <HAS> 0.60 <C> Pornography <WITH> Sentiment <HAS> 0.69 <C> <R> <C> Seanad Abolition <WITH> Bigrams <HAS> [EMPTY] <C> Video Games <WITH> Bigrams <HAS> [EMPTY] <C> Pornography <WITH> Bigrams <HAS> [EMPTY] <C> <R> <C> Seanad Abolition <WITH> + Sentiment <HAS> 0.43 <C> Video Games <WITH> + Sentiment <HAS> 0.58 <C> Pornography <WITH> + Sentiment <HAS> 0.66 <C> <R> <C> Seanad Abolition <WITH> TF-IDF <HAS> 0.50 <C> Video Games <WITH> TF-IDF <HAS> 0.65 <C> Pornography <WITH> TF-IDF <HAS> 0.57 <C> <R> <C> Seanad Abolition <WITH> WMD <HAS> 0.40 <C> Video Games <WITH> WMD <HAS> 0.73 <C> Pornography <WITH> WMD <HAS> 0.57 <C> <R> <C> Seanad Abolition <WITH> Sent2vec <HAS> 0.39 <C> Video Games <WITH> Sent2vec <HAS> 0.79 <C> Pornography <WITH> Sent2vec <HAS> 0.70 <C> <R> <C> Seanad Abolition <WITH> Doc2vec <HAS> 0.27 <C> Video Games <WITH> Doc2vec <HAS> 0.51 <C> Pornography <WITH> Doc2vec <HAS> 0.56 <C> <R> <C> Seanad Abolition <WITH> BERT <HAS> 0.46 <C> Video Games <WITH> BERT <HAS> 0.84 <C> Pornography <WITH> BERT <HAS> 0.68 <C> <R> <C> Seanad Abolition <WITH> Unigrams <HAS> [EMPTY] <C> Video Games <WITH> Unigrams <HAS> [EMPTY] <C> Pornography <WITH> Unigrams <HAS> [EMPTY] <C> <R> <C> Seanad Abolition <WITH> + Bigrams <HAS> 0.40 <C> Video Games <WITH> + Bigrams <HAS> 0.64 <C> Pornography <WITH> + Bigrams <HAS> 0.78 <C> <R> <C> Seanad Abolition <WITH> + Sentiment <HAS> 0.24 <C> Video Games <WITH> + Sentiment <HAS> 0.54 <C> Pornography <WITH> + Sentiment <HAS> 0.54 <C> <R> <C> Seanad Abolition <WITH> + LSA <HAS> 0.73 <C> Video Games <WITH> + LSA <HAS> 0.51 <C> Pornography <WITH> + LSA <HAS> 0.58 <C> <R> <C> Seanad Abolition <WITH> + TF-IDF <HAS> 0.42 <C> Video Games <WITH> + TF-IDF <HAS> 0.65 <C> Pornography <WITH> + TF-IDF <HAS> 0.56 <C> <R> <C> Seanad Abolition <WITH> + WMD <HAS> 0.48 <C> Video Games <WITH> + WMD <HAS> 0.73 <C> Pornography <WITH> + WMD <HAS> 0.53 <C> <R> <C> Seanad Abolition <WITH> + Sent2vec <HAS> 0.56 <C> Video Games <WITH> + Sent2vec <HAS> 0.59 <C> Pornography <WITH> + Sent2vec <HAS> 0.66 <C> <R> <C> Seanad Abolition <WITH> + Doc2vec <HAS> 0.31 <C> Video Games <WITH> + Doc2vec <HAS> 0.56 <C> Pornography <WITH> + Doc2vec <HAS> 0.47 <C> <R> <C> Seanad Abolition <WITH> OD-parse <HAS> 0.50 <C> Video Games <WITH> OD-parse <HAS> 0.58 <C> Pornography <WITH> OD-parse <HAS> 0.53 <C> <R> <C> Seanad Abolition <WITH> OD <HAS> 0.71 <C> Video Games <WITH> OD <HAS> [BOLD] 0.88 <C> Pornography <WITH> OD <HAS> 0.88 <C> <R> <C> Seanad Abolition <WITH> OD <HAS> [EMPTY] <C> Video Games <WITH> OD <HAS> [EMPTY] <C> Pornography <WITH> OD <HAS> [EMPTY] <C> <R> <C> Seanad Abolition <WITH> + Unigrams <HAS> 0.83 <C> Video Games <WITH> + Unigrams <HAS> [ITALIC] 0.86 <C> Pornography <WITH> + Unigrams <HAS> [ITALIC] 0.88 <C> <R> <C> Seanad Abolition <WITH> + Bigrams <HAS> [BOLD] 0.87 <C> Video Games <WITH> + Bigrams <HAS> 0.85 <C> Pornography <WITH> + Bigrams <HAS> [ITALIC] 0.88 <C> <R> <C> Seanad Abolition <WITH> + Sentiment <HAS> 0.64 <C> Video Games <WITH> + Sentiment <HAS> [ITALIC] 0.86 <C> Pornography <WITH> + Sentiment <HAS> 0.86 <C> <R> <C> Seanad Abolition <WITH> + LSA <HAS> [ITALIC] 0.84 <C> Video Games <WITH> + LSA <HAS> 0.82 <C> Pornography <WITH> + LSA <HAS> [BOLD] 0.90 <C> <R> <C> Seanad Abolition <WITH> + WMD <HAS> 0.75 <C> Video Games <WITH> + WMD <HAS> 0.82 <C> Pornography <WITH> + WMD <HAS> 0.86 <C> <CAP> Table 4: The quality of opinion distance when leveraged as a feature for multi-class classification. Each entry in + X feature should be treated independently. The second best result is italicized and underlined.
 <R> <C> Difference Function <WITH> OD-parse <HAS> Absolute <C> Seanad Abolition <WITH> OD-parse <HAS> 0.01 <C> Video Games <WITH> OD-parse <HAS> -0.01 <C> Pornography <WITH> OD-parse <HAS> 0.07 <C> <R> <C> Difference Function <WITH> OD-parse <HAS> JS div. <C> Seanad Abolition <WITH> OD-parse <HAS> 0.01 <C> Video Games <WITH> OD-parse <HAS> -0.01 <C> Pornography <WITH> OD-parse <HAS> -0.01 <C> <R> <C> Difference Function <WITH> OD-parse <HAS> EMD <C> Seanad Abolition <WITH> OD-parse <HAS> 0.07 <C> Video Games <WITH> OD-parse <HAS> 0.01 <C> Pornography <WITH> OD-parse <HAS> -0.01 <C> <R> <C> Difference Function <WITH> OD <HAS> Absolute <C> Seanad Abolition <WITH> OD <HAS> [BOLD] 0.54 <C> Video Games <WITH> OD <HAS> [BOLD] 0.56 <C> Pornography <WITH> OD <HAS> [BOLD] 0.41 <C> <R> <C> Difference Function <WITH> OD <HAS> JS div. <C> Seanad Abolition <WITH> OD <HAS> 0.07 <C> Video Games <WITH> OD <HAS> -0.01 <C> Pornography <WITH> OD <HAS> -0.02 <C> <R> <C> Difference Function <WITH> OD <HAS> EMD <C> Seanad Abolition <WITH> OD <HAS> 0.26 <C> Video Games <WITH> OD <HAS> -0.01 <C> Pornography <WITH> OD <HAS> 0.01 <C> <R> <C> Difference Function <WITH> OD (no polarity shifters) <HAS> Absolute <C> Seanad Abolition <WITH> OD (no polarity shifters) <HAS> 0.23 <C> Video Games <WITH> OD (no polarity shifters) <HAS> 0.08 <C> Pornography <WITH> OD (no polarity shifters) <HAS> 0.04 <C> <R> <C> Difference Function <WITH> OD (no polarity shifters) <HAS> JS div. <C> Seanad Abolition <WITH> OD (no polarity shifters) <HAS> 0.09 <C> Video Games <WITH> OD (no polarity shifters) <HAS> -0.01 <C> Pornography <WITH> OD (no polarity shifters) <HAS> -0.02 <C> <R> <C> Difference Function <WITH> OD (no polarity shifters) <HAS> EMD <C> Seanad Abolition <WITH> OD (no polarity shifters) <HAS> 0.10 <C> Video Games <WITH> OD (no polarity shifters) <HAS> 0.01 <C> Pornography <WITH> OD (no polarity shifters) <HAS> -0.01 <C> <CAP> Table 5: We compare the quality of variants of Opinion Distance measures on opinion clustering task with ARI.
 <R> <C> [BOLD] Accuracy <WITH> Development <HAS> 0.782 <C> [BOLD] Macro F <WITH> Development <HAS> 0.561 <C> [BOLD] S <WITH> Development <HAS> 0.621 <C> [BOLD] D <WITH> Development <HAS> 0.000 <C> [BOLD] Q <WITH> Development <HAS> 0.762 <C> [BOLD] C <WITH> Development <HAS> 0.860 <C> <R> <C> [BOLD] Accuracy <WITH> Testing <HAS> [BOLD] 0.784 <C> [BOLD] Macro F <WITH> Testing <HAS> 0.434 <C> [BOLD] S <WITH> Testing <HAS> 0.403 <C> [BOLD] D <WITH> Testing <HAS> 0.000 <C> [BOLD] Q <WITH> Testing <HAS> 0.462 <C> [BOLD] C <WITH> Testing <HAS> 0.873 <C> <CAP> Table 3: Results on the development and testing sets. Accuracy and F1 scores: macro-averaged and per class (S: supporting, D: denying, Q: querying, C: commenting).
 <R> <C> [BOLD] C <WITH> [BOLD] Commenting <HAS> 760 <C> [BOLD] D <WITH> [BOLD] Commenting <HAS> 0 <C> [BOLD] Q <WITH> [BOLD] Commenting <HAS> 12 <C> [BOLD] S <WITH> [BOLD] Commenting <HAS> 6 <C> <R> <C> [BOLD] C <WITH> [BOLD] Denying <HAS> 68 <C> [BOLD] D <WITH> [BOLD] Denying <HAS> 0 <C> [BOLD] Q <WITH> [BOLD] Denying <HAS> 1 <C> [BOLD] S <WITH> [BOLD] Denying <HAS> 2 <C> <R> <C> [BOLD] C <WITH> [BOLD] Querying <HAS> 69 <C> [BOLD] D <WITH> [BOLD] Querying <HAS> 0 <C> [BOLD] Q <WITH> [BOLD] Querying <HAS> 36 <C> [BOLD] S <WITH> [BOLD] Querying <HAS> 1 <C> <R> <C> [BOLD] C <WITH> [BOLD] Supporting <HAS> 67 <C> [BOLD] D <WITH> [BOLD] Supporting <HAS> 0 <C> [BOLD] Q <WITH> [BOLD] Supporting <HAS> 1 <C> [BOLD] S <WITH> [BOLD] Supporting <HAS> 26 <C> <CAP> Table 5: Confusion matrix for testing set predictions
 <R> <C> ABSA <WITH> [EMPTY] <HAS> [EMPTY] <C> No. of Tokens and Opinion Targets Train <WITH> [EMPTY] <HAS> Token <C> No. of Tokens and Opinion Targets Train <WITH> [EMPTY] <HAS> B-target <C> No. of Tokens and Opinion Targets Train <WITH> [EMPTY] <HAS> I-target <C> No. of Tokens and Opinion Targets Test <WITH> [EMPTY] <HAS> Token <C> No. of Tokens and Opinion Targets Test <WITH> [EMPTY] <HAS> B-target <C> No. of Tokens and Opinion Targets Test <WITH> [EMPTY] <HAS> I-target <C> <R> <C> ABSA <WITH> en <HAS> 2014 <C> No. of Tokens and Opinion Targets Train <WITH> en <HAS> 47028 <C> No. of Tokens and Opinion Targets Train <WITH> en <HAS> 3687 <C> No. of Tokens and Opinion Targets Train <WITH> en <HAS> 1457 <C> No. of Tokens and Opinion Targets Test <WITH> en <HAS> 12606 <C> No. of Tokens and Opinion Targets Test <WITH> en <HAS> 1134 <C> No. of Tokens and Opinion Targets Test <WITH> en <HAS> 524 <C> <R> <C> ABSA <WITH> en <HAS> 2015 <C> No. of Tokens and Opinion Targets Train <WITH> en <HAS> 18488 <C> No. of Tokens and Opinion Targets Train <WITH> en <HAS> 1199 <C> No. of Tokens and Opinion Targets Train <WITH> en <HAS> 538 <C> No. of Tokens and Opinion Targets Test <WITH> en <HAS> 10412 <C> No. of Tokens and Opinion Targets Test <WITH> en <HAS> 542 <C> No. of Tokens and Opinion Targets Test <WITH> en <HAS> 264 <C> <R> <C> ABSA <WITH> en <HAS> 2016 <C> No. of Tokens and Opinion Targets Train <WITH> en <HAS> 28900 <C> No. of Tokens and Opinion Targets Train <WITH> en <HAS> 1743 <C> No. of Tokens and Opinion Targets Train <WITH> en <HAS> 797 <C> No. of Tokens and Opinion Targets Test <WITH> en <HAS> 9952 <C> No. of Tokens and Opinion Targets Test <WITH> en <HAS> 612 <C> No. of Tokens and Opinion Targets Test <WITH> en <HAS> 274 <C> <R> <C> ABSA <WITH> es <HAS> 2016 <C> No. of Tokens and Opinion Targets Train <WITH> es <HAS> 35847 <C> No. of Tokens and Opinion Targets Train <WITH> es <HAS> 1858 <C> No. of Tokens and Opinion Targets Train <WITH> es <HAS> 742 <C> No. of Tokens and Opinion Targets Test <WITH> es <HAS> 13179 <C> No. of Tokens and Opinion Targets Test <WITH> es <HAS> 713 <C> No. of Tokens and Opinion Targets Test <WITH> es <HAS> 173 <C> <R> <C> ABSA <WITH> fr <HAS> 2016 <C> No. of Tokens and Opinion Targets Train <WITH> fr <HAS> 26777 <C> No. of Tokens and Opinion Targets Train <WITH> fr <HAS> 1641 <C> No. of Tokens and Opinion Targets Train <WITH> fr <HAS> 443 <C> No. of Tokens and Opinion Targets Test <WITH> fr <HAS> 11646 <C> No. of Tokens and Opinion Targets Test <WITH> fr <HAS> 650 <C> No. of Tokens and Opinion Targets Test <WITH> fr <HAS> 239 <C> <R> <C> ABSA <WITH> nl <HAS> 2016 <C> No. of Tokens and Opinion Targets Train <WITH> nl <HAS> 24788 <C> No. of Tokens and Opinion Targets Train <WITH> nl <HAS> 1231 <C> No. of Tokens and Opinion Targets Train <WITH> nl <HAS> 331 <C> No. of Tokens and Opinion Targets Test <WITH> nl <HAS> 7606 <C> No. of Tokens and Opinion Targets Test <WITH> nl <HAS> 373 <C> No. of Tokens and Opinion Targets Test <WITH> nl <HAS> 81 <C> <R> <C> ABSA <WITH> ru <HAS> 2016 <C> No. of Tokens and Opinion Targets Train <WITH> ru <HAS> 51509 <C> No. of Tokens and Opinion Targets Train <WITH> ru <HAS> 3078 <C> No. of Tokens and Opinion Targets Train <WITH> ru <HAS> 953 <C> No. of Tokens and Opinion Targets Test <WITH> ru <HAS> 16999 <C> No. of Tokens and Opinion Targets Test <WITH> ru <HAS> 952 <C> No. of Tokens and Opinion Targets Test <WITH> ru <HAS> 372 <C> <R> <C> ABSA <WITH> tr <HAS> 2016 <C> No. of Tokens and Opinion Targets Train <WITH> tr <HAS> 12406 <C> No. of Tokens and Opinion Targets Train <WITH> tr <HAS> 1374 <C> No. of Tokens and Opinion Targets Train <WITH> tr <HAS> 516 <C> No. of Tokens and Opinion Targets Test <WITH> tr <HAS> 1316 <C> No. of Tokens and Opinion Targets Test <WITH> tr <HAS> 145 <C> No. of Tokens and Opinion Targets Test <WITH> tr <HAS> 61 <C> <CAP> Table 1: ABSA SemEval 2014-2016 datasets for the restaurant domain. B-target indicates the number of opinion targets in each set; I-target refers to the number of multiword targets.
 <R> <C> 2014 P <WITH> Local (L) <HAS> 81.84 <C> 2014 R <WITH> Local (L) <HAS> 74.69 <C> 2014 F1 <WITH> Local (L) <HAS> 78.10 <C> 2015 P <WITH> Local (L) <HAS> [BOLD] 76.82 <C> 2015 R <WITH> Local (L) <HAS> 54.43 <C> 2015 F1 <WITH> Local (L) <HAS> 63.71 <C> 2016 P <WITH> Local (L) <HAS> 74.41 <C> 2016 R <WITH> Local (L) <HAS> 61.76 <C> 2016 F1 <WITH> Local (L) <HAS> 67.50 <C> <R> <C> 2014 P <WITH> L + BY <HAS> 77.84 <C> 2014 R <WITH> L + BY <HAS> 84.57 <C> 2014 F1 <WITH> L + BY <HAS> 81.07 <C> 2015 P <WITH> L + BY <HAS> 71.73 <C> 2015 R <WITH> L + BY <HAS> 63.65 <C> 2015 F1 <WITH> L + BY <HAS> 67.45 <C> 2016 P <WITH> L + BY <HAS> [BOLD] 74.49 <C> 2016 R <WITH> L + BY <HAS> 71.08 <C> 2016 F1 <WITH> L + BY <HAS> 72.74 <C> <R> <C> 2014 P <WITH> L + CYF100-CYR200 <HAS> [BOLD] 82.91 <C> 2014 R <WITH> L + CYF100-CYR200 <HAS> 84.30 <C> 2014 F1 <WITH> L + CYF100-CYR200 <HAS> 83.60 <C> 2015 P <WITH> L + CYF100-CYR200 <HAS> 73.25 <C> 2015 R <WITH> L + CYF100-CYR200 <HAS> 61.62 <C> 2015 F1 <WITH> L + CYF100-CYR200 <HAS> 66.93 <C> 2016 P <WITH> L + CYF100-CYR200 <HAS> 74.12 <C> 2016 R <WITH> L + CYF100-CYR200 <HAS> 72.06 <C> 2016 F1 <WITH> L + CYF100-CYR200 <HAS> 73.07 <C> <R> <C> 2014 P <WITH> L + W2VW400 <HAS> 76.82 <C> 2014 R <WITH> L + W2VW400 <HAS> 82.10 <C> 2014 F1 <WITH> L + W2VW400 <HAS> 79.37 <C> 2015 P <WITH> L + W2VW400 <HAS> 74.42 <C> 2015 R <WITH> L + W2VW400 <HAS> 59.04 <C> 2015 F1 <WITH> L + W2VW400 <HAS> 65.84 <C> 2016 P <WITH> L + W2VW400 <HAS> 73.04 <C> 2016 R <WITH> L + W2VW400 <HAS> 65.52 <C> 2016 F1 <WITH> L + W2VW400 <HAS> 69.08 <C> <R> <C> 2014 P <WITH> L +  [BOLD] ALL <HAS> 81.15 <C> 2014 R <WITH> L +  [BOLD] ALL <HAS> [BOLD] 87.30 <C> 2014 F1 <WITH> L +  [BOLD] ALL <HAS> [BOLD] 84.11 <C> 2015 P <WITH> L +  [BOLD] ALL <HAS> 72.90 <C> 2015 R <WITH> L +  [BOLD] ALL <HAS> [BOLD] 69.00 <C> 2015 F1 <WITH> L +  [BOLD] ALL <HAS> [BOLD] 70.90 <C> 2016 P <WITH> L +  [BOLD] ALL <HAS> 73.33 <C> 2016 R <WITH> L +  [BOLD] ALL <HAS> [BOLD] 73.69 <C> 2016 F1 <WITH> L +  [BOLD] ALL <HAS> [BOLD] 73.51 <C> <CAP> Table 3: ABSA SemEval 2014-2016 English results. BY: Brown Yelp 1000 classes; CYF100-CYR200: Clark Yelp Food 100 classes and Clark Yelp Reviews 200 classes; W2VW400: Word2vec Wikipedia 400 classes; ALL: BY+CYF100-CYR200+W2VW400.
 <R> <C> System <WITH> es <HAS> GTI <C> F1 <WITH> es <HAS> 68.51 <C> <R> <C> System <WITH> es <HAS> L +  [BOLD] CW600 + W2VW300 <C> F1 <WITH> es <HAS> [BOLD] 69.92 <C> <R> <C> System <WITH> es <HAS> Baseline <C> F1 <WITH> es <HAS> 51.91 <C> <R> <C> System <WITH> fr <HAS> IIT-T <C> F1 <WITH> fr <HAS> 66.67 <C> <R> <C> System <WITH> fr <HAS> L +  [BOLD] CW100 <C> F1 <WITH> fr <HAS> [BOLD] 69.50 <C> <R> <C> System <WITH> fr <HAS> Baseline <C> F1 <WITH> fr <HAS> 45.45 <C> <R> <C> System <WITH> nl <HAS> IIT-T <C> F1 <WITH> nl <HAS> 56.99 <C> <R> <C> System <WITH> nl <HAS> L +  [BOLD] W2VW400 <C> F1 <WITH> nl <HAS> [BOLD] 66.39 <C> <R> <C> System <WITH> nl <HAS> Baseline <C> F1 <WITH> nl <HAS> 50.64 <C> <R> <C> System <WITH> ru <HAS> Danii. <C> F1 <WITH> ru <HAS> 33.47 <C> <R> <C> System <WITH> ru <HAS> L +  [BOLD] CW500 <C> F1 <WITH> ru <HAS> [BOLD] 65.53 <C> <R> <C> System <WITH> ru <HAS> Baseline <C> F1 <WITH> ru <HAS> 49.31 <C> <R> <C> System <WITH> tr <HAS> L +  [BOLD] BW <C> F1 <WITH> tr <HAS> [BOLD] 60.22 <C> <R> <C> System <WITH> tr <HAS> Baseline <C> F1 <WITH> tr <HAS> 41.86 <C> <CAP> Table 6: ABSA SemEval 2016: Comparison of multilingual results in terms of F1 scores.
 <R> <C> 2014 en <WITH> FP <HAS> [BOLD] 230 <C> 2015 en <WITH> FP <HAS> 151 <C> 2016 en <WITH> FP <HAS> [BOLD] 189 <C> 2016 es <WITH> FP <HAS> 165 <C> 2016 fr <WITH> FP <HAS> 194 <C> 2016 nl <WITH> FP <HAS> 117 <C> 2016 ru <WITH> FP <HAS> [BOLD] 390 <C> 2016 tr <WITH> FP <HAS> 62 <C> <R> <C> 2014 en <WITH> FN <HAS> 143 <C> 2015 en <WITH> FN <HAS> [BOLD] 169 <C> 2016 en <WITH> FN <HAS> 163 <C> 2016 es <WITH> FN <HAS> [BOLD] 248 <C> 2016 fr <WITH> FN <HAS> [BOLD] 202 <C> 2016 nl <WITH> FN <HAS> [BOLD] 132 <C> 2016 ru <WITH> FN <HAS> 312 <C> 2016 tr <WITH> FN <HAS> [BOLD] 65 <C> <CAP> Table 7: False Positives and Negatives for every ABSA 2014-2016 setting.
 <R> <C> Category no oov words <WITH> [EMPTY] <HAS> with oov words <C> gr_def 60.60% <WITH> [EMPTY] <HAS> 54.90% <C> gr_neg10 62.50% <WITH> [EMPTY] <HAS> 57.00% <C> cc.el.300  [BOLD] 70.90% <WITH> [EMPTY] <HAS> [BOLD] 65.50% <C> wiki.el 37.50% <WITH> [EMPTY] <HAS> 35.00% <C> gr_cbow_def 29.80% <WITH> [EMPTY] <HAS> 27.10% <C> gr_d300_nosub 62.50% <WITH> [EMPTY] <HAS> 56.60% <C> gr_w2v_sg_n5 54.60% <WITH> [EMPTY] <HAS> 49.50% <C> <R> <C> Category no oov words <WITH> Syntactic <HAS> no oov words <C> gr_def 60.60% <WITH> Syntactic <HAS> 67.90% <C> gr_neg10 62.50% <WITH> Syntactic <HAS> 62.90% <C> cc.el.300  [BOLD] 70.90% <WITH> Syntactic <HAS> [BOLD] 69.60% <C> wiki.el 37.50% <WITH> Syntactic <HAS> 50.70% <C> gr_cbow_def 29.80% <WITH> Syntactic <HAS> 63.80% <C> gr_d300_nosub 62.50% <WITH> Syntactic <HAS> 56.50% <C> gr_w2v_sg_n5 54.60% <WITH> Syntactic <HAS> 55.40% <C> <R> <C> Category no oov words <WITH> [EMPTY] <HAS> with oov words <C> gr_def 60.60% <WITH> [EMPTY] <HAS> [BOLD] 55.70% <C> gr_neg10 62.50% <WITH> [EMPTY] <HAS> 51.30% <C> cc.el.300  [BOLD] 70.90% <WITH> [EMPTY] <HAS> 50.20% <C> wiki.el 37.50% <WITH> [EMPTY] <HAS> 33.40% <C> gr_cbow_def 29.80% <WITH> [EMPTY] <HAS> 52.30% <C> gr_d300_nosub 62.50% <WITH> [EMPTY] <HAS> 46.40% <C> gr_w2v_sg_n5 54.60% <WITH> [EMPTY] <HAS> 45.50% <C> <R> <C> Category no oov words <WITH> Overall <HAS> no oov words <C> gr_def 60.60% <WITH> Overall <HAS> 65.19% <C> gr_neg10 62.50% <WITH> Overall <HAS> 62.66% <C> cc.el.300  [BOLD] 70.90% <WITH> Overall <HAS> [BOLD] 70.12% <C> wiki.el 37.50% <WITH> Overall <HAS> 45.01% <C> gr_cbow_def 29.80% <WITH> Overall <HAS> 51.18% <C> gr_d300_nosub 62.50% <WITH> Overall <HAS> 58.73% <C> gr_w2v_sg_n5 54.60% <WITH> Overall <HAS> 55.10% <C> <R> <C> Category no oov words <WITH> [EMPTY] <HAS> with oov words <C> gr_def 60.60% <WITH> [EMPTY] <HAS> 55.46% <C> gr_neg10 62.50% <WITH> [EMPTY] <HAS> 53.30% <C> cc.el.300  [BOLD] 70.90% <WITH> [EMPTY] <HAS> [BOLD] 55.54% <C> wiki.el 37.50% <WITH> [EMPTY] <HAS> 33.94% <C> gr_cbow_def 29.80% <WITH> [EMPTY] <HAS> 43.53% <C> gr_d300_nosub 62.50% <WITH> [EMPTY] <HAS> 49.96% <C> gr_w2v_sg_n5 54.60% <WITH> [EMPTY] <HAS> 46.87% <C> <CAP> Table 8: Summary for 3CosMul and top-1 nearest vectors.
 <R> <C> #pairs <WITH> Semantic: (13650 tuples) <HAS> Semantic: (13650 tuples) <C> #tuples <WITH> Semantic: (13650 tuples) <HAS> Semantic: (13650 tuples) <C> <R> <C> #pairs <WITH> common_capital_country <HAS> 42 <C> #tuples <WITH> common_capital_country <HAS> 1722 <C> <R> <C> #pairs <WITH> all_capital_country <HAS> 78 <C> #tuples <WITH> all_capital_country <HAS> 6006 <C> <R> <C> #pairs <WITH> eu_city_country <HAS> 50 <C> #tuples <WITH> eu_city_country <HAS> 2366 <C> <R> <C> #pairs <WITH> city_in_region <HAS> 40 <C> #tuples <WITH> city_in_region <HAS> 1536 <C> <R> <C> #pairs <WITH> currency_country <HAS> 24 <C> #tuples <WITH> currency_country <HAS> 552 <C> <R> <C> #pairs <WITH> man_woman_family <HAS> 18 <C> #tuples <WITH> man_woman_family <HAS> 306 <C> <R> <C> #pairs <WITH> profession_placeof_work <HAS> 16 <C> #tuples <WITH> profession_placeof_work <HAS> 240 <C> <R> <C> #pairs <WITH> performer_action <HAS> 24 <C> #tuples <WITH> performer_action <HAS> 552 <C> <R> <C> #pairs <WITH> politician_country <HAS> 20 <C> #tuples <WITH> politician_country <HAS> 370 <C> <R> <C> #pairs <WITH> Syntactic: (25524 tuples) <HAS> Syntactic: (25524 tuples) <C> #tuples <WITH> Syntactic: (25524 tuples) <HAS> Syntactic: (25524 tuples) <C> <R> <C> #pairs <WITH> man_woman_job <HAS> 26 <C> #tuples <WITH> man_woman_job <HAS> 650 <C> <R> <C> #pairs <WITH> adjective_adverb <HAS> 28 <C> #tuples <WITH> adjective_adverb <HAS> 756 <C> <R> <C> #pairs <WITH> opposite <HAS> 35 <C> #tuples <WITH> opposite <HAS> 1190 <C> <R> <C> #pairs <WITH> comparative <HAS> 36 <C> #tuples <WITH> comparative <HAS> 1260 <C> <R> <C> #pairs <WITH> superlative <HAS> 25 <C> #tuples <WITH> superlative <HAS> 600 <C> <R> <C> #pairs <WITH> present_participle_active <HAS> 48 <C> #tuples <WITH> present_participle_active <HAS> 2256 <C> <R> <C> #pairs <WITH> present_participle_passive <HAS> 44 <C> #tuples <WITH> present_participle_passive <HAS> 1892 <C> <R> <C> #pairs <WITH> nationality_adjective_man <HAS> 56 <C> #tuples <WITH> nationality_adjective_man <HAS> 3080 <C> <R> <C> #pairs <WITH> nationality_adjective_woman <HAS> 42 <C> #tuples <WITH> nationality_adjective_woman <HAS> 1722 <C> <R> <C> #pairs <WITH> past_tense <HAS> 34 <C> #tuples <WITH> past_tense <HAS> 1122 <C> <R> <C> #pairs <WITH> plural_nouns <HAS> 72 <C> #tuples <WITH> plural_nouns <HAS> 5112 <C> <R> <C> #pairs <WITH> plural_verbs <HAS> 37 <C> #tuples <WITH> plural_verbs <HAS> 1332 <C> <R> <C> #pairs <WITH> adjectives_antonyms <HAS> 50 <C> #tuples <WITH> adjectives_antonyms <HAS> 2450 <C> <R> <C> #pairs <WITH> verbs_antonyms <HAS> 20 <C> #tuples <WITH> verbs_antonyms <HAS> 380 <C> <R> <C> #pairs <WITH> verbs_i_you <HAS> 42 <C> #tuples <WITH> verbs_i_you <HAS> 1722 <C> <CAP> Table 1: The Greek word analogy test set.
 <R> <C> Category no oov words <WITH> [EMPTY] <HAS> with oov words <C> gr_def 58.42% <WITH> [EMPTY] <HAS> 52.97% <C> gr_neg10 59.33% <WITH> [EMPTY] <HAS> 55.33% <C> cc.el.300  [BOLD] 68.80% <WITH> [EMPTY] <HAS> [BOLD] 64.34% <C> wiki.el 27.20% <WITH> [EMPTY] <HAS> 25.73% <C> gr_cbow_def 31.76% <WITH> [EMPTY] <HAS> 28.80% <C> gr_d300_nosub 60.79% <WITH> [EMPTY] <HAS> 55.11% <C> gr_w2v_sg_n5 52.70% <WITH> [EMPTY] <HAS> 47.82% <C> <R> <C> Category no oov words <WITH> Syntactic <HAS> no oov words <C> gr_def 58.42% <WITH> Syntactic <HAS> 65.73% <C> gr_neg10 59.33% <WITH> Syntactic <HAS> 61.02% <C> cc.el.300  [BOLD] 68.80% <WITH> Syntactic <HAS> [BOLD] 69.35% <C> wiki.el 27.20% <WITH> Syntactic <HAS> 40.90% <C> gr_cbow_def 31.76% <WITH> Syntactic <HAS> 64.02% <C> gr_d300_nosub 60.79% <WITH> Syntactic <HAS> 53.69% <C> gr_w2v_sg_n5 52.70% <WITH> Syntactic <HAS> 52.60% <C> <R> <C> Category no oov words <WITH> [EMPTY] <HAS> with oov words <C> gr_def 58.42% <WITH> [EMPTY] <HAS> [BOLD] 53.95% <C> gr_neg10 59.33% <WITH> [EMPTY] <HAS> 48.69% <C> cc.el.300  [BOLD] 68.80% <WITH> [EMPTY] <HAS> 49.43% <C> wiki.el 27.20% <WITH> [EMPTY] <HAS> 28.42% <C> gr_cbow_def 31.76% <WITH> [EMPTY] <HAS> 52.54% <C> gr_d300_nosub 60.79% <WITH> [EMPTY] <HAS> 44.06% <C> gr_w2v_sg_n5 52.70% <WITH> [EMPTY] <HAS> 43.13% <C> <R> <C> Category no oov words <WITH> Overall <HAS> no oov words <C> gr_def 58.42% <WITH> Overall <HAS> 63.02% <C> gr_neg10 59.33% <WITH> Overall <HAS> 59.96% <C> cc.el.300  [BOLD] 68.80% <WITH> Overall <HAS> [BOLD] 68.97% <C> wiki.el 27.20% <WITH> Overall <HAS> 36.45% <C> gr_cbow_def 31.76% <WITH> Overall <HAS> 52.04% <C> gr_d300_nosub 60.79% <WITH> Overall <HAS> 56.30% <C> gr_w2v_sg_n5 52.70% <WITH> Overall <HAS> 52.66% <C> <R> <C> Category no oov words <WITH> [EMPTY] <HAS> with oov words <C> gr_def 58.42% <WITH> [EMPTY] <HAS> 53.60% <C> gr_neg10 59.33% <WITH> [EMPTY] <HAS> 51.00% <C> cc.el.300  [BOLD] 68.80% <WITH> [EMPTY] <HAS> [BOLD] 54.60% <C> wiki.el 27.20% <WITH> [EMPTY] <HAS> 27.50% <C> gr_cbow_def 31.76% <WITH> [EMPTY] <HAS> 44.30% <C> gr_d300_nosub 60.79% <WITH> [EMPTY] <HAS> 47.90% <C> gr_w2v_sg_n5 52.70% <WITH> [EMPTY] <HAS> 44.80% <C> <CAP> Table 3: Summary for 3CosAdd and top-1 nearest vectors.
 <R> <C> Category no oov words <WITH> [EMPTY] <HAS> with oov words <C> gr_def 83.72% <WITH> [EMPTY] <HAS> 75.90% <C> gr_neg10 84.38% <WITH> [EMPTY] <HAS> 76.50% <C> cc.el.300  [BOLD] 88.50% <WITH> [EMPTY] <HAS> [BOLD] 81.70% <C> wiki.el 65.85% <WITH> [EMPTY] <HAS> 61.40% <C> gr_cbow_def 52.05% <WITH> [EMPTY] <HAS> 47.20% <C> gr_d300_nosub 83.26% <WITH> [EMPTY] <HAS> 75.50% <C> gr_w2v_sg_n5 80.00% <WITH> [EMPTY] <HAS> 72.50% <C> <R> <C> Category no oov words <WITH> Syntactic <HAS> no oov words <C> gr_def 83.72% <WITH> Syntactic <HAS> 83.86% <C> gr_neg10 84.38% <WITH> Syntactic <HAS> 80.42% <C> cc.el.300  [BOLD] 88.50% <WITH> Syntactic <HAS> [BOLD] 85.07% <C> wiki.el 65.85% <WITH> Syntactic <HAS> 72.56% <C> gr_cbow_def 52.05% <WITH> Syntactic <HAS> 76.22% <C> gr_d300_nosub 83.26% <WITH> Syntactic <HAS> 75.97% <C> gr_w2v_sg_n5 80.00% <WITH> Syntactic <HAS> 74.55% <C> <R> <C> Category no oov words <WITH> [EMPTY] <HAS> with oov words <C> gr_def 83.72% <WITH> [EMPTY] <HAS> [BOLD] 68.80% <C> gr_neg10 84.38% <WITH> [EMPTY] <HAS> 66.00% <C> cc.el.300  [BOLD] 88.50% <WITH> [EMPTY] <HAS> 61.40% <C> wiki.el 65.85% <WITH> [EMPTY] <HAS> 47.80% <C> gr_cbow_def 52.05% <WITH> [EMPTY] <HAS> 62.60% <C> gr_d300_nosub 83.26% <WITH> [EMPTY] <HAS> 62.30% <C> gr_w2v_sg_n5 80.00% <WITH> [EMPTY] <HAS> 61.20% <C> <R> <C> Category no oov words <WITH> Overall <HAS> no oov words <C> gr_def 83.72% <WITH> Overall <HAS> 83.80% <C> gr_neg10 84.38% <WITH> Overall <HAS> 81.90% <C> cc.el.300  [BOLD] 88.50% <WITH> Overall <HAS> [BOLD] 86.50% <C> wiki.el 65.85% <WITH> Overall <HAS> 69.70% <C> gr_cbow_def 52.05% <WITH> Overall <HAS> 67.20% <C> gr_d300_nosub 83.26% <WITH> Overall <HAS> 78.70% <C> gr_w2v_sg_n5 80.00% <WITH> Overall <HAS> 76.60% <C> <R> <C> Category no oov words <WITH> [EMPTY] <HAS> with oov words <C> gr_def 83.72% <WITH> [EMPTY] <HAS> [BOLD] 71.29% <C> gr_neg10 84.38% <WITH> [EMPTY] <HAS> 69.66% <C> cc.el.300  [BOLD] 88.50% <WITH> [EMPTY] <HAS> 68.48% <C> wiki.el 65.85% <WITH> [EMPTY] <HAS> 52.53% <C> gr_cbow_def 52.05% <WITH> [EMPTY] <HAS> 57.20% <C> gr_d300_nosub 83.26% <WITH> [EMPTY] <HAS> 66.93% <C> gr_w2v_sg_n5 80.00% <WITH> [EMPTY] <HAS> 65.14% <C> <CAP> Table 7: Summary for 3CosMul and top-5 nearest vectors.
 <R> <C> Pearson <WITH> gr_def <HAS> [BOLD] 0.6042 <C> p-value <WITH> gr_def <HAS> 3.1E-35 <C> Pairs (unknown) <WITH> gr_def <HAS> 2.3% <C> <R> <C> Pearson <WITH> gr_neg10 <HAS> 0.5973 <C> p-value <WITH> gr_neg10 <HAS> 2.9E-34 <C> Pairs (unknown) <WITH> gr_neg10 <HAS> 2.3% <C> <R> <C> Pearson <WITH> cc.el.300 <HAS> 0.5311 <C> p-value <WITH> cc.el.300 <HAS> 1.7E-25 <C> Pairs (unknown) <WITH> cc.el.300 <HAS> 4.9% <C> <R> <C> Pearson <WITH> wiki.el <HAS> 0.5812 <C> p-value <WITH> wiki.el <HAS> 2.2E-31 <C> Pairs (unknown) <WITH> wiki.el <HAS> 4.5% <C> <R> <C> Pearson <WITH> gr_cbow_def <HAS> 0.5232 <C> p-value <WITH> gr_cbow_def <HAS> 2.7E-25 <C> Pairs (unknown) <WITH> gr_cbow_def <HAS> 2.3% <C> <R> <C> Pearson <WITH> gr_d300_nosub <HAS> 0.5889 <C> p-value <WITH> gr_d300_nosub <HAS> 3.8E-33 <C> Pairs (unknown) <WITH> gr_d300_nosub <HAS> 2.3% <C> <R> <C> Pearson <WITH> gr_w2v_sg_n5 <HAS> 0.5879 <C> p-value <WITH> gr_w2v_sg_n5 <HAS> 4.4E-33 <C> Pairs (unknown) <WITH> gr_w2v_sg_n5 <HAS> 2.3% <C> <CAP> Table 4: Word similarity.
 <R> <C> [EMPTY] <WITH> [EMPTY] <HAS> [EMPTY] <C> in-domain CoNLL <WITH> [EMPTY] <HAS> pt (Bible) <C> in-domain LEA <WITH> [EMPTY] <HAS> pt (Bible) <C> out-of-domain CoNLL <WITH> [EMPTY] <HAS> pt (Bible) <C> out-of-domain LEA <WITH> [EMPTY] <HAS> pt (Bible) <C> <R> <C> [EMPTY] <WITH> deep-coref <HAS> ranking <C> in-domain CoNLL <WITH> deep-coref <HAS> 75.61 <C> in-domain LEA <WITH> deep-coref <HAS> 71.00 <C> out-of-domain CoNLL <WITH> deep-coref <HAS> 66.06 <C> out-of-domain LEA <WITH> deep-coref <HAS> 57.58 <C> <R> <C> [EMPTY] <WITH> deep-coref <HAS> +EPM <C> in-domain CoNLL <WITH> deep-coref <HAS> 76.08 <C> in-domain LEA <WITH> deep-coref <HAS> 71.13 <C> out-of-domain CoNLL <WITH> deep-coref <HAS> <bold>68.14</bold> <C> out-of-domain LEA <WITH> deep-coref <HAS> <bold>60.74</bold> <C> <R> <C> [EMPTY] <WITH> e2e-coref <HAS> single <C> in-domain CoNLL <WITH> e2e-coref <HAS> 77.80 <C> in-domain LEA <WITH> e2e-coref <HAS> 73.73 <C> out-of-domain CoNLL <WITH> e2e-coref <HAS> 65.22 <C> out-of-domain LEA <WITH> e2e-coref <HAS> 58.26 <C> <R> <C> [EMPTY] <WITH> e2e-coref <HAS> ensemble <C> in-domain CoNLL <WITH> e2e-coref <HAS> <bold>78.88</bold> <C> in-domain LEA <WITH> e2e-coref <HAS> <bold>74.88</bold> <C> out-of-domain CoNLL <WITH> e2e-coref <HAS> 65.45 <C> out-of-domain LEA <WITH> e2e-coref <HAS> 59.71 <C> <R> <C> [EMPTY] <WITH> [EMPTY] <HAS> [EMPTY] <C> in-domain CoNLL <WITH> [EMPTY] <HAS> wb (weblog) <C> in-domain LEA <WITH> [EMPTY] <HAS> wb (weblog) <C> out-of-domain CoNLL <WITH> [EMPTY] <HAS> wb (weblog) <C> out-of-domain LEA <WITH> [EMPTY] <HAS> wb (weblog) <C> <R> <C> [EMPTY] <WITH> deep-coref <HAS> ranking <C> in-domain CoNLL <WITH> deep-coref <HAS> 61.46 <C> in-domain LEA <WITH> deep-coref <HAS> 53.75 <C> out-of-domain CoNLL <WITH> deep-coref <HAS> 57.17 <C> out-of-domain LEA <WITH> deep-coref <HAS> 48.74 <C> <R> <C> [EMPTY] <WITH> deep-coref <HAS> +EPM <C> in-domain CoNLL <WITH> deep-coref <HAS> 61.97 <C> in-domain LEA <WITH> deep-coref <HAS> 53.93 <C> out-of-domain CoNLL <WITH> deep-coref <HAS> <bold>61.52</bold> <C> out-of-domain LEA <WITH> deep-coref <HAS> <bold>53.78</bold> <C> <R> <C> [EMPTY] <WITH> e2e-coref <HAS> single <C> in-domain CoNLL <WITH> e2e-coref <HAS> 62.02 <C> in-domain LEA <WITH> e2e-coref <HAS> 53.09 <C> out-of-domain CoNLL <WITH> e2e-coref <HAS> 60.69 <C> out-of-domain LEA <WITH> e2e-coref <HAS> 52.69 <C> <R> <C> [EMPTY] <WITH> e2e-coref <HAS> ensemble <C> in-domain CoNLL <WITH> e2e-coref <HAS> <bold>64.76</bold> <C> in-domain LEA <WITH> e2e-coref <HAS> <bold>57.54</bold> <C> out-of-domain CoNLL <WITH> e2e-coref <HAS> 60.99 <C> out-of-domain LEA <WITH> e2e-coref <HAS> 52.99 <C> <R> <C> [EMPTY] <WITH> [EMPTY] <HAS> [EMPTY] <C> in-domain CoNLL <WITH> [EMPTY] <HAS> [EMPTY] <C> in-domain LEA <WITH> [EMPTY] <HAS> [EMPTY] <C> out-of-domain CoNLL <WITH> [EMPTY] <HAS> [EMPTY] <C> out-of-domain LEA <WITH> [EMPTY] <HAS> [EMPTY] <C> <CAP> Table 7: In-domain and out-of-domain evaluations for the pt and wb genres of the CoNLL test set. The highest scores are boldfaced.
 <R> <C> MUC <WITH> +EPM <HAS> 74.92 <C> <italic>B</italic>3 <WITH> +EPM <HAS> 65.03 <C> CEAF<italic>e</italic> <WITH> +EPM <HAS> 60.88 <C> CoNLL <WITH> +EPM <HAS> 66.95 <C> LEA <WITH> +EPM <HAS> 61.34 <C> <R> <C> MUC <WITH> -pairwise <HAS> 74.37 <C> <italic>B</italic>3 <WITH> -pairwise <HAS> 64.55 <C> CEAF<italic>e</italic> <WITH> -pairwise <HAS> 60.46 <C> CoNLL <WITH> -pairwise <HAS> 66.46 <C> LEA <WITH> -pairwise <HAS> 60.71 <C> <R> <C> MUC <WITH> -type <HAS> 74.71 <C> <italic>B</italic>3 <WITH> -type <HAS> 64.87 <C> CEAF<italic>e</italic> <WITH> -type <HAS> 61.00 <C> CoNLL <WITH> -type <HAS> 66.86 <C> LEA <WITH> -type <HAS> 61.07 <C> <R> <C> MUC <WITH> -dep <HAS> 74.57 <C> <italic>B</italic>3 <WITH> -dep <HAS> 64.79 <C> CEAF<italic>e</italic> <WITH> -dep <HAS> 60.65 <C> CoNLL <WITH> -dep <HAS> 66.67 <C> LEA <WITH> -dep <HAS> 61.01 <C> <R> <C> MUC <WITH> -NER <HAS> 74.61 <C> <italic>B</italic>3 <WITH> -NER <HAS> 65.05 <C> CEAF<italic>e</italic> <WITH> -NER <HAS> 60.93 <C> CoNLL <WITH> -NER <HAS> 66.86 <C> LEA <WITH> -NER <HAS> 61.27 <C> <R> <C> MUC <WITH> -POS <HAS> 74.74 <C> <italic>B</italic>3 <WITH> -POS <HAS> 65.04 <C> CEAF<italic>e</italic> <WITH> -POS <HAS> 60.88 <C> CoNLL <WITH> -POS <HAS> 66.89 <C> LEA <WITH> -POS <HAS> 61.30 <C> <R> <C> MUC <WITH> +pairwise <HAS> 74.25 <C> <italic>B</italic>3 <WITH> +pairwise <HAS> 64.33 <C> CEAF<italic>e</italic> <WITH> +pairwise <HAS> 60.02 <C> CoNLL <WITH> +pairwise <HAS> 66.20 <C> LEA <WITH> +pairwise <HAS> 60.57 <C> <CAP> Table 5: Impact of different EPM feature groups on the CoNLL development set.
 <R> <C> [EMPTY] <WITH> deep-coref <HAS> ranking <C> MUC R <WITH> deep-coref <HAS> 57.72 <C> MUC P <WITH> deep-coref <HAS> 69.57 <C> MUC F1 <WITH> deep-coref <HAS> 63.10 <C> <italic>B</italic>3 R <WITH> deep-coref <HAS> 41.42 <C> <italic>B</italic>3 P <WITH> deep-coref <HAS> 58.30 <C> <italic>B</italic>3 F1 <WITH> deep-coref <HAS> 48.43 <C> CEAF<italic>e</italic> R <WITH> deep-coref <HAS> 42.20 <C> CEAF<italic>e</italic> P <WITH> deep-coref <HAS> 53.50 <C> CEAF<italic>e</italic> F1 <WITH> deep-coref <HAS> 47.18 <C> CoNLL <WITH> deep-coref <HAS> 52.90 <C> LEA R <WITH> deep-coref <HAS> 37.57 <C> LEA P <WITH> deep-coref <HAS> 54.27 <C> LEA F1 <WITH> deep-coref <HAS> 44.40 <C> <R> <C> [EMPTY] <WITH> deep-coref <HAS> reinforce <C> MUC R <WITH> deep-coref <HAS> 62.12 <C> MUC P <WITH> deep-coref <HAS> 58.98 <C> MUC F1 <WITH> deep-coref <HAS> 60.51 <C> <italic>B</italic>3 R <WITH> deep-coref <HAS> 46.98 <C> <italic>B</italic>3 P <WITH> deep-coref <HAS> 45.79 <C> <italic>B</italic>3 F1 <WITH> deep-coref <HAS> 46.38 <C> CEAF<italic>e</italic> R <WITH> deep-coref <HAS> 44.28 <C> CEAF<italic>e</italic> P <WITH> deep-coref <HAS> 46.35 <C> CEAF<italic>e</italic> F1 <WITH> deep-coref <HAS> 45.29 <C> CoNLL <WITH> deep-coref <HAS> 50.73 <C> LEA R <WITH> deep-coref <HAS> 42.28 <C> LEA P <WITH> deep-coref <HAS> 41.70 <C> LEA F1 <WITH> deep-coref <HAS> 41.98 <C> <R> <C> [EMPTY] <WITH> deep-coref <HAS> top-pairs <C> MUC R <WITH> deep-coref <HAS> 56.31 <C> MUC P <WITH> deep-coref <HAS> 71.74 <C> MUC F1 <WITH> deep-coref <HAS> 63.09 <C> <italic>B</italic>3 R <WITH> deep-coref <HAS> 39.78 <C> <italic>B</italic>3 P <WITH> deep-coref <HAS> 61.85 <C> <italic>B</italic>3 F1 <WITH> deep-coref <HAS> 48.42 <C> CEAF<italic>e</italic> R <WITH> deep-coref <HAS> 40.80 <C> CEAF<italic>e</italic> P <WITH> deep-coref <HAS> 52.85 <C> CEAF<italic>e</italic> F1 <WITH> deep-coref <HAS> 46.05 <C> CoNLL <WITH> deep-coref <HAS> 52.52 <C> LEA R <WITH> deep-coref <HAS> 35.87 <C> LEA P <WITH> deep-coref <HAS> 57.58 <C> LEA F1 <WITH> deep-coref <HAS> 44.21 <C> <R> <C> [EMPTY] <WITH> deep-coref <HAS> +EPM <C> MUC R <WITH> deep-coref <HAS> 58.23 <C> MUC P <WITH> deep-coref <HAS> 74.05 <C> MUC F1 <WITH> deep-coref <HAS> <bold>65.20</bold> <C> <italic>B</italic>3 R <WITH> deep-coref <HAS> 43.33 <C> <italic>B</italic>3 P <WITH> deep-coref <HAS> 63.90 <C> <italic>B</italic>3 F1 <WITH> deep-coref <HAS> 51.64 <C> CEAF<italic>e</italic> R <WITH> deep-coref <HAS> 43.44 <C> CEAF<italic>e</italic> P <WITH> deep-coref <HAS> 56.33 <C> CEAF<italic>e</italic> F1 <WITH> deep-coref <HAS> <bold>49.05</bold> <C> CoNLL <WITH> deep-coref <HAS> <bold>55.30</bold> <C> LEA R <WITH> deep-coref <HAS> 39.70 <C> LEA P <WITH> deep-coref <HAS> 59.81 <C> LEA F1 <WITH> deep-coref <HAS> <bold>47.72</bold> <C> <R> <C> [EMPTY] <WITH> e2e <HAS> single <C> MUC R <WITH> e2e <HAS> 60.14 <C> MUC P <WITH> e2e <HAS> 64.46 <C> MUC F1 <WITH> e2e <HAS> 62.22 <C> <italic>B</italic>3 R <WITH> e2e <HAS> 45.20 <C> <italic>B</italic>3 P <WITH> e2e <HAS> 51.75 <C> <italic>B</italic>3 F1 <WITH> e2e <HAS> 48.25 <C> CEAF<italic>e</italic> R <WITH> e2e <HAS> 38.18 <C> CEAF<italic>e</italic> P <WITH> e2e <HAS> 43.50 <C> CEAF<italic>e</italic> F1 <WITH> e2e <HAS> 40.67 <C> CoNLL <WITH> e2e <HAS> 50.38 <C> LEA R <WITH> e2e <HAS> 40.70 <C> LEA P <WITH> e2e <HAS> 47.56 <C> LEA F1 <WITH> e2e <HAS> 43.86 <C> <R> <C> [EMPTY] <WITH> e2e <HAS> ensemble <C> MUC R <WITH> e2e <HAS> 59.58 <C> MUC P <WITH> e2e <HAS> 71.60 <C> MUC F1 <WITH> e2e <HAS> 65.04 <C> <italic>B</italic>3 R <WITH> e2e <HAS> 44.64 <C> <italic>B</italic>3 P <WITH> e2e <HAS> 60.91 <C> <italic>B</italic>3 F1 <WITH> e2e <HAS> 51.52 <C> CEAF<italic>e</italic> R <WITH> e2e <HAS> 40.38 <C> CEAF<italic>e</italic> P <WITH> e2e <HAS> 49.17 <C> CEAF<italic>e</italic> F1 <WITH> e2e <HAS> 44.35 <C> CoNLL <WITH> e2e <HAS> 53.63 <C> LEA R <WITH> e2e <HAS> 40.73 <C> LEA P <WITH> e2e <HAS> 56.97 <C> LEA F1 <WITH> e2e <HAS> 47.50 <C> <R> <C> [EMPTY] <WITH> [EMPTY] <HAS> G&L <C> MUC R <WITH> [EMPTY] <HAS> 66.06 <C> MUC P <WITH> [EMPTY] <HAS> 62.93 <C> MUC F1 <WITH> [EMPTY] <HAS> 64.46 <C> <italic>B</italic>3 R <WITH> [EMPTY] <HAS> 57.73 <C> <italic>B</italic>3 P <WITH> [EMPTY] <HAS> 48.58 <C> <italic>B</italic>3 F1 <WITH> [EMPTY] <HAS> <bold>52.76</bold> <C> CEAF<italic>e</italic> R <WITH> [EMPTY] <HAS> 46.76 <C> CEAF<italic>e</italic> P <WITH> [EMPTY] <HAS> 49.54 <C> CEAF<italic>e</italic> F1 <WITH> [EMPTY] <HAS> 48.11 <C> CoNLL <WITH> [EMPTY] <HAS> 55.11 <C> LEA R <WITH> [EMPTY] <HAS> - <C> LEA P <WITH> [EMPTY] <HAS> - <C> LEA F1 <WITH> [EMPTY] <HAS> - <C> <CAP> Table 6: Out-of-domain evaluation on the WikiCoref dataset. The highest F1 scores are boldfaced.
 <R> <C> MUC <WITH> ranking <HAS> 74.31 <C> <italic>B</italic>3 <WITH> ranking <HAS> 64.23 <C> CEAF<italic>e</italic> <WITH> ranking <HAS> 59.73 <C> CoNLL <WITH> ranking <HAS> 66.09 <C> LEA <WITH> ranking <HAS> 60.47 <C> <R> <C> MUC <WITH> +linguistic <HAS> 74.35 <C> <italic>B</italic>3 <WITH> +linguistic <HAS> 63.96 <C> CEAF<italic>e</italic> <WITH> +linguistic <HAS> 60.19 <C> CoNLL <WITH> +linguistic <HAS> 66.17 <C> LEA <WITH> +linguistic <HAS> 60.20 <C> <R> <C> MUC <WITH> top-pairs <HAS> 73.95 <C> <italic>B</italic>3 <WITH> top-pairs <HAS> 63.98 <C> CEAF<italic>e</italic> <WITH> top-pairs <HAS> 59.52 <C> CoNLL <WITH> top-pairs <HAS> 65.82 <C> LEA <WITH> top-pairs <HAS> 60.07 <C> <R> <C> MUC <WITH> +linguistic <HAS> 74.32 <C> <italic>B</italic>3 <WITH> +linguistic <HAS> 64.45 <C> CEAF<italic>e</italic> <WITH> +linguistic <HAS> 60.19 <C> CoNLL <WITH> +linguistic <HAS> 66.32 <C> LEA <WITH> +linguistic <HAS> 60.62 <C> <CAP> Table 1: Impact of linguistic features on deep-coref models on the CoNLL development set.
 <R> <C> MUC <WITH> ranking <HAS> 63.10 <C> <italic>B</italic>3 <WITH> ranking <HAS> 48.43 <C> CEAF<italic>e</italic> <WITH> ranking <HAS> 47.18 <C> CoNLL <WITH> ranking <HAS> 52.90 <C> LEA <WITH> ranking <HAS> 44.40 <C> <R> <C> MUC <WITH> top-pairs <HAS> 63.09 <C> <italic>B</italic>3 <WITH> top-pairs <HAS> 48.42 <C> CEAF<italic>e</italic> <WITH> top-pairs <HAS> 46.05 <C> CoNLL <WITH> top-pairs <HAS> 52.52 <C> LEA <WITH> top-pairs <HAS> 44.21 <C> <R> <C> MUC <WITH> +linguistic <HAS> 63.99 <C> <italic>B</italic>3 <WITH> +linguistic <HAS> 49.63 <C> CEAF<italic>e</italic> <WITH> +linguistic <HAS> 46.60 <C> CoNLL <WITH> +linguistic <HAS> 53.40 <C> LEA <WITH> +linguistic <HAS> 45.66 <C> <CAP> Table 2: Out-of-domain evaluation of deep-coref models on the WikiCoref dataset.
 <R> <C> [EMPTY] <WITH> deep-coref <HAS> ranking <C> MUC R <WITH> deep-coref <HAS> 70.43 <C> MUC P <WITH> deep-coref <HAS> 79.57 <C> MUC F1 <WITH> deep-coref <HAS> 74.72 <C> <italic>B</italic>3 R <WITH> deep-coref <HAS> 58.08 <C> <italic>B</italic>3 P <WITH> deep-coref <HAS> 69.26 <C> <italic>B</italic>3 F1 <WITH> deep-coref <HAS> 63.18 <C> CEAF<italic>e</italic> R <WITH> deep-coref <HAS> 54.43 <C> CEAF<italic>e</italic> P <WITH> deep-coref <HAS> 64.17 <C> CEAF<italic>e</italic> F1 <WITH> deep-coref <HAS> 58.90 <C> CoNLL <WITH> deep-coref <HAS> 65.60 <C> LEA R <WITH> deep-coref <HAS> 54.55 <C> LEA P <WITH> deep-coref <HAS> 65.68 <C> LEA F1 <WITH> deep-coref <HAS> 59.60 <C> <R> <C> [EMPTY] <WITH> deep-coref <HAS> reinforce <C> MUC R <WITH> deep-coref <HAS> 69.84 <C> MUC P <WITH> deep-coref <HAS> 79.79 <C> MUC F1 <WITH> deep-coref <HAS> 74.48 <C> <italic>B</italic>3 R <WITH> deep-coref <HAS> 57.41 <C> <italic>B</italic>3 P <WITH> deep-coref <HAS> 70.96 <C> <italic>B</italic>3 F1 <WITH> deep-coref <HAS> 63.47 <C> CEAF<italic>e</italic> R <WITH> deep-coref <HAS> 55.63 <C> CEAF<italic>e</italic> P <WITH> deep-coref <HAS> 63.83 <C> CEAF<italic>e</italic> F1 <WITH> deep-coref <HAS> 59.45 <C> CoNLL <WITH> deep-coref <HAS> 65.80 <C> LEA R <WITH> deep-coref <HAS> 53.78 <C> LEA P <WITH> deep-coref <HAS> 67.23 <C> LEA F1 <WITH> deep-coref <HAS> 59.76 <C> <R> <C> [EMPTY] <WITH> deep-coref <HAS> top-pairs <C> MUC R <WITH> deep-coref <HAS> 69.41 <C> MUC P <WITH> deep-coref <HAS> 79.90 <C> MUC F1 <WITH> deep-coref <HAS> 74.29 <C> <italic>B</italic>3 R <WITH> deep-coref <HAS> 57.01 <C> <italic>B</italic>3 P <WITH> deep-coref <HAS> 70.80 <C> <italic>B</italic>3 F1 <WITH> deep-coref <HAS> 63.16 <C> CEAF<italic>e</italic> R <WITH> deep-coref <HAS> 54.43 <C> CEAF<italic>e</italic> P <WITH> deep-coref <HAS> 63.74 <C> CEAF<italic>e</italic> F1 <WITH> deep-coref <HAS> 58.72 <C> CoNLL <WITH> deep-coref <HAS> 65.39 <C> LEA R <WITH> deep-coref <HAS> 53.31 <C> LEA P <WITH> deep-coref <HAS> 67.09 <C> LEA F1 <WITH> deep-coref <HAS> 59.41 <C> <R> <C> [EMPTY] <WITH> deep-coref <HAS> +EPM <C> MUC R <WITH> deep-coref <HAS> 71.16 <C> MUC P <WITH> deep-coref <HAS> 79.35 <C> MUC F1 <WITH> deep-coref <HAS> 75.03 <C> <italic>B</italic>3 R <WITH> deep-coref <HAS> 59.28 <C> <italic>B</italic>3 P <WITH> deep-coref <HAS> 69.70 <C> <italic>B</italic>3 F1 <WITH> deep-coref <HAS> 64.07 <C> CEAF<italic>e</italic> R <WITH> deep-coref <HAS> 56.52 <C> CEAF<italic>e</italic> P <WITH> deep-coref <HAS> 64.02 <C> CEAF<italic>e</italic> F1 <WITH> deep-coref <HAS> 60.04 <C> CoNLL <WITH> deep-coref <HAS> 66.38 <C> LEA R <WITH> deep-coref <HAS> 55.63 <C> LEA P <WITH> deep-coref <HAS> 66.11 <C> LEA F1 <WITH> deep-coref <HAS> 60.42 <C> <R> <C> [EMPTY] <WITH> deep-coref <HAS> +JIM <C> MUC R <WITH> deep-coref <HAS> 69.89 <C> MUC P <WITH> deep-coref <HAS> 80.45 <C> MUC F1 <WITH> deep-coref <HAS> 74.80 <C> <italic>B</italic>3 R <WITH> deep-coref <HAS> 57.08 <C> <italic>B</italic>3 P <WITH> deep-coref <HAS> 71.58 <C> <italic>B</italic>3 F1 <WITH> deep-coref <HAS> 63.51 <C> CEAF<italic>e</italic> R <WITH> deep-coref <HAS> 55.36 <C> CEAF<italic>e</italic> P <WITH> deep-coref <HAS> 64.20 <C> CEAF<italic>e</italic> F1 <WITH> deep-coref <HAS> 59.45 <C> CoNLL <WITH> deep-coref <HAS> 65.93 <C> LEA R <WITH> deep-coref <HAS> 53.46 <C> LEA P <WITH> deep-coref <HAS> 67.97 <C> LEA F1 <WITH> deep-coref <HAS> 59.85 <C> <R> <C> [EMPTY] <WITH> e2e <HAS> single <C> MUC R <WITH> e2e <HAS> 74.02 <C> MUC P <WITH> e2e <HAS> 77.82 <C> MUC F1 <WITH> e2e <HAS> 75.88 <C> <italic>B</italic>3 R <WITH> e2e <HAS> 62.58 <C> <italic>B</italic>3 P <WITH> e2e <HAS> 67.45 <C> <italic>B</italic>3 F1 <WITH> e2e <HAS> 64.92 <C> CEAF<italic>e</italic> R <WITH> e2e <HAS> 59.16 <C> CEAF<italic>e</italic> P <WITH> e2e <HAS> 62.96 <C> CEAF<italic>e</italic> F1 <WITH> e2e <HAS> 61.00 <C> CoNLL <WITH> e2e <HAS> 67.27 <C> LEA R <WITH> e2e <HAS> 58.90 <C> LEA P <WITH> e2e <HAS> 63.79 <C> LEA F1 <WITH> e2e <HAS> 61.25 <C> <R> <C> [EMPTY] <WITH> e2e <HAS> ensemble <C> MUC R <WITH> e2e <HAS> 73.73 <C> MUC P <WITH> e2e <HAS> 80.95 <C> MUC F1 <WITH> e2e <HAS> 77.17 <C> <italic>B</italic>3 R <WITH> e2e <HAS> 61.83 <C> <italic>B</italic>3 P <WITH> e2e <HAS> 72.10 <C> <italic>B</italic>3 F1 <WITH> e2e <HAS> 66.57 <C> CEAF<italic>e</italic> R <WITH> e2e <HAS> 60.11 <C> CEAF<italic>e</italic> P <WITH> e2e <HAS> 65.62 <C> CEAF<italic>e</italic> F1 <WITH> e2e <HAS> 62.74 <C> CoNLL <WITH> e2e <HAS> 68.83 <C> LEA R <WITH> e2e <HAS> 58.48 <C> LEA P <WITH> e2e <HAS> 68.81 <C> LEA F1 <WITH> e2e <HAS> 63.23 <C> <CAP> Table 4: Comparisons on the CoNLL test set. The F1 gains that are statistically significant: (1) “+EPM” compared to “top-pairs”, “ranking” and “JIM”, (2) “+EPM” compared to “reinforce” based on MUC, B3 and LEA, (3) “single” compared to “+EPM” based on MUC and B3, and (4) “ensemble” compared to other systems. Significance is measured based on the approximate randomization test (p<0.05) Noreen (1989).
 <R> <C> VN <WITH> type <HAS> 81 <C> WN-V <WITH> type <HAS> 66 <C> WN-N <WITH> type <HAS> 47 <C> <R> <C> VN <WITH> x+POS <HAS> 54 <C> WN-V <WITH> x+POS <HAS> 39 <C> WN-N <WITH> x+POS <HAS> 43 <C> <R> <C> VN <WITH> lemma <HAS> 88 <C> WN-V <WITH> lemma <HAS> 76 <C> WN-N <WITH> lemma <HAS> 53 <C> <R> <C> VN <WITH> x+POS <HAS> 79 <C> WN-V <WITH> x+POS <HAS> 63 <C> WN-N <WITH> x+POS <HAS> 50 <C> <R> <C> VN <WITH> shared <HAS> 54 <C> WN-V <WITH> shared <HAS> 39 <C> WN-N <WITH> shared <HAS> 41 <C> <CAP> Table 4: Lexicon member coverage (%)
 <R> <C> Context: w2 SimLex <WITH> target <HAS> N <C> Context: w2 SimLex <WITH> target <HAS> V <C> Context: w2 SimLex <WITH> target <HAS> A <C> Context: w2 SimLex <WITH> target <HAS> all <C> Context: w2 SimVerb <WITH> target <HAS> V <C> <R> <C> Context: w2 SimLex <WITH> type <HAS> .334 <C> Context: w2 SimLex <WITH> type <HAS> <bold>.336</bold> <C> Context: w2 SimLex <WITH> type <HAS> <bold>.518</bold> <C> Context: w2 SimLex <WITH> type <HAS> .348 <C> Context: w2 SimVerb <WITH> type <HAS> .307 <C> <R> <C> Context: w2 SimLex <WITH> x + POS <HAS> .342 <C> Context: w2 SimLex <WITH> x + POS <HAS> .323 <C> Context: w2 SimLex <WITH> x + POS <HAS> .513 <C> Context: w2 SimLex <WITH> x + POS <HAS> .350 <C> Context: w2 SimVerb <WITH> x + POS <HAS> .279 <C> <R> <C> Context: w2 SimLex <WITH> lemma <HAS> <bold>.362</bold> <C> Context: w2 SimLex <WITH> lemma <HAS> .333 <C> Context: w2 SimLex <WITH> lemma <HAS> .497 <C> Context: w2 SimLex <WITH> lemma <HAS> <bold>.351</bold> <C> Context: w2 SimVerb <WITH> lemma <HAS> .400 <C> <R> <C> Context: w2 SimLex <WITH> x + POS <HAS> .354 <C> Context: w2 SimLex <WITH> x + POS <HAS> <bold>.336</bold> <C> Context: w2 SimLex <WITH> x + POS <HAS> .504 <C> Context: w2 SimLex <WITH> x + POS <HAS> .345 <C> Context: w2 SimVerb <WITH> x + POS <HAS> <bold>.406</bold> <C> <R> <C> Context: w2 SimLex <WITH> * type <HAS> - <C> Context: w2 SimLex <WITH> * type <HAS> - <C> Context: w2 SimLex <WITH> * type <HAS> - <C> Context: w2 SimLex <WITH> * type <HAS> .339 <C> Context: w2 SimVerb <WITH> * type <HAS> .277 <C> <R> <C> Context: w2 SimLex <WITH> * type MFit-A <HAS> - <C> Context: w2 SimLex <WITH> * type MFit-A <HAS> - <C> Context: w2 SimLex <WITH> * type MFit-A <HAS> - <C> Context: w2 SimLex <WITH> * type MFit-A <HAS> .385 <C> Context: w2 SimVerb <WITH> * type MFit-A <HAS> - <C> <R> <C> Context: w2 SimLex <WITH> * type MFit-AR <HAS> - <C> Context: w2 SimLex <WITH> * type MFit-AR <HAS> - <C> Context: w2 SimLex <WITH> * type MFit-AR <HAS> - <C> Context: w2 SimLex <WITH> * type MFit-AR <HAS> .439 <C> Context: w2 SimVerb <WITH> * type MFit-AR <HAS> .381 <C> <R> <C> Context: w2 SimLex <WITH> Context: dep-W <HAS> Context: dep-W <C> Context: w2 SimLex <WITH> Context: dep-W <HAS> Context: dep-W <C> Context: w2 SimLex <WITH> Context: dep-W <HAS> Context: dep-W <C> Context: w2 SimLex <WITH> Context: dep-W <HAS> Context: dep-W <C> Context: w2 SimVerb <WITH> Context: dep-W <HAS> Context: dep-W <C> <R> <C> Context: w2 SimLex <WITH> type <HAS> .366 <C> Context: w2 SimLex <WITH> type <HAS> .365 <C> Context: w2 SimLex <WITH> type <HAS> .489 <C> Context: w2 SimLex <WITH> type <HAS> .362 <C> Context: w2 SimVerb <WITH> type <HAS> .314 <C> <R> <C> Context: w2 SimLex <WITH> x + POS <HAS> .364 <C> Context: w2 SimLex <WITH> x + POS <HAS> .351 <C> Context: w2 SimLex <WITH> x + POS <HAS> .482 <C> Context: w2 SimLex <WITH> x + POS <HAS> .359 <C> Context: w2 SimVerb <WITH> x + POS <HAS> .287 <C> <R> <C> Context: w2 SimLex <WITH> lemma <HAS> <bold>.391</bold> <C> Context: w2 SimLex <WITH> lemma <HAS> .380 <C> Context: w2 SimLex <WITH> lemma <HAS> <bold>.522</bold> <C> Context: w2 SimLex <WITH> lemma <HAS> <bold>.379</bold> <C> Context: w2 SimVerb <WITH> lemma <HAS> .401 <C> <R> <C> Context: w2 SimLex <WITH> x + POS <HAS> .384 <C> Context: w2 SimLex <WITH> x + POS <HAS> <bold>.388</bold> <C> Context: w2 SimLex <WITH> x + POS <HAS> .480 <C> Context: w2 SimLex <WITH> x + POS <HAS> .366 <C> Context: w2 SimVerb <WITH> x + POS <HAS> <bold>.431</bold> <C> <R> <C> Context: w2 SimLex <WITH> * type <HAS> - <C> Context: w2 SimLex <WITH> * type <HAS> - <C> Context: w2 SimLex <WITH> * type <HAS> - <C> Context: w2 SimLex <WITH> * type <HAS> .376 <C> Context: w2 SimVerb <WITH> * type <HAS> .313 <C> <R> <C> Context: w2 SimLex <WITH> * type MFit-AR <HAS> - <C> Context: w2 SimLex <WITH> * type MFit-AR <HAS> - <C> Context: w2 SimLex <WITH> * type MFit-AR <HAS> - <C> Context: w2 SimLex <WITH> * type MFit-AR <HAS> .434 <C> Context: w2 SimVerb <WITH> * type MFit-AR <HAS> .418 <C> <CAP> Table 1: Benchmark performance, Spearman’s ρ. SGNS results with * taken from [morphfit]. Best results per column (benchmark) annotated for our setup only.
 <R> <C> WN-N P <WITH> Context: w2 <HAS> Context: w2 <C> WN-N R <WITH> Context: w2 <HAS> Context: w2 <C> WN-N F <WITH> Context: w2 <HAS> Context: w2 <C> WN-V P <WITH> Context: w2 <HAS> Context: w2 <C> WN-V R <WITH> Context: w2 <HAS> Context: w2 <C> WN-V F <WITH> Context: w2 <HAS> Context: w2 <C> VN P <WITH> Context: w2 <HAS> Context: w2 <C> VN R <WITH> Context: w2 <HAS> Context: w2 <C> VN F <WITH> Context: w2 <HAS> Context: w2 <C> <R> <C> WN-N P <WITH> type <HAS> .700 <C> WN-N R <WITH> type <HAS> .654 <C> WN-N F <WITH> type <HAS> .676 <C> WN-V P <WITH> type <HAS> .535 <C> WN-V R <WITH> type <HAS> .474 <C> WN-V F <WITH> type <HAS> .503 <C> VN P <WITH> type <HAS> .327 <C> VN R <WITH> type <HAS> .309 <C> VN F <WITH> type <HAS> .318 <C> <R> <C> WN-N P <WITH> x+POS <HAS> .699 <C> WN-N R <WITH> x+POS <HAS> .651 <C> WN-N F <WITH> x+POS <HAS> .674 <C> WN-V P <WITH> x+POS <HAS> .544 <C> WN-V R <WITH> x+POS <HAS> .472 <C> WN-V F <WITH> x+POS <HAS> .505 <C> VN P <WITH> x+POS <HAS> .339 <C> VN R <WITH> x+POS <HAS> .312 <C> VN F <WITH> x+POS <HAS> .325 <C> <R> <C> WN-N P <WITH> lemma <HAS> .706 <C> WN-N R <WITH> lemma <HAS> .660 <C> WN-N F <WITH> lemma <HAS> .682 <C> WN-V P <WITH> lemma <HAS> .576 <C> WN-V R <WITH> lemma <HAS> .520 <C> WN-V F <WITH> lemma <HAS> .547 <C> VN P <WITH> lemma <HAS> .384 <C> VN R <WITH> lemma <HAS> .360 <C> VN F <WITH> lemma <HAS> .371 <C> <R> <C> WN-N P <WITH> x+POS <HAS> <bold>.710</bold> <C> WN-N R <WITH> x+POS <HAS> <bold>.662</bold> <C> WN-N F <WITH> x+POS <HAS> <bold>.685</bold> <C> WN-V P <WITH> x+POS <HAS> <bold>.589</bold> <C> WN-V R <WITH> x+POS <HAS> <bold>.529</bold> <C> WN-V F <WITH> x+POS <HAS> <bold>.557</bold> <C> VN P <WITH> x+POS <HAS> <bold>.410</bold> <C> VN R <WITH> x+POS <HAS> <bold>.389</bold> <C> VN F <WITH> x+POS <HAS> <bold>.399</bold> <C> <R> <C> WN-N P <WITH> Context: dep <HAS> Context: dep <C> WN-N R <WITH> Context: dep <HAS> Context: dep <C> WN-N F <WITH> Context: dep <HAS> Context: dep <C> WN-V P <WITH> Context: dep <HAS> Context: dep <C> WN-V R <WITH> Context: dep <HAS> Context: dep <C> WN-V F <WITH> Context: dep <HAS> Context: dep <C> VN P <WITH> Context: dep <HAS> Context: dep <C> VN R <WITH> Context: dep <HAS> Context: dep <C> VN F <WITH> Context: dep <HAS> Context: dep <C> <R> <C> WN-N P <WITH> type <HAS> .712 <C> WN-N R <WITH> type <HAS> .661 <C> WN-N F <WITH> type <HAS> .686 <C> WN-V P <WITH> type <HAS> .545 <C> WN-V R <WITH> type <HAS> .457 <C> WN-V F <WITH> type <HAS> .497 <C> VN P <WITH> type <HAS> .324 <C> VN R <WITH> type <HAS> .296 <C> VN F <WITH> type <HAS> .310 <C> <R> <C> WN-N P <WITH> x+POS <HAS> .715 <C> WN-N R <WITH> x+POS <HAS> .659 <C> WN-N F <WITH> x+POS <HAS> .686 <C> WN-V P <WITH> x+POS <HAS> .560 <C> WN-V R <WITH> x+POS <HAS> .464 <C> WN-V F <WITH> x+POS <HAS> .508 <C> VN P <WITH> x+POS <HAS> .349 <C> VN R <WITH> x+POS <HAS> .320 <C> VN F <WITH> x+POS <HAS> .334 <C> <R> <C> WN-N P <WITH> lemma <HAS> <bold>.725</bold> <C> WN-N R <WITH> lemma <HAS> <bold>.668</bold> <C> WN-N F <WITH> lemma <HAS> <bold>.696</bold> <C> WN-V P <WITH> lemma <HAS> .591 <C> WN-V R <WITH> lemma <HAS> .512 <C> WN-V F <WITH> lemma <HAS> .548 <C> VN P <WITH> lemma <HAS> .408 <C> VN R <WITH> lemma <HAS> .371 <C> VN F <WITH> lemma <HAS> .388 <C> <R> <C> WN-N P <WITH> x+POS <HAS> .722 <C> WN-N R <WITH> x+POS <HAS> .666 <C> WN-N F <WITH> x+POS <HAS> .693 <C> WN-V P <WITH> x+POS <HAS> <bold>.609</bold> <C> WN-V R <WITH> x+POS <HAS> <bold>.527</bold> <C> WN-V F <WITH> x+POS <HAS> <bold>.565</bold> <C> VN P <WITH> x+POS <HAS> <bold>.412</bold> <C> VN R <WITH> x+POS <HAS> <bold>.381</bold> <C> VN F <WITH> x+POS <HAS> <bold>.396</bold> <C> <CAP> Table 5: WCS performance, shared vocabulary, k=1. Best results across VSMs in bold.
 <R> <C> LR P <WITH> +BoW <HAS> 0.93 <C> LR R <WITH> +BoW <HAS> 0.91 <C> LR F1 <WITH> +BoW <HAS> 0.92 <C> SVM P <WITH> +BoW <HAS> 0.94 <C> SVM R <WITH> +BoW <HAS> 0.92 <C> SVM F1 <WITH> +BoW <HAS> 0.93 <C> ANN P <WITH> +BoW <HAS> 0.91 <C> ANN R <WITH> +BoW <HAS> 0.91 <C> ANN F1 <WITH> +BoW <HAS> 0.91 <C> <R> <C> LR P <WITH> +BoC (Wiki-PubMed-PMC) <HAS> 0.94 <C> LR R <WITH> +BoC (Wiki-PubMed-PMC) <HAS> 0.92 <C> LR F1 <WITH> +BoC (Wiki-PubMed-PMC) <HAS> [BOLD] 0.93 <C> SVM P <WITH> +BoC (Wiki-PubMed-PMC) <HAS> 0.94 <C> SVM R <WITH> +BoC (Wiki-PubMed-PMC) <HAS> 0.92 <C> SVM F1 <WITH> +BoC (Wiki-PubMed-PMC) <HAS> [BOLD] 0.93 <C> ANN P <WITH> +BoC (Wiki-PubMed-PMC) <HAS> 0.91 <C> ANN R <WITH> +BoC (Wiki-PubMed-PMC) <HAS> 0.91 <C> ANN F1 <WITH> +BoC (Wiki-PubMed-PMC) <HAS> [BOLD] 0.91 <C> <R> <C> LR P <WITH> +BoC (GloVe) <HAS> 0.93 <C> LR R <WITH> +BoC (GloVe) <HAS> 0.92 <C> LR F1 <WITH> +BoC (GloVe) <HAS> 0.92 <C> SVM P <WITH> +BoC (GloVe) <HAS> 0.94 <C> SVM R <WITH> +BoC (GloVe) <HAS> 0.92 <C> SVM F1 <WITH> +BoC (GloVe) <HAS> 0.93 <C> ANN P <WITH> +BoC (GloVe) <HAS> 0.91 <C> ANN R <WITH> +BoC (GloVe) <HAS> 0.91 <C> ANN F1 <WITH> +BoC (GloVe) <HAS> 0.91 <C> <R> <C> LR P <WITH> +ASM <HAS> 0.90 <C> LR R <WITH> +ASM <HAS> 0.85 <C> LR F1 <WITH> +ASM <HAS> 0.88 <C> SVM P <WITH> +ASM <HAS> 0.90 <C> SVM R <WITH> +ASM <HAS> 0.86 <C> SVM F1 <WITH> +ASM <HAS> 0.88 <C> ANN P <WITH> +ASM <HAS> 0.89 <C> ANN R <WITH> +ASM <HAS> 0.89 <C> ANN F1 <WITH> +ASM <HAS> 0.89 <C> <R> <C> LR P <WITH> +Sentence Embeddings(SEs) <HAS> 0.89 <C> LR R <WITH> +Sentence Embeddings(SEs) <HAS> 0.89 <C> LR F1 <WITH> +Sentence Embeddings(SEs) <HAS> 0.89 <C> SVM P <WITH> +Sentence Embeddings(SEs) <HAS> 0.90 <C> SVM R <WITH> +Sentence Embeddings(SEs) <HAS> 0.86 <C> SVM F1 <WITH> +Sentence Embeddings(SEs) <HAS> 0.88 <C> ANN P <WITH> +Sentence Embeddings(SEs) <HAS> 0.88 <C> ANN R <WITH> +Sentence Embeddings(SEs) <HAS> 0.88 <C> ANN F1 <WITH> +Sentence Embeddings(SEs) <HAS> 0.88 <C> <R> <C> LR P <WITH> +BoC(Wiki-PubMed-PMC)+SEs <HAS> 0.92 <C> LR R <WITH> +BoC(Wiki-PubMed-PMC)+SEs <HAS> 0.92 <C> LR F1 <WITH> +BoC(Wiki-PubMed-PMC)+SEs <HAS> 0.92 <C> SVM P <WITH> +BoC(Wiki-PubMed-PMC)+SEs <HAS> 0.94 <C> SVM R <WITH> +BoC(Wiki-PubMed-PMC)+SEs <HAS> 0.92 <C> SVM F1 <WITH> +BoC(Wiki-PubMed-PMC)+SEs <HAS> 0.93 <C> ANN P <WITH> +BoC(Wiki-PubMed-PMC)+SEs <HAS> 0.91 <C> ANN R <WITH> +BoC(Wiki-PubMed-PMC)+SEs <HAS> 0.91 <C> ANN F1 <WITH> +BoC(Wiki-PubMed-PMC)+SEs <HAS> 0.91 <C> <CAP> Table 1: Performance of supervised learning models with different features.
 <R> <C> Count <WITH> TherapyTiming(TP,TD) <HAS> 428 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> TherapyTiming(TP,TD) <HAS> [BOLD] 0.84 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> TherapyTiming(TP,TD) <HAS> 0.59 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> TherapyTiming(TP,TD) <HAS> 0.47 <C> BoC(Wiki-PubMed-PMC) LR <WITH> TherapyTiming(TP,TD) <HAS> 0.78 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> TherapyTiming(TP,TD) <HAS> 0.81 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> TherapyTiming(TP,TD) <HAS> 0.78 <C> <R> <C> Count <WITH> NextReview(Followup,TP) <HAS> 164 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> NextReview(Followup,TP) <HAS> [BOLD] 0.90 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> NextReview(Followup,TP) <HAS> 0.83 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> NextReview(Followup,TP) <HAS> 0.63 <C> BoC(Wiki-PubMed-PMC) LR <WITH> NextReview(Followup,TP) <HAS> 0.86 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> NextReview(Followup,TP) <HAS> 0.88 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> NextReview(Followup,TP) <HAS> 0.84 <C> <R> <C> Count <WITH> Toxicity(TP,CF/TR) <HAS> 163 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> Toxicity(TP,CF/TR) <HAS> [BOLD] 0.91 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> Toxicity(TP,CF/TR) <HAS> 0.77 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> Toxicity(TP,CF/TR) <HAS> 0.55 <C> BoC(Wiki-PubMed-PMC) LR <WITH> Toxicity(TP,CF/TR) <HAS> 0.85 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> Toxicity(TP,CF/TR) <HAS> 0.86 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> Toxicity(TP,CF/TR) <HAS> 0.86 <C> <R> <C> Count <WITH> TestTiming(TN,TD/TP) <HAS> 184 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> TestTiming(TN,TD/TP) <HAS> 0.90 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> TestTiming(TN,TD/TP) <HAS> 0.81 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> TestTiming(TN,TD/TP) <HAS> 0.42 <C> BoC(Wiki-PubMed-PMC) LR <WITH> TestTiming(TN,TD/TP) <HAS> 0.96 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> TestTiming(TN,TD/TP) <HAS> [BOLD] 0.97 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> TestTiming(TN,TD/TP) <HAS> 0.95 <C> <R> <C> Count <WITH> TestFinding(TN,TR) <HAS> 136 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> TestFinding(TN,TR) <HAS> 0.76 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> TestFinding(TN,TR) <HAS> 0.60 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> TestFinding(TN,TR) <HAS> 0.44 <C> BoC(Wiki-PubMed-PMC) LR <WITH> TestFinding(TN,TR) <HAS> [BOLD] 0.82 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> TestFinding(TN,TR) <HAS> 0.79 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> TestFinding(TN,TR) <HAS> 0.78 <C> <R> <C> Count <WITH> Threat(O,CF/TR) <HAS> 32 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> Threat(O,CF/TR) <HAS> 0.85 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> Threat(O,CF/TR) <HAS> 0.69 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> Threat(O,CF/TR) <HAS> 0.54 <C> BoC(Wiki-PubMed-PMC) LR <WITH> Threat(O,CF/TR) <HAS> [BOLD] 0.95 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> Threat(O,CF/TR) <HAS> [BOLD] 0.95 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> Threat(O,CF/TR) <HAS> 0.92 <C> <R> <C> Count <WITH> Intervention(TP,YR) <HAS> 5 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> Intervention(TP,YR) <HAS> [BOLD] 0.88 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> Intervention(TP,YR) <HAS> 0.65 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> Intervention(TP,YR) <HAS> 0.47 <C> BoC(Wiki-PubMed-PMC) LR <WITH> Intervention(TP,YR) <HAS> - <C> BoC(Wiki-PubMed-PMC) SVM <WITH> Intervention(TP,YR) <HAS> - <C> BoC(Wiki-PubMed-PMC) ANN <WITH> Intervention(TP,YR) <HAS> - <C> <R> <C> Count <WITH> EffectOf(Com,CF) <HAS> 3 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> EffectOf(Com,CF) <HAS> [BOLD] 0.92 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> EffectOf(Com,CF) <HAS> 0.62 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> EffectOf(Com,CF) <HAS> 0.23 <C> BoC(Wiki-PubMed-PMC) LR <WITH> EffectOf(Com,CF) <HAS> - <C> BoC(Wiki-PubMed-PMC) SVM <WITH> EffectOf(Com,CF) <HAS> - <C> BoC(Wiki-PubMed-PMC) ANN <WITH> EffectOf(Com,CF) <HAS> - <C> <R> <C> Count <WITH> Severity(CF,CS) <HAS> 75 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> Severity(CF,CS) <HAS> [BOLD] 0.61 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> Severity(CF,CS) <HAS> 0.53 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> Severity(CF,CS) <HAS> 0.47 <C> BoC(Wiki-PubMed-PMC) LR <WITH> Severity(CF,CS) <HAS> 0.52 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> Severity(CF,CS) <HAS> 0.55 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> Severity(CF,CS) <HAS> 0.51 <C> <R> <C> Count <WITH> RecurLink(YR,YR/CF) <HAS> 7 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> RecurLink(YR,YR/CF) <HAS> [BOLD] 1.0 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> RecurLink(YR,YR/CF) <HAS> [BOLD] 1.0 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> RecurLink(YR,YR/CF) <HAS> 0.64 <C> BoC(Wiki-PubMed-PMC) LR <WITH> RecurLink(YR,YR/CF) <HAS> - <C> BoC(Wiki-PubMed-PMC) SVM <WITH> RecurLink(YR,YR/CF) <HAS> - <C> BoC(Wiki-PubMed-PMC) ANN <WITH> RecurLink(YR,YR/CF) <HAS> - <C> <R> <C> Count <WITH> RecurInfer(NR/YR,TR) <HAS> 51 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> RecurInfer(NR/YR,TR) <HAS> 0.97 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> RecurInfer(NR/YR,TR) <HAS> 0.69 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> RecurInfer(NR/YR,TR) <HAS> 0.43 <C> BoC(Wiki-PubMed-PMC) LR <WITH> RecurInfer(NR/YR,TR) <HAS> [BOLD] 0.99 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> RecurInfer(NR/YR,TR) <HAS> [BOLD] 0.99 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> RecurInfer(NR/YR,TR) <HAS> 0.98 <C> <R> <C> Count <WITH> GetOpinion(Referral,CF/other) <HAS> 4 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> GetOpinion(Referral,CF/other) <HAS> [BOLD] 0.75 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> GetOpinion(Referral,CF/other) <HAS> [BOLD] 0.75 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> GetOpinion(Referral,CF/other) <HAS> 0.5 <C> BoC(Wiki-PubMed-PMC) LR <WITH> GetOpinion(Referral,CF/other) <HAS> - <C> BoC(Wiki-PubMed-PMC) SVM <WITH> GetOpinion(Referral,CF/other) <HAS> - <C> BoC(Wiki-PubMed-PMC) ANN <WITH> GetOpinion(Referral,CF/other) <HAS> - <C> <R> <C> Count <WITH> Context(Dis,DisCont) <HAS> 40 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> Context(Dis,DisCont) <HAS> [BOLD] 0.70 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> Context(Dis,DisCont) <HAS> 0.63 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> Context(Dis,DisCont) <HAS> 0.53 <C> BoC(Wiki-PubMed-PMC) LR <WITH> Context(Dis,DisCont) <HAS> 0.60 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> Context(Dis,DisCont) <HAS> 0.41 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> Context(Dis,DisCont) <HAS> 0.57 <C> <R> <C> Count <WITH> TestToAssess(TN,CF/TR) <HAS> 36 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> TestToAssess(TN,CF/TR) <HAS> 0.76 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> TestToAssess(TN,CF/TR) <HAS> 0.66 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> TestToAssess(TN,CF/TR) <HAS> 0.36 <C> BoC(Wiki-PubMed-PMC) LR <WITH> TestToAssess(TN,CF/TR) <HAS> [BOLD] 0.92 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> TestToAssess(TN,CF/TR) <HAS> [BOLD] 0.92 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> TestToAssess(TN,CF/TR) <HAS> 0.91 <C> <R> <C> Count <WITH> TimeStamp(TD,TP) <HAS> 221 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> TimeStamp(TD,TP) <HAS> [BOLD] 0.88 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> TimeStamp(TD,TP) <HAS> 0.83 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> TimeStamp(TD,TP) <HAS> 0.50 <C> BoC(Wiki-PubMed-PMC) LR <WITH> TimeStamp(TD,TP) <HAS> 0.86 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> TimeStamp(TD,TP) <HAS> 0.85 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> TimeStamp(TD,TP) <HAS> 0.83 <C> <R> <C> Count <WITH> TimeLink(TP,TP) <HAS> 20 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> TimeLink(TP,TP) <HAS> [BOLD] 0.92 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> TimeLink(TP,TP) <HAS> 0.85 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> TimeLink(TP,TP) <HAS> 0.45 <C> BoC(Wiki-PubMed-PMC) LR <WITH> TimeLink(TP,TP) <HAS> 0.91 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> TimeLink(TP,TP) <HAS> [BOLD] 0.92 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> TimeLink(TP,TP) <HAS> 0.90 <C> <R> <C> Count <WITH> Overall <HAS> 1569 <C> Intra-sentential co-occ.  [ITALIC] ρ=0 <WITH> Overall <HAS> 0.90 <C> Intra-sentential co-occ.  [ITALIC] ρ=5 <WITH> Overall <HAS> 0.73 <C> Intra-sentential co-occ.  [ITALIC] ρ=10 <WITH> Overall <HAS> 0.45 <C> BoC(Wiki-PubMed-PMC) LR <WITH> Overall <HAS> 0.92 <C> BoC(Wiki-PubMed-PMC) SVM <WITH> Overall <HAS> [BOLD] 0.93 <C> BoC(Wiki-PubMed-PMC) ANN <WITH> Overall <HAS> 0.91 <C> <CAP> Table 2: F1 score results per relation type of the best performing models.
 <R> <C> [BOLD] # pairs <WITH> Multi-News <HAS> 44,972/5,622/5,622 <C> [BOLD] # words (doc) <WITH> Multi-News <HAS> 2,103.49 <C> [BOLD] # sents (docs) <WITH> Multi-News <HAS> 82.73 <C> [BOLD] # words (summary) <WITH> Multi-News <HAS> 263.66 <C> [BOLD] # sents (summary) <WITH> Multi-News <HAS> 9.97 <C> [BOLD] vocab size <WITH> Multi-News <HAS> 666,515 <C> <R> <C> [BOLD] # pairs <WITH> DUC03+04 <HAS> 320 <C> [BOLD] # words (doc) <WITH> DUC03+04 <HAS> 4,636.24 <C> [BOLD] # sents (docs) <WITH> DUC03+04 <HAS> 173.15 <C> [BOLD] # words (summary) <WITH> DUC03+04 <HAS> 109.58 <C> [BOLD] # sents (summary) <WITH> DUC03+04 <HAS> 2.88 <C> [BOLD] vocab size <WITH> DUC03+04 <HAS> 19,734 <C> <R> <C> [BOLD] # pairs <WITH> TAC 2011 <HAS> 176 <C> [BOLD] # words (doc) <WITH> TAC 2011 <HAS> 4,695.70 <C> [BOLD] # sents (docs) <WITH> TAC 2011 <HAS> 188.43 <C> [BOLD] # words (summary) <WITH> TAC 2011 <HAS> 99.70 <C> [BOLD] # sents (summary) <WITH> TAC 2011 <HAS> 1.00 <C> [BOLD] vocab size <WITH> TAC 2011 <HAS> 24,672 <C> <R> <C> [BOLD] # pairs <WITH> CNNDM <HAS> 287,227/13,368/11,490 <C> [BOLD] # words (doc) <WITH> CNNDM <HAS> 810.57 <C> [BOLD] # sents (docs) <WITH> CNNDM <HAS> 39.78 <C> [BOLD] # words (summary) <WITH> CNNDM <HAS> 56.20 <C> [BOLD] # sents (summary) <WITH> CNNDM <HAS> 3.68 <C> [BOLD] vocab size <WITH> CNNDM <HAS> 717,951 <C> <CAP> Table 3: Comparison of our Multi-News dataset to other MDS datasets as well as an SDS dataset used as training data for MDS (CNNDM). Training, validation and testing size splits (article(s) to summary) are provided when applicable. Statistics for multi-document inputs are calculated on the concatenation of all input sources.
 <R> <C> [BOLD] Multi-News <WITH> uni-grams <HAS> 17.76 <C> [BOLD] DUC03+04 <WITH> uni-grams <HAS> 27.74 <C> [BOLD] TAC11 <WITH> uni-grams <HAS> 16.65 <C> [BOLD] CNNDM <WITH> uni-grams <HAS> 19.50 <C> <R> <C> [BOLD] Multi-News <WITH> bi-grams <HAS> 57.10 <C> [BOLD] DUC03+04 <WITH> bi-grams <HAS> 72.87 <C> [BOLD] TAC11 <WITH> bi-grams <HAS> 61.18 <C> [BOLD] CNNDM <WITH> bi-grams <HAS> 56.88 <C> <R> <C> [BOLD] Multi-News <WITH> tri-grams <HAS> 75.71 <C> [BOLD] DUC03+04 <WITH> tri-grams <HAS> 90.61 <C> [BOLD] TAC11 <WITH> tri-grams <HAS> 83.34 <C> [BOLD] CNNDM <WITH> tri-grams <HAS> 74.41 <C> <R> <C> [BOLD] Multi-News <WITH> 4-grams <HAS> 82.30 <C> [BOLD] DUC03+04 <WITH> 4-grams <HAS> 96.18 <C> [BOLD] TAC11 <WITH> 4-grams <HAS> 92.04 <C> [BOLD] CNNDM <WITH> 4-grams <HAS> 82.83 <C> <CAP> Table 4: Percentage of n-grams in summaries which do not appear in the input documents , a measure of the abstractiveness, in relevant datasets.
 <R> <C> [BOLD] R-1 <WITH> First-1 <HAS> 26.83 <C> [BOLD] R-2 <WITH> First-1 <HAS> 7.25 <C> [BOLD] R-SU <WITH> First-1 <HAS> 6.46 <C> <R> <C> [BOLD] R-1 <WITH> First-2 <HAS> 35.99 <C> [BOLD] R-2 <WITH> First-2 <HAS> 10.17 <C> [BOLD] R-SU <WITH> First-2 <HAS> 12.06 <C> <R> <C> [BOLD] R-1 <WITH> First-3 <HAS> 39.41 <C> [BOLD] R-2 <WITH> First-3 <HAS> 11.77 <C> [BOLD] R-SU <WITH> First-3 <HAS> 14.51 <C> <R> <C> [BOLD] R-1 <WITH> LexRank Erkan and Radev ( 2004 ) <HAS> 38.27 <C> [BOLD] R-2 <WITH> LexRank Erkan and Radev ( 2004 ) <HAS> 12.70 <C> [BOLD] R-SU <WITH> LexRank Erkan and Radev ( 2004 ) <HAS> 13.20 <C> <R> <C> [BOLD] R-1 <WITH> TextRank Mihalcea and Tarau ( 2004 ) <HAS> 38.44 <C> [BOLD] R-2 <WITH> TextRank Mihalcea and Tarau ( 2004 ) <HAS> 13.10 <C> [BOLD] R-SU <WITH> TextRank Mihalcea and Tarau ( 2004 ) <HAS> 13.50 <C> <R> <C> [BOLD] R-1 <WITH> MMR Carbonell and Goldstein ( 1998 ) <HAS> 38.77 <C> [BOLD] R-2 <WITH> MMR Carbonell and Goldstein ( 1998 ) <HAS> 11.98 <C> [BOLD] R-SU <WITH> MMR Carbonell and Goldstein ( 1998 ) <HAS> 12.91 <C> <R> <C> [BOLD] R-1 <WITH> PG-Original Lebanoff et al. ( 2018 ) <HAS> 41.85 <C> [BOLD] R-2 <WITH> PG-Original Lebanoff et al. ( 2018 ) <HAS> 12.91 <C> [BOLD] R-SU <WITH> PG-Original Lebanoff et al. ( 2018 ) <HAS> 16.46 <C> <R> <C> [BOLD] R-1 <WITH> PG-MMR Lebanoff et al. ( 2018 ) <HAS> 40.55 <C> [BOLD] R-2 <WITH> PG-MMR Lebanoff et al. ( 2018 ) <HAS> 12.36 <C> [BOLD] R-SU <WITH> PG-MMR Lebanoff et al. ( 2018 ) <HAS> 15.87 <C> <R> <C> [BOLD] R-1 <WITH> PG-BRNN Gehrmann et al. ( 2018 ) <HAS> 42.80 <C> [BOLD] R-2 <WITH> PG-BRNN Gehrmann et al. ( 2018 ) <HAS> 14.19 <C> [BOLD] R-SU <WITH> PG-BRNN Gehrmann et al. ( 2018 ) <HAS> 16.75 <C> <R> <C> [BOLD] R-1 <WITH> CopyTransformer Gehrmann et al. ( 2018 ) <HAS> [BOLD] 43.57 <C> [BOLD] R-2 <WITH> CopyTransformer Gehrmann et al. ( 2018 ) <HAS> 14.03 <C> [BOLD] R-SU <WITH> CopyTransformer Gehrmann et al. ( 2018 ) <HAS> 17.37 <C> <R> <C> [BOLD] R-1 <WITH> Hi-MAP (Our Model) <HAS> 43.47 <C> [BOLD] R-2 <WITH> Hi-MAP (Our Model) <HAS> [BOLD] 14.89 <C> [BOLD] R-SU <WITH> Hi-MAP (Our Model) <HAS> [BOLD] 17.41 <C> <CAP> Table 6: ROUGE scores for models trained and tested on the Multi-News dataset.
 <R> <C> Answer Prec. <WITH> 1 <HAS> 79.2 <C> Derivation Prec. <WITH> 1 <HAS> 38.4 <C> <R> <C> Answer Prec. <WITH> 2 <HAS> 64.4 <C> Derivation Prec. <WITH> 2 <HAS> 48.6 <C> <R> <C> Answer Prec. <WITH> 3 <HAS> 62.3 <C> Derivation Prec. <WITH> 3 <HAS> 41.3 <C> <CAP> Table 5: Performance breakdown of the PRKGC+NS model. Derivation Precision denotes ROUGE-L F1 of generated NLDs.
 <R> <C> Reachability <WITH> 1 <HAS> 3.0 <C> Derivability Step 1 <WITH> 1 <HAS> 3.8 <C> Derivability Step 2 <WITH> 1 <HAS> - <C> Derivability Step 3 <WITH> 1 <HAS> - <C> <R> <C> Reachability <WITH> 2 <HAS> 2.8 <C> Derivability Step 1 <WITH> 2 <HAS> 3.8 <C> Derivability Step 2 <WITH> 2 <HAS> 3.7 <C> Derivability Step 3 <WITH> 2 <HAS> - <C> <R> <C> Reachability <WITH> 3 <HAS> 2.3 <C> Derivability Step 1 <WITH> 3 <HAS> 3.9 <C> Derivability Step 2 <WITH> 3 <HAS> 3.8 <C> Derivability Step 3 <WITH> 3 <HAS> 3.8 <C> <CAP> Table 2: Ratings of annotated NLDs by human judges.
 <R> <C> Answerability Macro P/R/F <WITH> Shortest Path <HAS> 54.8/55.5/53.2 <C> # Answerable <WITH> Shortest Path <HAS> 976 <C> Answer Prec. <WITH> Shortest Path <HAS> 3.6 <C> Derivation Prec. RG-L (P/R/F) <WITH> Shortest Path <HAS> 56.7/38.5/41.5 <C> Derivation Prec. BL-4 <WITH> Shortest Path <HAS> 31.3 <C> <R> <C> Answerability Macro P/R/F <WITH> PRKGC <HAS> 52.6/51.5/50.7 <C> # Answerable <WITH> PRKGC <HAS> 1,021 <C> Answer Prec. <WITH> PRKGC <HAS> 45.2 <C> Derivation Prec. RG-L (P/R/F) <WITH> PRKGC <HAS> 40.7/60.7/44.7 <C> Derivation Prec. BL-4 <WITH> PRKGC <HAS> 30.9 <C> <R> <C> Answerability Macro P/R/F <WITH> PRKGC+NS <HAS> 53.6/54.1/52.1 <C> # Answerable <WITH> PRKGC+NS <HAS> 980 <C> Answer Prec. <WITH> PRKGC+NS <HAS> 45.4 <C> Derivation Prec. RG-L (P/R/F) <WITH> PRKGC+NS <HAS> 42.2/61.6/46.1 <C> Derivation Prec. BL-4 <WITH> PRKGC+NS <HAS> 33.4 <C> <CAP> Table 4: Performance of RC-QEDE of our baseline models (see Section 2.1 for further details of each evaluation metrics). “NS” indicates the use of annotated NLDs as supervision (i.e. using Ld during training).
 <R> <C> Accuracy <WITH> PRKGC (our work) <HAS> 51.4 <C> <R> <C> Accuracy <WITH> PRKGC+NS (our work) <HAS> [BOLD] 52.7 <C> <R> <C> Accuracy <WITH> BiDAF Welbl2017a <HAS> 42.1 <C> <R> <C> Accuracy <WITH> CorefGRU Dhingra2018NeuralCoreference <HAS> 56.0 <C> <R> <C> Accuracy <WITH> MHPGM+NOIC Bauer2018CommonsenseTasks <HAS> 58.2 <C> <R> <C> Accuracy <WITH> EntityGCN DeCao2018QuestionNetworks <HAS> 65.3 <C> <R> <C> Accuracy <WITH> CFC Zhong2019Coarse-GrainAnswering <HAS> 66.4 <C> <CAP> Table 7: Accuracy of our baseline models and previous work on WikiHop Welbl2017a’s development set. Note that our baseline models are explainable, whereas the others are not. “NS” indicates the use of annotated NLDs as supervision. Accuracies of existing models are taken from the papers.
 <R> <C> 5-fold CV 70.56 <WITH> LSTM-400 <HAS> 70.50 <C> Δ 0.66 <WITH> LSTM-400 <HAS> 0.60 <C> Single model 67.54 <WITH> LSTM-400 <HAS> [BOLD] 67.59 <C> Δ 0.78 <WITH> LSTM-400 <HAS> 0.83 <C> Ensemble 67.65 <WITH> LSTM-400 <HAS> [BOLD] 68.00 <C> Δ 0.30 <WITH> LSTM-400 <HAS> 0.65 <C> <R> <C> 5-fold CV 70.56 <WITH> IN-TITLE <HAS> 70.11 <C> Δ 0.66 <WITH> IN-TITLE <HAS> 0.21 <C> Single model 67.54 <WITH> IN-TITLE <HAS> [EMPTY] <C> Δ 0.78 <WITH> IN-TITLE <HAS> [EMPTY] <C> Ensemble 67.65 <WITH> IN-TITLE <HAS> 67.52 <C> Δ 0.30 <WITH> IN-TITLE <HAS> 0.17 <C> <R> <C> 5-fold CV 70.56 <WITH> [BOLD] SUBMISSION <HAS> 69.90 <C> Δ 0.66 <WITH> [BOLD] SUBMISSION <HAS> – <C> Single model 67.54 <WITH> [BOLD] SUBMISSION <HAS> 66.76 <C> Δ 0.78 <WITH> [BOLD] SUBMISSION <HAS> – <C> Ensemble 67.65 <WITH> [BOLD] SUBMISSION <HAS> 67.35 <C> Δ 0.30 <WITH> [BOLD] SUBMISSION <HAS> – <C> <R> <C> 5-fold CV 70.56 <WITH> NO-HIGHWAY <HAS> 69.72 <C> Δ 0.66 <WITH> NO-HIGHWAY <HAS> −0.18 <C> Single model 67.54 <WITH> NO-HIGHWAY <HAS> 66.42 <C> Δ 0.78 <WITH> NO-HIGHWAY <HAS> −0.34 <C> Ensemble 67.65 <WITH> NO-HIGHWAY <HAS> 66.64 <C> Δ 0.30 <WITH> NO-HIGHWAY <HAS> −0.71 <C> <R> <C> 5-fold CV 70.56 <WITH> NO-OVERLAPS <HAS> 69.46 <C> Δ 0.66 <WITH> NO-OVERLAPS <HAS> −0.44 <C> Single model 67.54 <WITH> NO-OVERLAPS <HAS> 65.07 <C> Δ 0.78 <WITH> NO-OVERLAPS <HAS> −1.69 <C> Ensemble 67.65 <WITH> NO-OVERLAPS <HAS> 66.47 <C> Δ 0.30 <WITH> NO-OVERLAPS <HAS> −0.88 <C> <R> <C> 5-fold CV 70.56 <WITH> LSTM-400-DROPOUT <HAS> 69.45 <C> Δ 0.66 <WITH> LSTM-400-DROPOUT <HAS> −0.45 <C> Single model 67.54 <WITH> LSTM-400-DROPOUT <HAS> 65.53 <C> Δ 0.78 <WITH> LSTM-400-DROPOUT <HAS> −1.23 <C> Ensemble 67.65 <WITH> LSTM-400-DROPOUT <HAS> 67.28 <C> Δ 0.30 <WITH> LSTM-400-DROPOUT <HAS> −0.07 <C> <R> <C> 5-fold CV 70.56 <WITH> NO-TRANSLATIONS <HAS> 69.42 <C> Δ 0.66 <WITH> NO-TRANSLATIONS <HAS> −0.48 <C> Single model 67.54 <WITH> NO-TRANSLATIONS <HAS> 65.92 <C> Δ 0.78 <WITH> NO-TRANSLATIONS <HAS> −0.84 <C> Ensemble 67.65 <WITH> NO-TRANSLATIONS <HAS> 67.23 <C> Δ 0.30 <WITH> NO-TRANSLATIONS <HAS> −0.12 <C> <R> <C> 5-fold CV 70.56 <WITH> NO-ELMO-FINETUNING <HAS> 67.71 <C> Δ 0.66 <WITH> NO-ELMO-FINETUNING <HAS> −2.19 <C> Single model 67.54 <WITH> NO-ELMO-FINETUNING <HAS> 65.16 <C> Δ 0.78 <WITH> NO-ELMO-FINETUNING <HAS> −1.60 <C> Ensemble 67.65 <WITH> NO-ELMO-FINETUNING <HAS> 65.42 <C> Δ 0.30 <WITH> NO-ELMO-FINETUNING <HAS> −1.93 <C> <CAP> Table 3: The estimation of impact of various design choices on the final result. The entries are sorted by the out-of-fold scores from CV. The SUBMISSION here uses score from ep_1 run for the single model and ep_2 for the ensemble performance.
 <R> <C> Official score <WITH> ep_1 <HAS> 60.29 <C> Score with correction <WITH> ep_1 <HAS> 66.76 <C> <R> <C> Official score <WITH> ep_2 <HAS> [BOLD] 60.90 <C> Score with correction <WITH> ep_2 <HAS> [BOLD] 67.35 <C> <R> <C> Official score <WITH> ep_3 <HAS> 60.61 <C> Score with correction <WITH> ep_3 <HAS> 67.07 <C> <CAP> Table 1: The scores of our three submitted runs for similarity threshold 50%.
 <R> <C> No. examples <WITH> Total <HAS> 15265 <C> F1 (5-CV) <WITH> Total <HAS> 69.90 <C> F1 (Test) <WITH> Total <HAS> 67.35 <C> <R> <C> No. examples <WITH> Endpoint <HAS> 4411 <C> F1 (5-CV) <WITH> Endpoint <HAS> 66.89 <C> F1 (Test) <WITH> Endpoint <HAS> 61.47 <C> <R> <C> No. examples <WITH> TestArticle <HAS> 1922 <C> F1 (5-CV) <WITH> TestArticle <HAS> 63.29 <C> F1 (Test) <WITH> TestArticle <HAS> 64.19 <C> <R> <C> No. examples <WITH> Species <HAS> 1624 <C> F1 (5-CV) <WITH> Species <HAS> 95.33 <C> F1 (Test) <WITH> Species <HAS> 95.95 <C> <R> <C> No. examples <WITH> GroupName <HAS> 963 <C> F1 (5-CV) <WITH> GroupName <HAS> 67.08 <C> F1 (Test) <WITH> GroupName <HAS> 62.40 <C> <R> <C> No. examples <WITH> EndpointUnitOfMeasure <HAS> 706 <C> F1 (5-CV) <WITH> EndpointUnitOfMeasure <HAS> 42.27 <C> F1 (Test) <WITH> EndpointUnitOfMeasure <HAS> 40.41 <C> <R> <C> No. examples <WITH> TimeEndpointAssessed <HAS> 672 <C> F1 (5-CV) <WITH> TimeEndpointAssessed <HAS> 57.27 <C> F1 (Test) <WITH> TimeEndpointAssessed <HAS> 55.51 <C> <R> <C> No. examples <WITH> Dose <HAS> 659 <C> F1 (5-CV) <WITH> Dose <HAS> 78.47 <C> F1 (Test) <WITH> Dose <HAS> 75.85 <C> <R> <C> No. examples <WITH> Sex <HAS> 612 <C> F1 (5-CV) <WITH> Sex <HAS> 96.27 <C> F1 (Test) <WITH> Sex <HAS> 98.36 <C> <R> <C> No. examples <WITH> TimeUnits <HAS> 608 <C> F1 (5-CV) <WITH> TimeUnits <HAS> 68.03 <C> F1 (Test) <WITH> TimeUnits <HAS> 61.26 <C> <R> <C> No. examples <WITH> DoseRoute <HAS> 572 <C> F1 (5-CV) <WITH> DoseRoute <HAS> 69.24 <C> F1 (Test) <WITH> DoseRoute <HAS> 69.80 <C> <R> <C> No. examples <WITH> DoseUnits <HAS> 493 <C> F1 (5-CV) <WITH> DoseUnits <HAS> 77.50 <C> F1 (Test) <WITH> DoseUnits <HAS> 72.33 <C> <R> <C> No. examples <WITH> Vehicle <HAS> 440 <C> F1 (5-CV) <WITH> Vehicle <HAS> 63.03 <C> F1 (Test) <WITH> Vehicle <HAS> 67.15 <C> <R> <C> No. examples <WITH> GroupSize <HAS> 387 <C> F1 (5-CV) <WITH> GroupSize <HAS> 77.79 <C> F1 (Test) <WITH> GroupSize <HAS> 75.74 <C> <R> <C> No. examples <WITH> Strain <HAS> 375 <C> F1 (5-CV) <WITH> Strain <HAS> 78.56 <C> F1 (Test) <WITH> Strain <HAS> 76.00 <C> <R> <C> No. examples <WITH> DoseDuration <HAS> 216 <C> F1 (5-CV) <WITH> DoseDuration <HAS> 59.78 <C> F1 (Test) <WITH> DoseDuration <HAS> 56.80 <C> <R> <C> No. examples <WITH> DoseDurationUnits <HAS> 204 <C> F1 (5-CV) <WITH> DoseDurationUnits <HAS> 57.83 <C> F1 (Test) <WITH> DoseDurationUnits <HAS> 56.60 <C> <R> <C> No. examples <WITH> TimeAtDose <HAS> 117 <C> F1 (5-CV) <WITH> TimeAtDose <HAS> 34.29 <C> F1 (Test) <WITH> TimeAtDose <HAS> 35.68 <C> <R> <C> No. examples <WITH> DoseFrequency <HAS> 96 <C> F1 (5-CV) <WITH> DoseFrequency <HAS> 41.56 <C> F1 (Test) <WITH> DoseFrequency <HAS> 59.78 <C> <R> <C> No. examples <WITH> TimeAtFirstDose <HAS> 47 <C> F1 (5-CV) <WITH> TimeAtFirstDose <HAS> 3.92 <C> F1 (Test) <WITH> TimeAtFirstDose <HAS> 0.00 <C> <R> <C> No. examples <WITH> SampleSize <HAS> 45 <C> F1 (5-CV) <WITH> SampleSize <HAS> 43.84 <C> F1 (Test) <WITH> SampleSize <HAS> 50.00 <C> <R> <C> No. examples <WITH> CellLine <HAS> 39 <C> F1 (5-CV) <WITH> CellLine <HAS> 50.00 <C> F1 (Test) <WITH> CellLine <HAS> 50.77 <C> <R> <C> No. examples <WITH> TestArticlePurity <HAS> 28 <C> F1 (5-CV) <WITH> TestArticlePurity <HAS> 34.04 <C> F1 (Test) <WITH> TestArticlePurity <HAS> 60.00 <C> <R> <C> No. examples <WITH> TimeAtLastDose <HAS> 23 <C> F1 (5-CV) <WITH> TimeAtLastDose <HAS> 0.00 <C> F1 (Test) <WITH> TimeAtLastDose <HAS> 0.00 <C> <R> <C> No. examples <WITH> TestArticleVerification <HAS> 6 <C> F1 (5-CV) <WITH> TestArticleVerification <HAS> 0.00 <C> F1 (Test) <WITH> TestArticleVerification <HAS> 0.00 <C> <CAP> Table 2: Detailed results of our best run (after correcting the submission format), along with numbers of mentions in the training set.
 <R> <C> DUC’01 <italic>R</italic>1 <WITH> ICSI <HAS> 33.31 <C> DUC’01 <italic>R</italic>2 <WITH> ICSI <HAS> 7.33 <C> DUC’02 <italic>R</italic>1 <WITH> ICSI <HAS> 35.04 <C> DUC’02 <italic>R</italic>2 <WITH> ICSI <HAS> 8.51 <C> DUC’04 <italic>R</italic>1 <WITH> ICSI <HAS> 37.31 <C> DUC’04 <italic>R</italic>2 <WITH> ICSI <HAS> 9.36 <C> <R> <C> DUC’01 <italic>R</italic>1 <WITH> PriorSum <HAS> 35.98 <C> DUC’01 <italic>R</italic>2 <WITH> PriorSum <HAS> 7.89 <C> DUC’02 <italic>R</italic>1 <WITH> PriorSum <HAS> 36.63 <C> DUC’02 <italic>R</italic>2 <WITH> PriorSum <HAS> 8.97 <C> DUC’04 <italic>R</italic>1 <WITH> PriorSum <HAS> 38.91 <C> DUC’04 <italic>R</italic>2 <WITH> PriorSum <HAS> 10.07 <C> <R> <C> DUC’01 <italic>R</italic>1 <WITH> TCSum <HAS> <bold>36.45</bold> <C> DUC’01 <italic>R</italic>2 <WITH> TCSum <HAS> 7.66 <C> DUC’02 <italic>R</italic>1 <WITH> TCSum <HAS> 36.90 <C> DUC’02 <italic>R</italic>2 <WITH> TCSum <HAS> 8.61 <C> DUC’04 <italic>R</italic>1 <WITH> TCSum <HAS> 38.27 <C> DUC’04 <italic>R</italic>2 <WITH> TCSum <HAS> 9.66 <C> <R> <C> DUC’01 <italic>R</italic>1 <WITH> TCSum− <HAS> 33.45 <C> DUC’01 <italic>R</italic>2 <WITH> TCSum− <HAS> 6.07 <C> DUC’02 <italic>R</italic>1 <WITH> TCSum− <HAS> 34.02 <C> DUC’02 <italic>R</italic>2 <WITH> TCSum− <HAS> 7.39 <C> DUC’04 <italic>R</italic>1 <WITH> TCSum− <HAS> 35.66 <C> DUC’04 <italic>R</italic>2 <WITH> TCSum− <HAS> 8.66 <C> <R> <C> DUC’01 <italic>R</italic>1 <WITH> SRSum <HAS> 36.04 <C> DUC’01 <italic>R</italic>2 <WITH> SRSum <HAS> 8.44 <C> DUC’02 <italic>R</italic>1 <WITH> SRSum <HAS> <bold>38.93</bold> <C> DUC’02 <italic>R</italic>2 <WITH> SRSum <HAS> <bold>10.29</bold> <C> DUC’04 <italic>R</italic>1 <WITH> SRSum <HAS> 39.29 <C> DUC’04 <italic>R</italic>2 <WITH> SRSum <HAS> 10.70 <C> <R> <C> DUC’01 <italic>R</italic>1 <WITH> DeepTD <HAS> 28.74 <C> DUC’01 <italic>R</italic>2 <WITH> DeepTD <HAS> 5.95 <C> DUC’02 <italic>R</italic>1 <WITH> DeepTD <HAS> 31.63 <C> DUC’02 <italic>R</italic>2 <WITH> DeepTD <HAS> 7.09 <C> DUC’04 <italic>R</italic>1 <WITH> DeepTD <HAS> 33.57 <C> DUC’04 <italic>R</italic>2 <WITH> DeepTD <HAS> 7.96 <C> <R> <C> DUC’01 <italic>R</italic>1 <WITH> REAPER <HAS> 32.43 <C> DUC’01 <italic>R</italic>2 <WITH> REAPER <HAS> 6.84 <C> DUC’02 <italic>R</italic>1 <WITH> REAPER <HAS> 35.03 <C> DUC’02 <italic>R</italic>2 <WITH> REAPER <HAS> 8.11 <C> DUC’04 <italic>R</italic>1 <WITH> REAPER <HAS> 37.22 <C> DUC’04 <italic>R</italic>2 <WITH> REAPER <HAS> 8.64 <C> <R> <C> DUC’01 <italic>R</italic>1 <WITH> RELIS <HAS> 34.73 <C> DUC’01 <italic>R</italic>2 <WITH> RELIS <HAS> <bold>8.66</bold> <C> DUC’02 <italic>R</italic>1 <WITH> RELIS <HAS> 37.11 <C> DUC’02 <italic>R</italic>2 <WITH> RELIS <HAS> 9.12 <C> DUC’04 <italic>R</italic>1 <WITH> RELIS <HAS> <bold>39.34</bold> <C> DUC’04 <italic>R</italic>2 <WITH> RELIS <HAS> <bold>10.73</bold> <C> <CAP> Table 3: Results of non-RL (top), cross-input (DeepTD) and input-specific (REAPER) RL approaches (middle) compared with RELIS.
 <R> <C> DUC’01 <italic>ρ</italic> <WITH> ASRL <HAS> .176 <C> DUC’01 ndcg <WITH> ASRL <HAS> .555 <C> DUC’02 <italic>ρ</italic> <WITH> ASRL <HAS> .131 <C> DUC’02 ndcg <WITH> ASRL <HAS> .537 <C> DUC’04 <italic>ρ</italic> <WITH> ASRL <HAS> .145 <C> DUC’04 ndcg <WITH> ASRL <HAS> .558 <C> <R> <C> DUC’01 <italic>ρ</italic> <WITH> REAPER <HAS> .316 <C> DUC’01 ndcg <WITH> REAPER <HAS> .638 <C> DUC’02 <italic>ρ</italic> <WITH> REAPER <HAS> .301 <C> DUC’02 ndcg <WITH> REAPER <HAS> .639 <C> DUC’04 <italic>ρ</italic> <WITH> REAPER <HAS> .372 <C> DUC’04 ndcg <WITH> REAPER <HAS> .701 <C> <R> <C> DUC’01 <italic>ρ</italic> <WITH> JS <HAS> .549 <C> DUC’01 ndcg <WITH> JS <HAS> .736 <C> DUC’02 <italic>ρ</italic> <WITH> JS <HAS> .525 <C> DUC’02 ndcg <WITH> JS <HAS> .700 <C> DUC’04 <italic>ρ</italic> <WITH> JS <HAS> .570 <C> DUC’04 ndcg <WITH> JS <HAS> .763 <C> <R> <C> DUC’01 <italic>ρ</italic> <WITH> Our ^<italic>σUx</italic> <HAS> <bold>.601</bold> <C> DUC’01 ndcg <WITH> Our ^<italic>σUx</italic> <HAS> <bold>.764</bold> <C> DUC’02 <italic>ρ</italic> <WITH> Our ^<italic>σUx</italic> <HAS> <bold>.560</bold> <C> DUC’02 ndcg <WITH> Our ^<italic>σUx</italic> <HAS> <bold>.727</bold> <C> DUC’04 <italic>ρ</italic> <WITH> Our ^<italic>σUx</italic> <HAS> <bold>.617</bold> <C> DUC’04 ndcg <WITH> Our ^<italic>σUx</italic> <HAS> <bold>.802</bold> <C> <CAP> Table 2: The correlation of approximated and ground-truth ranking. ^σUx has significantly higher correlation over all other approaches.
 <R> <C> Micro F1 <WITH> Baseline <HAS> 0.709 <C> <R> <C> Micro F1 <WITH> W2V (<italic>d</italic>=50) <HAS> 0.748 <C> <R> <C> Micro F1 <WITH> W2V (<italic>d</italic>=500) <HAS> 0.756 <C> <R> <C> Micro F1 <WITH> S2V <HAS> 0.748 <C> <R> <C> Micro F1 <WITH> S2V + W2V (<italic>d</italic>=50) <HAS> 0.755 <C> <R> <C> Micro F1 <WITH> S2V + K + W2V(<italic>d</italic>=50) <HAS> 0.751 <C> <R> <C> Micro F1 <WITH> SIF (DE) <HAS> 0.748 <C> <R> <C> Micro F1 <WITH> SIF (DE-EN) <HAS> <bold>0.757</bold> <C> <CAP> Table 6: Task B results with polarity features
 <R> <C> Micro F1 <WITH> Baseline <HAS> 0.882 <C> <R> <C> Micro F1 <WITH> W2V (<italic>d</italic>=50) <HAS> 0.883 <C> <R> <C> Micro F1 <WITH> W2V (<italic>d</italic>=500) <HAS> <bold>0.897</bold> <C> <R> <C> Micro F1 <WITH> S2V <HAS> 0.885 <C> <R> <C> Micro F1 <WITH> S2V + W2V (<italic>d</italic>=50) <HAS> 0.891 <C> <R> <C> Micro F1 <WITH> S2V + K + W2V(<italic>d</italic>=50) <HAS> 0.890 <C> <R> <C> Micro F1 <WITH> SIF (DE) <HAS> 0.895 <C> <R> <C> Micro F1 <WITH> SIF (DE-EN) <HAS> 0.892 <C> <CAP> Table 4: Task A results
 <R> <C> Micro F1 <WITH> Baseline <HAS> 0.709 <C> <R> <C> Micro F1 <WITH> W2V (<italic>d</italic>=50) <HAS> 0.736 <C> <R> <C> Micro F1 <WITH> W2V (<italic>d</italic>=500) <HAS> 0.753 <C> <R> <C> Micro F1 <WITH> S2V <HAS> 0.748 <C> <R> <C> Micro F1 <WITH> S2V + W2V (<italic>d</italic>=50) <HAS> 0.744 <C> <R> <C> Micro F1 <WITH> S2V + K + W2V(<italic>d</italic>=50) <HAS> 0.749 <C> <R> <C> Micro F1 <WITH> SIF (DE) <HAS> 0.759 <C> <R> <C> Micro F1 <WITH> SIF (DE-EN) <HAS> <bold>0.765</bold> <C> <CAP> Table 5: Task B results
 <R> <C> [BOLD] Accuracy (%) <WITH> Submitted <HAS> [BOLD] 69.23 <C> [BOLD] Δ% <WITH> Submitted <HAS> - <C> <R> <C> [BOLD] Accuracy (%) <WITH> No emoji <HAS> 68.36 <C> [BOLD] Δ% <WITH> No emoji <HAS> - 0.87 <C> <R> <C> [BOLD] Accuracy (%) <WITH> No ELMo <HAS> 65.52 <C> [BOLD] Δ% <WITH> No ELMo <HAS> - 3.71 <C> <R> <C> [BOLD] Accuracy (%) <WITH> Concat Pooling <HAS> 68.47 <C> [BOLD] Δ% <WITH> Concat Pooling <HAS> - 0.76 <C> <R> <C> [BOLD] Accuracy (%) <WITH> LSTM hidden=4096 <HAS> 69.10 <C> [BOLD] Δ% <WITH> LSTM hidden=4096 <HAS> - 0.13 <C> <R> <C> [BOLD] Accuracy (%) <WITH> LSTM hidden=1024 <HAS> 68.93 <C> [BOLD] Δ% <WITH> LSTM hidden=1024 <HAS> - 0.30 <C> <R> <C> [BOLD] Accuracy (%) <WITH> LSTM hidden=512 <HAS> 68.43 <C> [BOLD] Δ% <WITH> LSTM hidden=512 <HAS> - 0.80 <C> <R> <C> [BOLD] Accuracy (%) <WITH> POS emb dim=100 <HAS> 68.99 <C> [BOLD] Δ% <WITH> POS emb dim=100 <HAS> - 0.24 <C> <R> <C> [BOLD] Accuracy (%) <WITH> POS emb dim=75 <HAS> 68.61 <C> [BOLD] Δ% <WITH> POS emb dim=75 <HAS> - 0.62 <C> <R> <C> [BOLD] Accuracy (%) <WITH> POS emb dim=50 <HAS> 69.33 <C> [BOLD] Δ% <WITH> POS emb dim=50 <HAS> + 0.10 <C> <R> <C> [BOLD] Accuracy (%) <WITH> POS emb dim=25 <HAS> 69.21 <C> [BOLD] Δ% <WITH> POS emb dim=25 <HAS> - 0.02 <C> <R> <C> [BOLD] Accuracy (%) <WITH> SGD optim lr=1 <HAS> 64.33 <C> [BOLD] Δ% <WITH> SGD optim lr=1 <HAS> - 4.90 <C> <R> <C> [BOLD] Accuracy (%) <WITH> SGD optim lr=0.1 <HAS> 66.11 <C> [BOLD] Δ% <WITH> SGD optim lr=0.1 <HAS> - 3.12 <C> <R> <C> [BOLD] Accuracy (%) <WITH> SGD optim lr=0.01 <HAS> 60.72 <C> [BOLD] Δ% <WITH> SGD optim lr=0.01 <HAS> - 8.51 <C> <R> <C> [BOLD] Accuracy (%) <WITH> SGD optim lr=0.001 <HAS> 30.49 <C> [BOLD] Δ% <WITH> SGD optim lr=0.001 <HAS> - 38.74 <C> <CAP> Table 2: Ablation study results.
 <R> <C> [BOLD] Precision <WITH> anger <HAS> 0.643 <C> [BOLD] Recall <WITH> anger <HAS> 0.601 <C> [BOLD] F1-score <WITH> anger <HAS> 0.621 <C> <R> <C> [BOLD] Precision <WITH> disgust <HAS> 0.703 <C> [BOLD] Recall <WITH> disgust <HAS> 0.661 <C> [BOLD] F1-score <WITH> disgust <HAS> 0.682 <C> <R> <C> [BOLD] Precision <WITH> fear <HAS> 0.742 <C> [BOLD] Recall <WITH> fear <HAS> 0.721 <C> [BOLD] F1-score <WITH> fear <HAS> 0.732 <C> <R> <C> [BOLD] Precision <WITH> joy <HAS> 0.762 <C> [BOLD] Recall <WITH> joy <HAS> 0.805 <C> [BOLD] F1-score <WITH> joy <HAS> 0.783 <C> <R> <C> [BOLD] Precision <WITH> sad <HAS> 0.685 <C> [BOLD] Recall <WITH> sad <HAS> 0.661 <C> [BOLD] F1-score <WITH> sad <HAS> 0.673 <C> <R> <C> [BOLD] Precision <WITH> surprise <HAS> 0.627 <C> [BOLD] Recall <WITH> surprise <HAS> 0.705 <C> [BOLD] F1-score <WITH> surprise <HAS> 0.663 <C> <R> <C> [BOLD] Precision <WITH> Average <HAS> 0.695 <C> [BOLD] Recall <WITH> Average <HAS> 0.695 <C> [BOLD] F1-score <WITH> Average <HAS> 0.694 <C> <CAP> Table 3: Classification Report (Test Set).
 <R> <C> [BOLD] Present <WITH> Emoji <HAS> 4805 (76.6%) <C> [BOLD] Not Present <WITH> Emoji <HAS> 23952 (68.0%) <C> <R> <C> [BOLD] Present <WITH> Hashtags <HAS> 2122 (70.5%) <C> [BOLD] Not Present <WITH> Hashtags <HAS> 26635 (69.4%) <C> <CAP> Table 4: Number of tweets on the test set with and without emoji and hashtags. The number between parentheses is the proportion of tweets classified correctly.
 <R> <C> [BOLD] N <WITH> mask <HAS> 163 <C> [BOLD] emoji # <WITH> mask <HAS> 154 <C> [BOLD] emoji % <WITH> mask <HAS> 94.48 <C> [BOLD] no-emoji # <WITH> mask <HAS> 134 <C> [BOLD] no-emoji % <WITH> mask <HAS> 82.21 <C> [BOLD] Δ% <WITH> mask <HAS> - 12.27 <C> <R> <C> [BOLD] N <WITH> two_hearts <HAS> 87 <C> [BOLD] emoji # <WITH> two_hearts <HAS> 81 <C> [BOLD] emoji % <WITH> two_hearts <HAS> 93.10 <C> [BOLD] no-emoji # <WITH> two_hearts <HAS> 77 <C> [BOLD] no-emoji % <WITH> two_hearts <HAS> 88.51 <C> [BOLD] Δ% <WITH> two_hearts <HAS> - 4.59 <C> <R> <C> [BOLD] N <WITH> heart_eyes <HAS> 122 <C> [BOLD] emoji # <WITH> heart_eyes <HAS> 109 <C> [BOLD] emoji % <WITH> heart_eyes <HAS> 89.34 <C> [BOLD] no-emoji # <WITH> heart_eyes <HAS> 103 <C> [BOLD] no-emoji % <WITH> heart_eyes <HAS> 84.43 <C> [BOLD] Δ% <WITH> heart_eyes <HAS> - 4.91 <C> <R> <C> [BOLD] N <WITH> heart <HAS> 267 <C> [BOLD] emoji # <WITH> heart <HAS> 237 <C> [BOLD] emoji % <WITH> heart <HAS> 88.76 <C> [BOLD] no-emoji # <WITH> heart <HAS> 235 <C> [BOLD] no-emoji % <WITH> heart <HAS> 88.01 <C> [BOLD] Δ% <WITH> heart <HAS> - 0.75 <C> <R> <C> [BOLD] N <WITH> rage <HAS> 92 <C> [BOLD] emoji # <WITH> rage <HAS> 78 <C> [BOLD] emoji % <WITH> rage <HAS> 84.78 <C> [BOLD] no-emoji # <WITH> rage <HAS> 66 <C> [BOLD] no-emoji % <WITH> rage <HAS> 71.74 <C> [BOLD] Δ% <WITH> rage <HAS> - 13.04 <C> <R> <C> [BOLD] N <WITH> cry <HAS> 116 <C> [BOLD] emoji # <WITH> cry <HAS> 97 <C> [BOLD] emoji % <WITH> cry <HAS> 83.62 <C> [BOLD] no-emoji # <WITH> cry <HAS> 83 <C> [BOLD] no-emoji % <WITH> cry <HAS> 71.55 <C> [BOLD] Δ% <WITH> cry <HAS> - 12.07 <C> <R> <C> [BOLD] N <WITH> sob <HAS> 490 <C> [BOLD] emoji # <WITH> sob <HAS> 363 <C> [BOLD] emoji % <WITH> sob <HAS> 74.08 <C> [BOLD] no-emoji # <WITH> sob <HAS> 345 <C> [BOLD] no-emoji % <WITH> sob <HAS> 70.41 <C> [BOLD] Δ% <WITH> sob <HAS> - 3.67 <C> <R> <C> [BOLD] N <WITH> unamused <HAS> 167 <C> [BOLD] emoji # <WITH> unamused <HAS> 121 <C> [BOLD] emoji % <WITH> unamused <HAS> 72.46 <C> [BOLD] no-emoji # <WITH> unamused <HAS> 116 <C> [BOLD] no-emoji % <WITH> unamused <HAS> 69.46 <C> [BOLD] Δ% <WITH> unamused <HAS> - 3.00 <C> <R> <C> [BOLD] N <WITH> weary <HAS> 204 <C> [BOLD] emoji # <WITH> weary <HAS> 140 <C> [BOLD] emoji % <WITH> weary <HAS> 68.63 <C> [BOLD] no-emoji # <WITH> weary <HAS> 139 <C> [BOLD] no-emoji % <WITH> weary <HAS> 68.14 <C> [BOLD] Δ% <WITH> weary <HAS> - 0.49 <C> <R> <C> [BOLD] N <WITH> joy <HAS> 978 <C> [BOLD] emoji # <WITH> joy <HAS> 649 <C> [BOLD] emoji % <WITH> joy <HAS> 66.36 <C> [BOLD] no-emoji # <WITH> joy <HAS> 629 <C> [BOLD] no-emoji % <WITH> joy <HAS> 64.31 <C> [BOLD] Δ% <WITH> joy <HAS> - 2.05 <C> <R> <C> [BOLD] N <WITH> sweat_smile <HAS> 111 <C> [BOLD] emoji # <WITH> sweat_smile <HAS> 73 <C> [BOLD] emoji % <WITH> sweat_smile <HAS> 65.77 <C> [BOLD] no-emoji # <WITH> sweat_smile <HAS> 75 <C> [BOLD] no-emoji % <WITH> sweat_smile <HAS> 67.57 <C> [BOLD] Δ% <WITH> sweat_smile <HAS> 1.80 <C> <R> <C> [BOLD] N <WITH> confused <HAS> 77 <C> [BOLD] emoji # <WITH> confused <HAS> 46 <C> [BOLD] emoji % <WITH> confused <HAS> 59.74 <C> [BOLD] no-emoji # <WITH> confused <HAS> 48 <C> [BOLD] no-emoji % <WITH> confused <HAS> 62.34 <C> [BOLD] Δ% <WITH> confused <HAS> 2.60 <C> <CAP> Table 5: Fine grained performance on tweets containing emoji, and the effect of removing them.
 <R> <C> Metric <WITH> [ITALIC] Winograd <HAS> Precision <C> Illinois <WITH> [ITALIC] Winograd <HAS> 51.48 <C> IlliCons <WITH> [ITALIC] Winograd <HAS> 53.26 <C> rahman2012resolving <WITH> [ITALIC] Winograd <HAS> 73.05 <C> KnowFeat <WITH> [ITALIC] Winograd <HAS> 71.81 <C> KnowCons <WITH> [ITALIC] Winograd <HAS> 74.93 <C> KnowComb <WITH> [ITALIC] Winograd <HAS> [BOLD] 76.41 <C> <R> <C> Metric <WITH> [ITALIC] WinoCoref <HAS> AntePre <C> Illinois <WITH> [ITALIC] WinoCoref <HAS> 68.37 <C> IlliCons <WITH> [ITALIC] WinoCoref <HAS> 74.32 <C> rahman2012resolving <WITH> [ITALIC] WinoCoref <HAS> —– <C> KnowFeat <WITH> [ITALIC] WinoCoref <HAS> 88.48 <C> KnowCons <WITH> [ITALIC] WinoCoref <HAS> 88.95 <C> KnowComb <WITH> [ITALIC] WinoCoref <HAS> [BOLD] 89.32 <C> <CAP> Table 7: Performance results on Winograd and WinoCoref datasets. All our three systems are trained on WinoCoref, and we evaluate the predictions on both datasets. Our systems improve over the baselines by over than 20% on Winograd and over 15% on WinoCoref.
 <R> <C> MUC <WITH> ACE <HAS> ACE <C> BCUB <WITH> ACE <HAS> ACE <C> CEAFe <WITH> ACE <HAS> ACE <C> AVG <WITH> ACE <HAS> ACE <C> <R> <C> MUC <WITH> IlliCons <HAS> [BOLD] 78.17 <C> BCUB <WITH> IlliCons <HAS> 81.64 <C> CEAFe <WITH> IlliCons <HAS> [BOLD] 78.45 <C> AVG <WITH> IlliCons <HAS> [BOLD] 79.42 <C> <R> <C> MUC <WITH> KnowComb <HAS> 77.51 <C> BCUB <WITH> KnowComb <HAS> [BOLD] 81.97 <C> CEAFe <WITH> KnowComb <HAS> 77.44 <C> AVG <WITH> KnowComb <HAS> 78.97 <C> <R> <C> MUC <WITH> OntoNotes <HAS> OntoNotes <C> BCUB <WITH> OntoNotes <HAS> OntoNotes <C> CEAFe <WITH> OntoNotes <HAS> OntoNotes <C> AVG <WITH> OntoNotes <HAS> OntoNotes <C> <R> <C> MUC <WITH> IlliCons <HAS> 84.10 <C> BCUB <WITH> IlliCons <HAS> [BOLD] 78.30 <C> CEAFe <WITH> IlliCons <HAS> [BOLD] 68.74 <C> AVG <WITH> IlliCons <HAS> [BOLD] 77.05 <C> <R> <C> MUC <WITH> KnowComb <HAS> [BOLD] 84.33 <C> BCUB <WITH> KnowComb <HAS> 78.02 <C> CEAFe <WITH> KnowComb <HAS> 67.95 <C> AVG <WITH> KnowComb <HAS> 76.76 <C> <CAP> Table 8: Performance results on ACE and OntoNotes datasets. Our system gets the same level of performance compared to a state-of-art general coreference system.
 <R> <C> Cat1 <WITH> Size <HAS> 317 <C> Cat2 <WITH> Size <HAS> 1060 <C> Cat3 <WITH> Size <HAS> 509 <C> <R> <C> Cat1 <WITH> Portion <HAS> 16.8% <C> Cat2 <WITH> Portion <HAS> 56.2% <C> Cat3 <WITH> Portion <HAS> 27.0% <C> <CAP> Table 9: Distribution of instances in Winograd dataset of each category. Cat1/Cat2 is the subset of instances that require Type 1/Type 2 schema knowledge, respectively. All other instances are put into Cat3. Cat1 and Cat2 instances can be covered by our proposed Predicate Schemas.
 <R> <C> AntePre(Test) <WITH> Type 1 <HAS> 76.67 <C> AntePre(Train) <WITH> Type 1 <HAS> 86.79 <C> <R> <C> AntePre(Test) <WITH> Type 2 <HAS> 79.55 <C> AntePre(Train) <WITH> Type 2 <HAS> 88.86 <C> <R> <C> AntePre(Test) <WITH> Type 1 (Cat1) <HAS> 90.26 <C> AntePre(Train) <WITH> Type 1 (Cat1) <HAS> 93.64 <C> <R> <C> AntePre(Test) <WITH> Type 2 (Cat2) <HAS> 83.38 <C> AntePre(Train) <WITH> Type 2 (Cat2) <HAS> 92.49 <C> <CAP> Table 10: Ablation Study of Knowledge Schemas on WinoCoref. The first line specifies the preformance for KnowComb with only Type 1 schema knowledge tested on all data while the third line specifies the preformance using the same model but tested on Cat1 data. The second line specifies the preformance results for KnowComb system with only Type 2 schema knowledge on all data while the fourth line specifies the preformance using the same model but tested on Cat2 data.
 <R> <C> [BOLD] BB source acc. <WITH> [BOLD] Apply Yelp BB to SST-2 <HAS> 89.18±0.08% <C> [BOLD] BB target acc. <WITH> [BOLD] Apply Yelp BB to SST-2 <HAS> 77.13±0.52% <C> [BOLD] Non-reject. acc. (10/20/30%) <WITH> [BOLD] Apply Yelp BB to SST-2 <HAS> 82.43±0.22% 88.19±0.50% 93.60±0.16% <C> [BOLD] Class. quality (10/20/30%) <WITH> [BOLD] Apply Yelp BB to SST-2 <HAS> 80.40±0.39% 83.11±0.80% 83.05±0.23% <C> [BOLD] Reject. quality (10/20/30%) <WITH> [BOLD] Apply Yelp BB to SST-2 <HAS> 6.03±0.45 6.04±0.51 4.97±0.07 <C> <R> <C> [BOLD] BB source acc. <WITH> [BOLD] Apply SST-2 BB to Yelp <HAS> 83.306±0.18% <C> [BOLD] BB target acc. <WITH> [BOLD] Apply SST-2 BB to Yelp <HAS> 82.106±0.88% <C> [BOLD] Non-reject. acc. (10/20/30%) <WITH> [BOLD] Apply SST-2 BB to Yelp <HAS> 87,98±0.18% 92.13±0.38% 94.19±0.33% <C> [BOLD] Class. quality (10/20/30%) <WITH> [BOLD] Apply SST-2 BB to Yelp <HAS> 85.49±0.88% 84.53±0.38% 78.99±0.46% <C> [BOLD] Reject. quality (10/20/30%) <WITH> [BOLD] Apply SST-2 BB to Yelp <HAS> 8.30±1.63 5.72±0.27 3.73±0.10 <C> <R> <C> [BOLD] BB source acc. <WITH> [BOLD] Apply Electronics BB to Music <HAS> 86.39±0.22% <C> [BOLD] BB target acc. <WITH> [BOLD] Apply Electronics BB to Music <HAS> 90.38±0.13% <C> [BOLD] Non-reject. acc. (10/20/30%) <WITH> [BOLD] Apply Electronics BB to Music <HAS> 95.04±0.43% 96.45±0.35% 97.26±0.31% <C> [BOLD] Class. quality (10/20/30%) <WITH> [BOLD] Apply Electronics BB to Music <HAS> 90.67±0.88% 83.93±0.67% 75.77±0.54% <C> [BOLD] Reject. quality (10/20/30%) <WITH> [BOLD] Apply Electronics BB to Music <HAS> 10.7±1.65 4.82±0.35 3.25±0.14 <C> <R> <C> [BOLD] BB source acc. <WITH> [BOLD] Apply Music BB to Electronics <HAS> 93.10±0.02% <C> [BOLD] BB target acc. <WITH> [BOLD] Apply Music BB to Electronics <HAS> 79.85±0.0% <C> [BOLD] Non-reject. acc. (10/20/30%) <WITH> [BOLD] Apply Music BB to Electronics <HAS> 83.26±0.41% 87.06±0.55% 90.50±0.29% <C> [BOLD] Class. quality (10/20/30%) <WITH> [BOLD] Apply Music BB to Electronics <HAS> 79.97±0.74% 79.93±0.87% 76.81±0.41% <C> [BOLD] Reject. quality (10/20/30%) <WITH> [BOLD] Apply Music BB to Electronics <HAS> 4.1±0.55 3.80±0.35 3.32±0.09 <C> <CAP> Table 1: Accuracy obtained by training an standalone classifier, applying the API and the proposed wrapper for each domain
